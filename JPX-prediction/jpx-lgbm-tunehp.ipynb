{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-27T04:48:04.960026Z","iopub.execute_input":"2022-06-27T04:48:04.961425Z","iopub.status.idle":"2022-06-27T04:48:05.031095Z","shell.execute_reply.started":"2022-06-27T04:48:04.961287Z","shell.execute_reply":"2022-06-27T04:48:05.029844Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/jpx-tokyo-stock-exchange-prediction/stock_list.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/sample_submission.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/example_test_files/stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/competition.cpython-37m-x86_64-linux-gnu.so\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/jpx_tokyo_market_prediction/__init__.py\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_fin_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/trades_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_price_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/options_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/data_specifications/stock_list_spec.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/options.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/financials.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/secondary_stock_prices.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/trades.csv\n/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv\n/kaggle/input/talib-package/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl\n","output_type":"stream"}]},{"cell_type":"code","source":"# %cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:05.033888Z","iopub.execute_input":"2022-06-27T04:48:05.034757Z","iopub.status.idle":"2022-06-27T04:48:05.040080Z","shell.execute_reply.started":"2022-06-27T04:48:05.034711Z","shell.execute_reply":"2022-06-27T04:48:05.038880Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink(r'train_alot_of_features.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:05.042151Z","iopub.execute_input":"2022-06-27T04:48:05.042575Z","iopub.status.idle":"2022-06-27T04:48:05.056107Z","shell.execute_reply.started":"2022-06-27T04:48:05.042530Z","shell.execute_reply":"2022-06-27T04:48:05.054957Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/talib-package/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl\nimport talib as ta ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:05.058089Z","iopub.execute_input":"2022-06-27T04:48:05.058984Z","iopub.status.idle":"2022-06-27T04:48:16.481774Z","shell.execute_reply.started":"2022-06-27T04:48:05.058947Z","shell.execute_reply":"2022-06-27T04:48:16.480055Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Processing /kaggle/input/talib-package/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from talib-binary==0.4.19) (1.21.6)\nInstalling collected packages: talib-binary\nSuccessfully installed talib-binary-0.4.19\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom lightgbm import LGBMRegressor\nfrom lightgbm import early_stopping\nfrom sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\nimport missingno as msno\n\nfrom sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error, mean_squared_error\nfrom sklearn.model_selection import TimeSeriesSplit \n\nimport statsmodels.api as sm\nfrom pylab import rcParams\n\nfrom tqdm import tqdm\n\nimport optuna\nfrom optuna.integration import LightGBMPruningCallback\n\nfrom talib import abstract\n\nimport plotly.graph_objects as go\n\nimport time\nimport gc\nimport sys\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n# sys.path.insert(0, '../input/jpx-local-api')\n# from local_api import local_api","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:55:39.186360Z","iopub.execute_input":"2022-06-27T04:55:39.186797Z","iopub.status.idle":"2022-06-27T04:55:39.196208Z","shell.execute_reply.started":"2022-06-27T04:55:39.186758Z","shell.execute_reply":"2022-06-27T04:55:39.194833Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def get_ta_features(df, inf=None, train=True):\n    \"\"\"\n    Get technical features from TA-Lib\n    ref : https://www.kaggle.com/code/daosword/jpx-pytorch-neural-network-with-ta-lib-features\n    \"\"\"\n    if train:\n        op = df['Open']\n        hi = df['High']\n        lo = df['Low']\n        cl = df['Close']\n        vo = df['Volume']\n\n    #     # Overlap Studies\n    #     df['BBANDS_upper'], df['BBANDS_middle'], df['BBANDS_lower'] = ta.BBANDS(cl, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n    #     df['DEMA'] = ta.DEMA(cl, timeperiod=30)\n        \n        df['EMA7'] = ta.EMA(cl, 7)/cl\n        df['EMA15'] = ta.EMA(cl, 15)/cl\n        df['EMA30'] = ta.EMA(cl, 30)/cl\n        df['EMA90'] = ta.EMA(cl, 90)/cl\n\n    #     df['HT_TRENDLINE'] = ta.HT_TRENDLINE(cl)\n    #     df['KAMA'] = ta.KAMA(cl, timeperiod=30)\n    #     df['MA'] = ta.MA(cl, timeperiod=30, matype=0)\n    #     df['MIDPOINT'] = ta.MIDPOINT(cl, timeperiod=14)\n    #     df['SAR'] = ta.SAR(hi, lo, acceleration=0, maximum=0)\n    #     df['SAREXT'] = ta.SAREXT(hi, lo, startvalue=0, offsetonreverse=0, accelerationinitlong=0, accelerationlong=0, accelerationmaxlong=0, accelerationinitshort=0, accelerationshort=0, accelerationmaxshort=0)\n    #     df['SMA'] = ta.SMA(cl, timeperiod=30)\n    #     df['T3'] = ta.T3(df['Close'], timeperiod=5, vfactor=0)\n    #     df['TEMA'] = ta.TEMA(df['Close'], timeperiod=30)\n    #     df['TRIMA'] = ta.TRIMA(df['Close'], timeperiod=30)\n    #     df['WMA'] = ta.WMA(df['Close'], timeperiod=30)\n\n        # Momentum Indicators\n    #     df['ADX'] = ta.ADX(hi, lo, cl, timeperiod=14)\n    #     df['ADXR'] = ta.ADXR(hi, lo, cl, timeperiod=14)\n    #     df['APO'] = ta.APO(cl, fastperiod=12, slowperiod=26, matype=0)\n    #     df['AROON_down'], df['AROON_up'] = ta.AROON(hi, lo, timeperiod=14)\n    #     df['AROONOSC'] = ta.AROONOSC(hi, lo, timeperiod=14)\n    #     df['BOP'] = ta.BOP(op, hi, lo, cl)\n    #     df['CCI'] = ta.CCI(hi, lo, cl, timeperiod=14)\n    #     df['DX'] = ta.DX(hi, lo, cl, timeperiod=14)\n    #     df['MACD_macd'], df['MACD_macdsignal'], df['MACD_macdhist'] = ta.MACD(cl, fastperiod=12, slowperiod=26, signalperiod=9)\n    #     df['MFI'] = ta.MFI(hi, lo, cl, vo, timeperiod=14)\n    #     df['MINUS_DI'] = ta.MINUS_DI(hi, lo, cl, timeperiod=14)\n    #     df['MINUS_DM'] = ta.MINUS_DM(hi, lo, timeperiod=14)\n        df['MOM'] = ta.MOM(cl, timeperiod=10)\n    #     df['PLUS_DI'] = ta.PLUS_DI(hi, lo, cl, timeperiod=14)\n    #     df['PLUS_DM'] = ta.PLUS_DM(hi, lo, timeperiod=14)\n        df['RSI'] = ta.RSI(cl, timeperiod=14)\n        df['STOCH_slowk'], df['STOCH_slowd'] = ta.STOCH(hi, lo, cl, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n        df['STOCHF_fastk'], df['STOCHF_fastd'] = ta.STOCHF(hi, lo, cl, fastk_period=5, fastd_period=3, fastd_matype=0)\n        df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = ta.STOCHRSI(cl, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)\n    #     df['TRIX'] = ta.TRIX(cl, timeperiod=30)\n    #     df['ULTOSC'] = ta.ULTOSC(hi, lo, cl, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n    #     df['WILLR'] = ta.WILLR(hi, lo, cl, timeperiod=14)\n\n        # Volume Indicators\n    #     df['AD'] = ta.AD(hi, lo, cl, vo)\n    #     df['ADOSC'] = ta.ADOSC(hi, lo, cl, vo, fastperiod=3, slowperiod=10)\n    #     df['OBV'] = ta.OBV(cl, vo)\n\n        # Volatility Indicators\n        df['ATR'] = ta.ATR(hi, lo, cl, timeperiod=14)\n        df['NATR'] = ta.NATR(hi, lo, cl, timeperiod=14)\n        df['TRANGE'] = ta.TRANGE(hi, lo, cl)\n\n        # Cycle Indicators\n    #     df['HT_DCPERIOD'] = ta.HT_DCPERIOD(cl)\n    #     df['HT_DCPHASE'] = ta.HT_DCPHASE(cl)\n    #     df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = ta.HT_PHASOR(cl)\n    #     df['HT_SINE_sine'], df['HT_SINE_leadsine'] = ta.HT_SINE(cl)\n    #     df['HT_TRENDMODE'] = ta.HT_TRENDMODE(cl)\n\n        # Statistic Functions\n    #     df['BETA'] = ta.BETA(hi, lo, timeperiod=5)\n    #     df['CORREL'] = ta.CORREL(hi, lo, timeperiod=30)\n    #     df['LINEARREG'] = ta.LINEARREG(cl, timeperiod=14) - cl\n    #     df['LINEARREG_ANGLE'] = ta.LINEARREG_ANGLE(cl, timeperiod=14)\n    #     df['LINEARREG_INTERCEPT'] = ta.LINEARREG_INTERCEPT(cl, timeperiod=14) - cl\n    #     df['LINEARREG_SLOPE'] = ta.LINEARREG_SLOPE(cl, timeperiod=14)\n        df['STDDEV'] = ta.STDDEV(cl, timeperiod=5, nbdev=1)   \n    \n    \n    else: #inference \n        op = inf['Open']\n        hi = inf['High']\n        lo = inf['Low']\n        cl = inf['Close']\n        vo = inf['Volume']\n        \n            #     # Overlap Studies\n    #     df['BBANDS_upper'], df['BBANDS_middle'], df['BBANDS_lower'] = ta.BBANDS(cl, timeperiod=5, nbdevup=2, nbdevdn=2, matype=0)\n    #     df['DEMA'] = ta.DEMA(cl, timeperiod=30)\n\n        df['EMA7'] = ta.EMA(cl, 7).iloc[-1]\n        df['EMA15'] = ta.EMA(cl, 15).iloc[-1]\n        df['EMA30'] = ta.EMA(cl, 30).iloc[-1]\n        df['EMA90'] = ta.EMA(cl, 90).iloc[-1]\n\n    #     df['HT_TRENDLINE'] = ta.HT_TRENDLINE(cl)\n    #     df['KAMA'] = ta.KAMA(cl, timeperiod=30)\n    #     df['MA'] = ta.MA(cl, timeperiod=30, matype=0)\n    #     df['MIDPOINT'] = ta.MIDPOINT(cl, timeperiod=14)\n    #     df['SAR'] = ta.SAR(hi, lo, acceleration=0, maximum=0)\n    #     df['SAREXT'] = ta.SAREXT(hi, lo, startvalue=0, offsetonreverse=0, accelerationinitlong=0, accelerationlong=0, accelerationmaxlong=0, accelerationinitshort=0, accelerationshort=0, accelerationmaxshort=0)\n    #     df['SMA'] = ta.SMA(cl, timeperiod=30)\n    #     df['T3'] = ta.T3(df['Close'], timeperiod=5, vfactor=0)\n    #     df['TEMA'] = ta.TEMA(df['Close'], timeperiod=30)\n    #     df['TRIMA'] = ta.TRIMA(df['Close'], timeperiod=30)\n    #     df['WMA'] = ta.WMA(df['Close'], timeperiod=30)\n\n        # Momentum Indicators\n    #     df['ADX'] = ta.ADX(hi, lo, cl, timeperiod=14)\n    #     df['ADXR'] = ta.ADXR(hi, lo, cl, timeperiod=14)\n    #     df['APO'] = ta.APO(cl, fastperiod=12, slowperiod=26, matype=0)\n    #     df['AROON_down'], df['AROON_up'] = ta.AROON(hi, lo, timeperiod=14)\n    #     df['AROONOSC'] = ta.AROONOSC(hi, lo, timeperiod=14)\n    #     df['BOP'] = ta.BOP(op, hi, lo, cl)\n    #     df['CCI'] = ta.CCI(hi, lo, cl, timeperiod=14)\n    #     df['DX'] = ta.DX(hi, lo, cl, timeperiod=14)\n    #     df['MACD_macd'], df['MACD_macdsignal'], df['MACD_macdhist'] = ta.MACD(cl, fastperiod=12, slowperiod=26, signalperiod=9)\n    #     df['MFI'] = ta.MFI(hi, lo, cl, vo, timeperiod=14)\n    #     df['MINUS_DI'] = ta.MINUS_DI(hi, lo, cl, timeperiod=14)\n    #     df['MINUS_DM'] = ta.MINUS_DM(hi, lo, timeperiod=14)\n        df['MOM'] = ta.MOM(cl, timeperiod=10).iloc[-1]\n    #     df['PLUS_DI'] = ta.PLUS_DI(hi, lo, cl, timeperiod=14)\n    #     df['PLUS_DM'] = ta.PLUS_DM(hi, lo, timeperiod=14)\n        df['RSI'] = ta.RSI(cl, timeperiod=14).iloc[-1]\n        df['STOCH_slowk'], df['STOCH_slowd'] = (ta.STOCH(hi, lo, cl, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)[0].iloc[-1],\n                                                ta.STOCH(hi, lo, cl, fastk_period=5, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)[1].iloc[-1])\n        df['STOCHF_fastk'], df['STOCHF_fastd'] = (ta.STOCHF(hi, lo, cl, fastk_period=5, fastd_period=3, fastd_matype=0)[0].iloc[-1],\n                                                  ta.STOCHF(hi, lo, cl, fastk_period=5, fastd_period=3, fastd_matype=0)[1].iloc[-1])\n        df['STOCHRSI_fastk'], df['STOCHRSI_fastd'] = (ta.STOCHRSI(cl, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)[0].iloc[-1],\n                                                      ta.STOCHRSI(cl, timeperiod=14, fastk_period=5, fastd_period=3, fastd_matype=0)[1].iloc[-1])\n    #     df['TRIX'] = ta.TRIX(cl, timeperiod=30)\n    #     df['ULTOSC'] = ta.ULTOSC(hi, lo, cl, timeperiod1=7, timeperiod2=14, timeperiod3=28)\n    #     df['WILLR'] = ta.WILLR(hi, lo, cl, timeperiod=14)\n\n        # Volume Indicators\n    #     df['AD'] = ta.AD(hi, lo, cl, vo)\n    #     df['ADOSC'] = ta.ADOSC(hi, lo, cl, vo, fastperiod=3, slowperiod=10)\n    #     df['OBV'] = ta.OBV(cl, vo)\n\n        # Volatility Indicators\n        df['ATR'] = ta.ATR(hi, lo, cl, timeperiod=14).iloc[-1]\n        df['NATR'] = ta.NATR(hi, lo, cl, timeperiod=14).iloc[-1]\n        df['TRANGE'] = ta.TRANGE(hi, lo, cl).iloc[-1]\n\n        # Cycle Indicators\n    #     df['HT_DCPERIOD'] = ta.HT_DCPERIOD(cl)\n    #     df['HT_DCPHASE'] = ta.HT_DCPHASE(cl)\n    #     df['HT_PHASOR_inphase'], df['HT_PHASOR_quadrature'] = ta.HT_PHASOR(cl)\n    #     df['HT_SINE_sine'], df['HT_SINE_leadsine'] = ta.HT_SINE(cl)\n    #     df['HT_TRENDMODE'] = ta.HT_TRENDMODE(cl)\n\n        # Statistic Functions\n    #     df['BETA'] = ta.BETA(hi, lo, timeperiod=5)\n    #     df['CORREL'] = ta.CORREL(hi, lo, timeperiod=30)\n    #     df['LINEARREG'] = ta.LINEARREG(cl, timeperiod=14) - cl\n    #     df['LINEARREG_ANGLE'] = ta.LINEARREG_ANGLE(cl, timeperiod=14)\n    #     df['LINEARREG_INTERCEPT'] = ta.LINEARREG_INTERCEPT(cl, timeperiod=14) - cl\n    #     df['LINEARREG_SLOPE'] = ta.LINEARREG_SLOPE(cl, timeperiod=14)\n        df['STDDEV'] = ta.STDDEV(cl, timeperiod=5, nbdev=1).iloc[-1]   \n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:19.758361Z","iopub.execute_input":"2022-06-27T04:48:19.758926Z","iopub.status.idle":"2022-06-27T04:48:19.786829Z","shell.execute_reply.started":"2022-06-27T04:48:19.758893Z","shell.execute_reply":"2022-06-27T04:48:19.785621Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\n# display(data)\n\n\n# using supplement data as test data\nsupp_data = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv')\n\n# train_with_supp = pd.concat([train, supp_data]).reset_index(drop=True)\n# train_with_supp = train.copy()\n# train_with_supp\n\n# TA Features\n# train","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:19.788275Z","iopub.execute_input":"2022-06-27T04:48:19.788736Z","iopub.status.idle":"2022-06-27T04:48:26.133226Z","shell.execute_reply.started":"2022-06-27T04:48:19.788681Z","shell.execute_reply":"2022-06-27T04:48:26.131976Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def divideSecurities(df):\n    sec_list = []\n    print('Divide securities individually..')\n    for code in np.sort(df.SecuritiesCode.unique()):\n        sec_list.append(df.loc[df.SecuritiesCode == code, :].reset_index(drop=True))\n    return sec_list\n\n# sec_list = divideSecurities(train)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.134670Z","iopub.execute_input":"2022-06-27T04:48:26.135158Z","iopub.status.idle":"2022-06-27T04:48:26.142288Z","shell.execute_reply.started":"2022-06-27T04:48:26.135115Z","shell.execute_reply":"2022-06-27T04:48:26.141134Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def add_features_train(sec_list):\n    df_list = []\n    for df in tqdm(sec_list):\n        \n        # shadows\n        df['upper_shadow'] = df['High'] - np.maximum(df['Open'], df['Close'])\n        df['lower_shadow'] = np.minimum(df['Open'], df['Close']) - df['Low']\n        \n\n        ## Rolling features ##\n        \n        # lagged features\n        # 날짜 단위이므로 7일전, 30일전, 180일전, 360일전 \n        # lagged close, target (target 은 정확히 무엇? return인가)\n        \n        # lagged feature 계산하기 전 결측치 채워넣기\n        df = df.fillna(method='ffill')\n        \n        \n        \n        # All indicators in ta\n        try:\n            df = get_ta_features(df.copy())\n        except:\n            print(f\"error in SecuritiesCode: {df['SecuritiesCode'][0]}\")\n            display(df)\n            continue\n                \n        # not add pattern recognition - feature importance 가 거의 0임. \n#         for indicator in ta.get_function_groups()['Pattern Recognition']:\n#             df[str(indicator)] = getattr(ta,str(indicator))(df.Open, df.High, df.Low, df.Close)\n\n\n        ####  For test!! df['STOCHF_fastd'] df['STOCHRSI_fastk'] df['ATR']\n        ####  open high low close 등 제거\n        df = df.drop(columns=['STOCHF_fastd', 'STOCHRSI_fastk', 'ATR', 'Open', 'High', 'Low', 'Close'])\n\n        # fill ema features by backward -- 이렇게 채워진 것은 false data 이므로 일단 test 해보고 없애는 것을 검토하자.\n        df = df.fillna(method='bfill')\n\n    \n        # volatility\n        \n        df_list.append(df)\n        \n        del df\n        \n    gc.collect()\n    df_feature_added = pd.concat(df_list).sort_values(['Date','SecuritiesCode'])\n    \n    return df_feature_added\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.143906Z","iopub.execute_input":"2022-06-27T04:48:26.144669Z","iopub.status.idle":"2022-06-27T04:48:26.158001Z","shell.execute_reply.started":"2022-06-27T04:48:26.144627Z","shell.execute_reply":"2022-06-27T04:48:26.156875Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n#         else:\n#             df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.159555Z","iopub.execute_input":"2022-06-27T04:48:26.159982Z","iopub.status.idle":"2022-06-27T04:48:26.178799Z","shell.execute_reply.started":"2022-06-27T04:48:26.159952Z","shell.execute_reply":"2022-06-27T04:48:26.177630Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def add_features_infer(input_df, close_df): #input df 는 price 데이터\n    \n    df_list = []\n    \n    print('Divide input securities...')\n    sec_list = divideSecurities(input_df)\n    print('Divide close_df securities...')\n    close_list = divideSecurities(close_df) # for rolling features\n    print('='*10 + 'feature adding' + '='*10)\n    for i in range(len(sec_list)):\n        \n        if i == 0:\n            t0 = time.time()\n        close = close_list[i] #.loc[close_df.SecuritiesCode == code, :].fillna(method='ffill')\n        df = sec_list[i]\n#         display(df)\n        # test data의 open, high, low, close 중 nan 있으면 이전 값에서 가져와 채움\n        if df.loc[:, ['Open', 'High', 'Low', 'Close', 'Volume']].isna().any().any():\n            df.loc[:, ['Open', 'High', 'Low', 'Close', 'Volume']] = close.loc[close['Date'] == close.iloc[-1]['Date'], ['Open', 'High', 'Low', 'Close', 'Volume']].values \n        \n        if i == 0:\n            t1 = time.time()\n            print(t1 - t0, 's')\n        # shadows\n        df['upper_shadow'] = df['High'] - np.maximum(df['Open'], df['Close'])\n        df['lower_shadow'] = np.minimum(df['Open'], df['Close']) - df['Low']\n       \n        if i == 0:\n            t2 = time.time()\n            print(t2 - t1, 's')\n            \n        # lagged features\n        # 날짜 단위이므로 7일전, 30일전, 180일전, 360일전 \n        # lagged close, target (target 은 정확히 무엇? return인가)\n        \n        ## Rolling features ##\n        # TA-lib features - RSI, EMA 7-90\n        df = get_ta_features(df, close, train=False)\n\n        if i == 0:\n            t3 = time.time()\n            print(t3 - t2, 's')\n        \n#         for indicator in ta.get_function_groups()['Pattern Recognition']:\n#             df[str(indicator)] = getattr(ta,str(indicator))(df.Open, df.High, df.Low, df.Close)\n\n\n        # volatility\n        \n        df_list.append(df)\n    \n    df_feature_added = pd.concat(df_list)\n    print('='*10 + 'feature added' + '='*10)\n    return df_feature_added\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.180272Z","iopub.execute_input":"2022-06-27T04:48:26.180548Z","iopub.status.idle":"2022-06-27T04:48:26.197983Z","shell.execute_reply.started":"2022-06-27T04:48:26.180524Z","shell.execute_reply":"2022-06-27T04:48:26.196972Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def preprocess_train(df):\n    \n    # remove columns - Date removed temporarily\n    dfc = df.drop(columns=['RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag'])\n    \n    \n#     minmax = MinMaxScaler()\n    stdsc = StandardScaler()\n    ordinal = OrdinalEncoder()\n\n    target = ['Target']\n#     minmax_features = ['Date']\n    ord_features = ['SecuritiesCode'] \n#     scaled_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'upper_shadow', 'lower_shadow',\n#                       'RSI', 'EMA7', 'EMA15', 'EMA30', 'EMA90'] + [c for c in df.columns if c.startswith('CDL')] # pattern recognition features\n    scaled_features = [i for i in df.columns if i not in ['Date', 'RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag',\n                                                         'Target', 'SecuritiesCode']]\n    \n    \n#     date_scaled = minmax.fit_transform(dfc.loc[:,minmax_features])\n    date_code_ord = ordinal.fit_transform(dfc.loc[:,ord_features])\n    scaled = stdsc.fit_transform(dfc.loc[:,scaled_features])\n    \n#     display(pd.DataFrame(date_code_ord, columns=ord_features))\n#     display(pd.DataFrame(scaled, columns=scaled_features))\n    \n    \n    dfc_scaled = pd.concat([# pd.DataFrame(date_scaled, columns=minmax_features),\n                            pd.DataFrame(date_code_ord, columns=ord_features),\n                            pd.DataFrame(scaled, columns=scaled_features)], \n                            axis=1)\n    dfc_scaled = pd.concat([df['Date'].reset_index(drop=True), dfc_scaled],\n                           axis=1)\n    dfc_scaled = dfc_scaled.set_index(['Date'])\n\n    y = dfc.set_index(['Date']).loc[:, ['Target']]\n    \n    \n    return dfc_scaled, y, [ordinal, stdsc]\n    \n\n# X_scaled, y, trained_scalers = preprocess_train(df_added)  # 2021-12-06부터 test 시작이므로 그 전까지만 이용한다.\n\n# X_scaled\n# y","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.199436Z","iopub.execute_input":"2022-06-27T04:48:26.200060Z","iopub.status.idle":"2022-06-27T04:48:26.218071Z","shell.execute_reply.started":"2022-06-27T04:48:26.200016Z","shell.execute_reply":"2022-06-27T04:48:26.216980Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def preprocess_inference(df, trained_scalers: list):\n    ordinal = trained_scalers[0]\n    stdsc = trained_scalers[1]\n    \n      \n    # remove columns - Date removed temporarily\n    dfc = df.drop(columns=['RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag'])\n    \n    \n    target = ['Target']\n#     ord_features = ['SecuritiesCode'] \n#     scaled_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'upper_shadow', 'lower_shadow',\n#                       'RSI', 'EMA7', 'EMA15', 'EMA30', 'EMA90'] + [c for c in df.columns if c.startswith('CDL')] # pattern recognition features\n    scaled_features = [i for i in df.columns if i not in ['Date', 'RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag',\n                                                         'Target', 'SecuritiesCode']]\n    \n#     date_code_ord = ordinal.transform(dfc.loc[:,ord_features])\n    scaled = stdsc.transform(dfc.loc[:,scaled_features])\n    dfc_scaled = pd.concat([dfc.loc[:, ['SecuritiesCode']].reset_index(drop=True),\n                            pd.DataFrame(scaled, columns=scaled_features)], axis=1)\n    \n    dfc_scaled = pd.concat([df['Date'].reset_index(drop=True), dfc_scaled],\n                           axis=1)\n    dfc_scaled = dfc_scaled.set_index(['Date'])\n\n    y = dfc.set_index(['Date']).loc[:, ['Target']]\n    \n    return dfc_scaled, y\n    \n\n# X_test_scaled = preprocess_train(df_added, trained_scalers)\n\n# X_test_scaled","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.219470Z","iopub.execute_input":"2022-06-27T04:48:26.220028Z","iopub.status.idle":"2022-06-27T04:48:26.236573Z","shell.execute_reply.started":"2022-06-27T04:48:26.219992Z","shell.execute_reply":"2022-06-27T04:48:26.235675Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Evaluation - Sharpe ratio\n\ntimeseriesCV - mean sharpe ratio 계산  ","metadata":{}},{"cell_type":"code","source":"def calc_spread_return_sharpe(df: pd.DataFrame, portfolio_size: int = 200, toprank_weight_ratio: float = 2) -> float:\n    \"\"\"\n    Args:\n        df (pd.DataFrame): predicted results\n        portfolio_size (int): # of equities to buy/sell\n        toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n    Returns:\n        (float): sharpe ratio\n    \"\"\"\n    def _calc_spread_return_per_day(df, portfolio_size, toprank_weight_ratio):\n        \"\"\"\n        Args:\n            df (pd.DataFrame): predicted results\n            portfolio_size (int): # of equities to buy/sell\n            toprank_weight_ratio (float): the relative weight of the most highly ranked stock compared to the least.\n        Returns:\n            (float): spread return\n        \"\"\"\n        assert df['Rank'].min() == 0\n        assert df['Rank'].max() == len(df['Rank']) - 1\n        weights = np.linspace(start=toprank_weight_ratio, stop=1, num=portfolio_size)\n        purchase = (df.sort_values(by='Rank')['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        short = (df.sort_values(by='Rank', ascending=False)['Target'][:portfolio_size] * weights).sum() / weights.mean()\n        return purchase - short\n\n    buf = df.groupby('Date').apply(_calc_spread_return_per_day, portfolio_size, toprank_weight_ratio)\n    sharpe_ratio = buf.mean() / buf.std()\n    return sharpe_ratio","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.240303Z","iopub.execute_input":"2022-06-27T04:48:26.240931Z","iopub.status.idle":"2022-06-27T04:48:26.256081Z","shell.execute_reply.started":"2022-06-27T04:48:26.240887Z","shell.execute_reply":"2022-06-27T04:48:26.255147Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"### Check stationary features","metadata":{}},{"cell_type":"markdown","source":"### test2 - without columns['STOCHF_fastd', 'STOCHRSI_fastk', 'ATR', 'Open', 'High', 'Low', 'Close'] - 더 향상된 cv score\n\n- Stationary features만 남기는게 중요한 것 같다.\n\n","metadata":{}},{"cell_type":"code","source":"# train_cv = train.set_index('Date')\n# eval_cv = supp_data.set_index('Date')\ntrain_with_supp = pd.concat([train, supp_data]).reset_index(drop=True)\ngrid = train_with_supp['Date'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.257610Z","iopub.execute_input":"2022-06-27T04:48:26.258138Z","iopub.status.idle":"2022-06-27T04:48:26.948006Z","shell.execute_reply.started":"2022-06-27T04:48:26.258109Z","shell.execute_reply":"2022-06-27T04:48:26.946485Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# # cv - test 3 month period\n# # test2 - without columns=['STOCHF_fastd', 'STOCHRSI_fastk', 'ATR', 'Open', 'High', 'Low', 'Close']\n\n# # evaluate on each CV\n# def evaluate_test2(train, val):\n#     global feat_importance#, fold\n#     # train model\n#     sec_list = divideSecurities(train)\n#     df_added = add_features_train(sec_list)\n#     X_scaled, y, trained_scalers = preprocess_train(df_added)\n    \n#     # base model - lgbm \n#     lgb = LGBMRegressor()\n#     lgb.fit(X_scaled, y)\n    \n#     # predict evaluation data - same as train\n#     sec_list_val = divideSecurities(val)\n#     df_added_val = add_features_train(sec_list_val)\n#     X_scaled_val = preprocess_inference(df_added_val, trained_scalers)\n    \n#     y_pred = lgb.predict(X_scaled_val)\n#     val['predict'] = y_pred\n    \n#     feat_importance[\"Importance_Fold\"+str(k)]=lgb.feature_importances_\n#     feat_importance.set_index(X_scaled_val.columns, inplace=True)\n    \n#     # evaluate - eval set 일자별로 순위 계산하고, 이 결과를 바탕으로 sharpe ratio 계산\n#     eval_dates = val['Date'].unique()  # supp 일자 리스트\n\n#     predicted_df_list = []\n#     for i, date in enumerate(tqdm(eval_dates)):\n#         X = val[val['Date'] == date]\n#         # X, y\n#         X['Rank'] = (X['predict'].rank(method='first', ascending=False)-1).astype(int)\n\n#         # check Rank\n#         assert X[\"Rank\"].notna().all()\n#         assert X[\"Rank\"].min() == 0\n#         assert X[\"Rank\"].max() == len(X[\"Rank\"]) - 1\n#         predicted_df_list.append(X)\n\n#     predicted_df = pd.concat(predicted_df_list)\n# #     display(predicted_df)\n#     eval_score = calc_spread_return_sharpe(predicted_df)\n#     print('evaluated score:', eval_score)\n#     return eval_score\n\n\n# tscv = TimeSeriesSplit(n_splits=7, test_size=60)  # 2000개 주식이 모두 있는 기간이 300일 정도이다. 그래서 직전 기간까지 train하고 60일씩 5-fold로 쪼갬\n# # split input : index date\n# grid = np.concatenate([train['Date'].unique(), supp_data['Date'].unique()])\n\n\n\n# scores = []\n# k = 0\n# feat_importance = pd.DataFrame([])\n# for train_idx, eval_idx in tscv.split(grid):\n#     k += 1\n#     print(f'========Training fold {k}========')\n#     t0 = time.time()\n#     print('training size:', len(train_idx), '  test size:', len(eval_idx))\n    \n#     print(\"Train Date range: {} to {}\".format(grid[train_idx].min(),grid[train_idx].max()))\n#     print(\"Valid Date range: {} to {}\".format(grid[eval_idx].min(),grid[eval_idx].max()))\n    \n#     score = evaluate_test2(train_with_supp.loc[grid[train_idx]].reset_index(),\n#                      train_with_supp.loc[grid[eval_idx]].reset_index())\n#     print(f'Fold {k} evaluated in {time.time() - t0 :.3f}s')\n#     print(f'Fold {k} score: {score :.6f}')\n#     scores.append(score)\n    \n# print(scores)\n# print('cv mean score:', np.mean(scores), end='\\t')\n# print('cv std:', np.std(scores))\n\n\n# # test2 feature importances plot\n# feat_importance['avg'] = feat_importance.mean(axis=1)\n# feat_importance = feat_importance.sort_values(by='avg',ascending=True)\n# pal=sns.color_palette(\"plasma_r\", 29).as_hex()[2:]\n\n# fig=go.Figure()\n# for i in range(len(feat_importance.index)):\n#     fig.add_shape(dict(type=\"line\", y0=i, y1=i, x0=0, x1=feat_importance['avg'][i], \n#                        line_color=pal[::-1][i],opacity=0.7,line_width=4))\n# fig.add_trace(go.Scatter(x=feat_importance['avg'], y=feat_importance.index, mode='markers', \n#                          marker_color=pal[::-1], marker_size=8,))\n# #                          hovertemplate='%{y} Importance = %{x:.0f}<extra></extra>'))\n\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.949635Z","iopub.execute_input":"2022-06-27T04:48:26.950747Z","iopub.status.idle":"2022-06-27T04:48:26.958853Z","shell.execute_reply.started":"2022-06-27T04:48:26.950702Z","shell.execute_reply":"2022-06-27T04:48:26.958129Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"Feature selection 결론?\n- case2 의 features 를 적극 이용\n- 나머지 case에서 상위 5개정도의 feature들을 이용\n- feature끼리의 상관계수 측정하여 너무 높은것은 뺌\n- target과의 상관계수도 살펴보기","metadata":{}},{"cell_type":"markdown","source":"### Hyperparameter tuning using Optuna","metadata":{}},{"cell_type":"code","source":"# cv optimize 를 위해 train으로만 scaler 만든 후 전체 데이터에 적용\nsec_list = divideSecurities(train)\ndf_added = add_features_train(sec_list)\nX_scaled, y, trained_scalers = preprocess_train(df_added)\ndel X_scaled, y\n\nsec_list = divideSecurities(train_with_supp)\ndf_added = add_features_train(sec_list)\nX_scaled, y = preprocess_inference(df_added, trained_scalers)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T04:48:26.959745Z","iopub.execute_input":"2022-06-27T04:48:26.960364Z","iopub.status.idle":"2022-06-27T04:49:43.796865Z","shell.execute_reply.started":"2022-06-27T04:48:26.960335Z","shell.execute_reply":"2022-06-27T04:49:43.795669Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Divide securities individually..\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:24<00:00, 83.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"Divide securities individually..\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2000/2000 [00:24<00:00, 81.77it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"def objective(trial, X, y, k=7):  # X_scaled, X_scaled_val, y, y_val\n    param_grid = {\n        # \"device_type\": trial.suggest_categorical(\"device_type\", ['gpu']),\n        'objective': 'regression',\n        \"n_estimators\": trial.suggest_categorical(\"n_estimators\", [4000]),\n        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.5),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 200, 10000, step=100),\n        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n#         \"min_gain_to_split\": trial.suggest_float(\"min_gain_to_split\", 0, 15),\n        \"bagging_fraction\": trial.suggest_float(\n            \"bagging_fraction\", 0.2, 0.9, step=0.1\n        ),\n#         \"bagging_freq\": trial.suggest_categorical(\"bagging_freq\", [1]),\n        \"feature_fraction\": trial.suggest_float(\n            \"feature_fraction\", 0.2, 0.9, step=0.1\n        ),\n        \"metric\": 'l2'\n    }\n\n    tscv = TimeSeriesSplit(n_splits=k, test_size=120)\n\n    cv_scores = []\n    for i, (train_idx, eval_idx) in enumerate(tscv.split(grid)):\n        print()\n        print(f'============== Fold {i+1} ================')\n        \n        \n        X_train, X_test = X.loc[grid[train_idx]].reset_index(drop=True), X.loc[grid[eval_idx]].reset_index(drop=True)\n        y_train, y_test = y.loc[grid[train_idx]].reset_index(drop=True), y.loc[grid[eval_idx]].reset_index(drop=True)\n        \n        print(\"Train Date range: {} to {}\".format(grid[train_idx].min(),grid[train_idx].max()))\n        print(\"Valid Date range: {} to {}\".format(grid[eval_idx].min(),grid[eval_idx].max()))\n        \n        model = LGBMRegressor(**param_grid)\n        model.fit(\n            X_train,\n            y_train,\n            eval_set=[(X_test, y_test)],\n            callbacks=[\n#                 LightGBMPruningCallback(trial, \"l2\"),\n                early_stopping(stopping_rounds=20)\n            ],  # Add a pruning callback\n        )\n        y_pred = model.predict(X_test)\n        \n#         cv_scores.append(mean_squared_error(y_test, y_pred))\n        \n        # test - optimize to maximize sharpe ratio\n        X_test['Date'] = X.loc[grid[eval_idx]].index\n        X_test['predict'] = y_pred\n        X_test['Target'] = y_test\n        X_test['Rank'] = (X_test.groupby('Date')['predict'].rank(method='first', ascending=False)-1).astype(int)\n#         display(X_test.groupby('Date')['Rank'].min())\n#         display(X_test.groupby('Date')['Rank'].max())\n#         display(X_test)\n        eval_score = calc_spread_return_sharpe(X_test)\n        cv_scores.append(eval_score)\n    print('cv completed with scores:', cv_scores)\n    print('mean score:', np.mean(cv_scores))\n    return np.mean(cv_scores)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:53:20.813268Z","iopub.execute_input":"2022-06-27T05:53:20.813662Z","iopub.status.idle":"2022-06-27T05:53:20.830566Z","shell.execute_reply.started":"2022-06-27T05:53:20.813631Z","shell.execute_reply":"2022-06-27T05:53:20.829346Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"optuna.logging.set_verbosity(optuna.logging.ERROR)\n\nstudy = optuna.create_study(direction=\"maximize\", study_name=\"LGBM Regressor\")\nfunc = lambda trial: objective(trial, X_scaled, y, k=5)\nstudy.optimize(func, n_trials=30)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:15:22.760386Z","iopub.execute_input":"2022-06-27T06:15:22.761690Z","iopub.status.idle":"2022-06-27T06:31:35.100244Z","shell.execute_reply.started":"2022-06-27T06:15:22.761627Z","shell.execute_reply":"2022-06-27T06:31:35.098629Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.5313675602373132e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5313675602373132e-05\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n[LightGBM] [Warning] lambda_l2 is set=1.448929843319282e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.448929843319282e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[46]\tvalid_0's l2: 0.00102281\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.5313675602373132e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5313675602373132e-05\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n[LightGBM] [Warning] lambda_l2 is set=1.448929843319282e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.448929843319282e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[14]\tvalid_0's l2: 0.000651571\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.5313675602373132e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5313675602373132e-05\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n[LightGBM] [Warning] lambda_l2 is set=1.448929843319282e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.448929843319282e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.5313675602373132e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5313675602373132e-05\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n[LightGBM] [Warning] lambda_l2 is set=1.448929843319282e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.448929843319282e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[26]\tvalid_0's l2: 0.000454143\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.5313675602373132e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.5313675602373132e-05\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000\n[LightGBM] [Warning] lambda_l2 is set=1.448929843319282e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.448929843319282e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.04965617397575287, 0.07162954391485132, 0.062314186711006796, 0.1336935963249068, -0.09294404550725473]\nmean score: 0.04486989108385261\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.2626273683393786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2626273683393786\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.0006271164188084195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006271164188084195\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[46]\tvalid_0's l2: 0.00102266\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.2626273683393786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2626273683393786\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.0006271164188084195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006271164188084195\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[12]\tvalid_0's l2: 0.000651544\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.2626273683393786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2626273683393786\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.0006271164188084195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006271164188084195\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.2626273683393786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2626273683393786\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.0006271164188084195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006271164188084195\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[18]\tvalid_0's l2: 0.000454141\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.2626273683393786, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2626273683393786\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.0006271164188084195, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006271164188084195\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595286\ncv completed with scores: [0.044458800430219, 0.06566064469903575, 0.05651578178448506, 0.1304500687334512, -0.11552489553994325]\nmean score: 0.03631208002144955\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=6.8510983934404494e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8510983934404494e-06\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n[LightGBM] [Warning] lambda_l2 is set=0.985062352948623, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.985062352948623\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.00102205\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=6.8510983934404494e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8510983934404494e-06\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n[LightGBM] [Warning] lambda_l2 is set=0.985062352948623, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.985062352948623\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[8]\tvalid_0's l2: 0.000651099\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=6.8510983934404494e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8510983934404494e-06\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n[LightGBM] [Warning] lambda_l2 is set=0.985062352948623, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.985062352948623\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000497827\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=6.8510983934404494e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8510983934404494e-06\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n[LightGBM] [Warning] lambda_l2 is set=0.985062352948623, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.985062352948623\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000454177\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=6.8510983934404494e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.8510983934404494e-06\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100\n[LightGBM] [Warning] lambda_l2 is set=0.985062352948623, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.985062352948623\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595492\ncv completed with scores: [0.0686041701672567, 0.08189997297694582, 0.04684020006118269, 0.05565595997103919, -0.10719751621436752]\nmean score: 0.029160557392411378\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=7.762356595675797e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.762356595675797e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n[LightGBM] [Warning] lambda_l2 is set=5.59548725795194e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.59548725795194e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[95]\tvalid_0's l2: 0.0010234\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=7.762356595675797e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.762356595675797e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n[LightGBM] [Warning] lambda_l2 is set=5.59548725795194e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.59548725795194e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.000651659\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=7.762356595675797e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.762356595675797e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n[LightGBM] [Warning] lambda_l2 is set=5.59548725795194e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.59548725795194e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=7.762356595675797e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.762356595675797e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n[LightGBM] [Warning] lambda_l2 is set=5.59548725795194e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.59548725795194e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[37]\tvalid_0's l2: 0.000454167\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=7.762356595675797e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.762356595675797e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600\n[LightGBM] [Warning] lambda_l2 is set=5.59548725795194e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.59548725795194e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.045662506887920035, 0.08194350100223127, 0.09686051489658135, 0.1731639218301766, -0.05801475318313688]\nmean score: 0.06792313828675448\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.0017653839223056237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017653839223056237\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n[LightGBM] [Warning] lambda_l2 is set=9.374851649006105e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.374851649006105e-06\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[11]\tvalid_0's l2: 0.00102388\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.0017653839223056237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017653839223056237\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n[LightGBM] [Warning] lambda_l2 is set=9.374851649006105e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.374851649006105e-06\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.00065166\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.0017653839223056237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017653839223056237\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n[LightGBM] [Warning] lambda_l2 is set=9.374851649006105e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.374851649006105e-06\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000497774\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.0017653839223056237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017653839223056237\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n[LightGBM] [Warning] lambda_l2 is set=9.374851649006105e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.374851649006105e-06\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[7]\tvalid_0's l2: 0.000454167\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.0017653839223056237, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0017653839223056237\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200\n[LightGBM] [Warning] lambda_l2 is set=9.374851649006105e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.374851649006105e-06\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595286\ncv completed with scores: [0.020689484134856034, 0.08116315451884455, 0.10270413252883687, 0.09808435466683019, -0.10684390990316027]\nmean score: 0.03915944318924147\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.2395924000684384e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2395924000684384e-07\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n[LightGBM] [Warning] lambda_l2 is set=0.004810289558080752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004810289558080752\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[56]\tvalid_0's l2: 0.00102303\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.2395924000684384e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2395924000684384e-07\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n[LightGBM] [Warning] lambda_l2 is set=0.004810289558080752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004810289558080752\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[14]\tvalid_0's l2: 0.000651601\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.2395924000684384e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2395924000684384e-07\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n[LightGBM] [Warning] lambda_l2 is set=0.004810289558080752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004810289558080752\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000497776\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.2395924000684384e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2395924000684384e-07\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n[LightGBM] [Warning] lambda_l2 is set=0.004810289558080752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004810289558080752\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[36]\tvalid_0's l2: 0.00045414\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.2395924000684384e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2395924000684384e-07\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200\n[LightGBM] [Warning] lambda_l2 is set=0.004810289558080752, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004810289558080752\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.03488030379562765, 0.0707043156427922, 0.07046903278247002, 0.15544819350844855, -0.16296715372010145]\nmean score: 0.03370693840184739\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.00021469166561962315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021469166561962315\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n[LightGBM] [Warning] lambda_l2 is set=0.0011394589365468718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011394589365468718\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.00102371\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.00021469166561962315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021469166561962315\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n[LightGBM] [Warning] lambda_l2 is set=0.0011394589365468718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011394589365468718\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[15]\tvalid_0's l2: 0.000651544\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.00021469166561962315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021469166561962315\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n[LightGBM] [Warning] lambda_l2 is set=0.0011394589365468718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011394589365468718\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[26]\tvalid_0's l2: 0.000497682\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.00021469166561962315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021469166561962315\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n[LightGBM] [Warning] lambda_l2 is set=0.0011394589365468718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011394589365468718\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[30]\tvalid_0's l2: 0.000454084\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.00021469166561962315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00021469166561962315\n[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2\n[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300\n[LightGBM] [Warning] lambda_l2 is set=0.0011394589365468718, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011394589365468718\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.00059528\ncv completed with scores: [0.0950806985551242, 0.09523378371660597, 0.05268343540545885, 0.08552749598527697, -0.09586200417842815]\nmean score: 0.04653268189680757\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.7069947027818764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7069947027818764\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n[LightGBM] [Warning] lambda_l2 is set=0.10124047176372314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10124047176372314\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[119]\tvalid_0's l2: 0.00102216\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.7069947027818764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7069947027818764\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n[LightGBM] [Warning] lambda_l2 is set=0.10124047176372314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10124047176372314\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000651688\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.7069947027818764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7069947027818764\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n[LightGBM] [Warning] lambda_l2 is set=0.10124047176372314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10124047176372314\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[19]\tvalid_0's l2: 0.000497758\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.7069947027818764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7069947027818764\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n[LightGBM] [Warning] lambda_l2 is set=0.10124047176372314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10124047176372314\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[12]\tvalid_0's l2: 0.000454166\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.7069947027818764, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7069947027818764\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600\n[LightGBM] [Warning] lambda_l2 is set=0.10124047176372314, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.10124047176372314\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595286\ncv completed with scores: [0.05049148451966932, -0.013720864283763136, 0.06352303091368856, 0.07398414191200928, -0.1419234341433639]\nmean score: 0.0064708717836480245\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.015151057397742099, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015151057397742099\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.00012295129318661466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00012295129318661466\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[26]\tvalid_0's l2: 0.00102217\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.015151057397742099, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015151057397742099\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.00012295129318661466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00012295129318661466\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.00065169\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.015151057397742099, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015151057397742099\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.00012295129318661466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00012295129318661466\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000497744\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.015151057397742099, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015151057397742099\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.00012295129318661466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00012295129318661466\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000454176\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.015151057397742099, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.015151057397742099\n[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9\n[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400\n[LightGBM] [Warning] lambda_l2 is set=0.00012295129318661466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00012295129318661466\n[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595296\ncv completed with scores: [0.04593451886140223, 0.04704780770937577, 0.04448620737256842, 0.027051741085121577, -0.10925567758824281]\nmean score: 0.011052919488045033\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.04561713845228317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04561713845228317\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n[LightGBM] [Warning] lambda_l2 is set=2.2728099992880004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2728099992880004\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[103]\tvalid_0's l2: 0.00102352\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.04561713845228317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04561713845228317\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n[LightGBM] [Warning] lambda_l2 is set=2.2728099992880004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2728099992880004\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[104]\tvalid_0's l2: 0.000651455\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.04561713845228317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04561713845228317\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n[LightGBM] [Warning] lambda_l2 is set=2.2728099992880004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2728099992880004\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[3]\tvalid_0's l2: 0.000497777\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.04561713845228317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04561713845228317\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n[LightGBM] [Warning] lambda_l2 is set=2.2728099992880004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2728099992880004\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[81]\tvalid_0's l2: 0.000454144\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.04561713845228317, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04561713845228317\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=6400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6400\n[LightGBM] [Warning] lambda_l2 is set=2.2728099992880004, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.2728099992880004\n[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595285\ncv completed with scores: [0.0737297143127374, 0.053518259621699524, 0.06276143687157455, 0.1199199649287951, -0.13327182348511477]\nmean score: 0.03533151044993836\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=3.576534525034766e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.576534525034766e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n[LightGBM] [Warning] lambda_l2 is set=1.961992248481084e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.961992248481084e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.0010239\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=3.576534525034766e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.576534525034766e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n[LightGBM] [Warning] lambda_l2 is set=1.961992248481084e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.961992248481084e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[27]\tvalid_0's l2: 0.000651674\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=3.576534525034766e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.576534525034766e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n[LightGBM] [Warning] lambda_l2 is set=1.961992248481084e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.961992248481084e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[8]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=3.576534525034766e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.576534525034766e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n[LightGBM] [Warning] lambda_l2 is set=1.961992248481084e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.961992248481084e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[70]\tvalid_0's l2: 0.000454167\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=3.576534525034766e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.576534525034766e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600\n[LightGBM] [Warning] lambda_l2 is set=1.961992248481084e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.961992248481084e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.11098638827285656, 0.08251620855091513, 0.08445345827121163, 0.17419893281528406, -0.05347079583638266]\nmean score: 0.07973683841477695\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=3.5024590885210416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5024590885210416e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n[LightGBM] [Warning] lambda_l2 is set=1.068109229012349e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.068109229012349e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.0010239\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=3.5024590885210416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5024590885210416e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n[LightGBM] [Warning] lambda_l2 is set=1.068109229012349e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.068109229012349e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[22]\tvalid_0's l2: 0.000651678\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=3.5024590885210416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5024590885210416e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n[LightGBM] [Warning] lambda_l2 is set=1.068109229012349e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.068109229012349e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[8]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=3.5024590885210416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5024590885210416e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n[LightGBM] [Warning] lambda_l2 is set=1.068109229012349e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.068109229012349e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[70]\tvalid_0's l2: 0.000454172\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=3.5024590885210416e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5024590885210416e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800\n[LightGBM] [Warning] lambda_l2 is set=1.068109229012349e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.068109229012349e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.11098638827285656, 0.0720420255649186, 0.07276067322784711, 0.1573334044878067, -0.052706935637446786]\nmean score: 0.07208311118319644\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.7269810744901014e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7269810744901014e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n[LightGBM] [Warning] lambda_l2 is set=7.130827453550858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.130827453550858e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[70]\tvalid_0's l2: 0.0010238\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.7269810744901014e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7269810744901014e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n[LightGBM] [Warning] lambda_l2 is set=7.130827453550858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.130827453550858e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[22]\tvalid_0's l2: 0.00065167\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.7269810744901014e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7269810744901014e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n[LightGBM] [Warning] lambda_l2 is set=7.130827453550858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.130827453550858e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[8]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.7269810744901014e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7269810744901014e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n[LightGBM] [Warning] lambda_l2 is set=7.130827453550858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.130827453550858e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[69]\tvalid_0's l2: 0.000454166\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.7269810744901014e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7269810744901014e-08\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600\n[LightGBM] [Warning] lambda_l2 is set=7.130827453550858e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=7.130827453550858e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.043846750850251005, 0.08976938925206356, 0.06913787581729997, 0.0719743486978194, -0.1212537056535034]\nmean score: 0.030694931792786106\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=3.0752108682992454e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0752108682992454e-07\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n[LightGBM] [Warning] lambda_l2 is set=1.046554109808675e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.046554109808675e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.00102405\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=3.0752108682992454e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0752108682992454e-07\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n[LightGBM] [Warning] lambda_l2 is set=1.046554109808675e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.046554109808675e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000651788\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=3.0752108682992454e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0752108682992454e-07\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n[LightGBM] [Warning] lambda_l2 is set=1.046554109808675e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.046554109808675e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.00049787\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=3.0752108682992454e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0752108682992454e-07\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n[LightGBM] [Warning] lambda_l2 is set=1.046554109808675e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.046554109808675e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[3]\tvalid_0's l2: 0.000454149\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=3.0752108682992454e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0752108682992454e-07\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700\n[LightGBM] [Warning] lambda_l2 is set=1.046554109808675e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.046554109808675e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595364\ncv completed with scores: [-0.18010745247534402, 0.0751680937428603, 0.07622040184722785, 0.01642847575880227, -0.0519638273140703]\nmean score: -0.012850861688104778\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=7.712667615070149e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.712667615070149e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n[LightGBM] [Warning] lambda_l2 is set=1.1587634802691828e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1587634802691828e-08\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[29]\tvalid_0's l2: 0.00102385\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=7.712667615070149e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.712667615070149e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n[LightGBM] [Warning] lambda_l2 is set=1.1587634802691828e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1587634802691828e-08\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[7]\tvalid_0's l2: 0.000651683\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=7.712667615070149e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.712667615070149e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n[LightGBM] [Warning] lambda_l2 is set=1.1587634802691828e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1587634802691828e-08\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497777\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=7.712667615070149e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.712667615070149e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n[LightGBM] [Warning] lambda_l2 is set=1.1587634802691828e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1587634802691828e-08\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[22]\tvalid_0's l2: 0.000454175\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=7.712667615070149e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.712667615070149e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900\n[LightGBM] [Warning] lambda_l2 is set=1.1587634802691828e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.1587634802691828e-08\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.0054783579696166705, 0.0884580720501838, 0.0739103467592455, 0.07996647545439806, -0.12329589240529189]\nmean score: 0.024903471965630426\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=2.3620382277470426e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3620382277470426e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n[LightGBM] [Warning] lambda_l2 is set=2.3945052283011863e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3945052283011863e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[3]\tvalid_0's l2: 0.00102413\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=2.3620382277470426e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3620382277470426e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n[LightGBM] [Warning] lambda_l2 is set=2.3945052283011863e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3945052283011863e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000651727\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=2.3620382277470426e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3620382277470426e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n[LightGBM] [Warning] lambda_l2 is set=2.3945052283011863e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3945052283011863e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000497793\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=2.3620382277470426e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3620382277470426e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n[LightGBM] [Warning] lambda_l2 is set=2.3945052283011863e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3945052283011863e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000454135\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=2.3620382277470426e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.3620382277470426e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700\n[LightGBM] [Warning] lambda_l2 is set=2.3945052283011863e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3945052283011863e-07\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595327\ncv completed with scores: [-0.047452818739057386, 0.07491891042234615, 0.08155711110990822, 0.08712442258238016, -0.05457282985412049]\nmean score: 0.028314959104291337\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=3.442835127870893e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.442835127870893e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000\n[LightGBM] [Warning] lambda_l2 is set=8.866460022886298e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.866460022886298e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.00102389\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=3.442835127870893e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.442835127870893e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000\n[LightGBM] [Warning] lambda_l2 is set=8.866460022886298e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.866460022886298e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[74]\tvalid_0's l2: 0.000651639\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=3.442835127870893e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.442835127870893e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000\n[LightGBM] [Warning] lambda_l2 is set=8.866460022886298e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.866460022886298e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000497778\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=3.442835127870893e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.442835127870893e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000\n[LightGBM] [Warning] lambda_l2 is set=8.866460022886298e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.866460022886298e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[95]\tvalid_0's l2: 0.000454166\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=3.442835127870893e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.442835127870893e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000\n[LightGBM] [Warning] lambda_l2 is set=8.866460022886298e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.866460022886298e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.03990696878583945, 0.10258888838044361, 0.060231763312233816, 0.13131202849557455, -0.05471782993351329]\nmean score: 0.05586436380811564\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.104078682283489e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.104078682283489e-08\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n[LightGBM] [Warning] lambda_l2 is set=1.6317462740736354e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6317462740736354e-05\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.00102539\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.104078682283489e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.104078682283489e-08\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n[LightGBM] [Warning] lambda_l2 is set=1.6317462740736354e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6317462740736354e-05\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000656174\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.104078682283489e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.104078682283489e-08\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n[LightGBM] [Warning] lambda_l2 is set=1.6317462740736354e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6317462740736354e-05\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000499169\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.104078682283489e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.104078682283489e-08\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n[LightGBM] [Warning] lambda_l2 is set=1.6317462740736354e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6317462740736354e-05\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000455136\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.104078682283489e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.104078682283489e-08\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600\n[LightGBM] [Warning] lambda_l2 is set=1.6317462740736354e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6317462740736354e-05\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000597547\ncv completed with scores: [0.08045573645770722, 0.06169065114347939, 0.027618231529772497, 0.018818798146569334, -0.12444989645247655]\nmean score: 0.01282670416501038\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=2.424805652830606e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.424805652830606e-07\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n[LightGBM] [Warning] lambda_l2 is set=1.2075258172139973e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2075258172139973e-07\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[16]\tvalid_0's l2: 0.00102385\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=2.424805652830606e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.424805652830606e-07\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n[LightGBM] [Warning] lambda_l2 is set=1.2075258172139973e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2075258172139973e-07\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[109]\tvalid_0's l2: 0.000651304\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=2.424805652830606e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.424805652830606e-07\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n[LightGBM] [Warning] lambda_l2 is set=1.2075258172139973e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2075258172139973e-07\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000497777\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=2.424805652830606e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.424805652830606e-07\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n[LightGBM] [Warning] lambda_l2 is set=1.2075258172139973e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2075258172139973e-07\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[40]\tvalid_0's l2: 0.000454158\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=2.424805652830606e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.424805652830606e-07\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600\n[LightGBM] [Warning] lambda_l2 is set=1.2075258172139973e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.2075258172139973e-07\n[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595285\ncv completed with scores: [0.0542015266702483, 0.08725210980309059, 0.06334490533810105, 0.1282129026450405, -0.04999399013461198]\nmean score: 0.0566034908643737\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.8632282482327e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8632282482327e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4300\n[LightGBM] [Warning] lambda_l2 is set=1.6365230362570995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6365230362570995e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.00102389\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.8632282482327e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8632282482327e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4300\n[LightGBM] [Warning] lambda_l2 is set=1.6365230362570995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6365230362570995e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[27]\tvalid_0's l2: 0.000651638\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.8632282482327e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8632282482327e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4300\n[LightGBM] [Warning] lambda_l2 is set=1.6365230362570995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6365230362570995e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000497779\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.8632282482327e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8632282482327e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4300\n[LightGBM] [Warning] lambda_l2 is set=1.6365230362570995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6365230362570995e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[40]\tvalid_0's l2: 0.000454177\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.8632282482327e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8632282482327e-06\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=4300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4300\n[LightGBM] [Warning] lambda_l2 is set=1.6365230362570995e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.6365230362570995e-06\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.049484318010000465, 0.08870020083090646, 0.06708769672180406, 0.14049573315796954, -0.06457448354327851]\nmean score: 0.0562386930354804\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=4.539665484319496, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.539665484319496\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n[LightGBM] [Warning] lambda_l2 is set=0.04026334729686956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04026334729686956\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[11]\tvalid_0's l2: 0.0010238\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=4.539665484319496, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.539665484319496\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n[LightGBM] [Warning] lambda_l2 is set=0.04026334729686956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04026334729686956\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000651683\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=4.539665484319496, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.539665484319496\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n[LightGBM] [Warning] lambda_l2 is set=0.04026334729686956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04026334729686956\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.00049778\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=4.539665484319496, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.539665484319496\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n[LightGBM] [Warning] lambda_l2 is set=0.04026334729686956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04026334729686956\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000454174\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=4.539665484319496, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.539665484319496\n[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7\n[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500\n[LightGBM] [Warning] lambda_l2 is set=0.04026334729686956, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04026334729686956\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595289\ncv completed with scores: [0.045102608525273084, 0.05051195406504203, 0.05490563490685108, 0.10182918553677615, -0.10589366605937511]\nmean score: 0.029291143394913444\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=5.898527192038466e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.898527192038466e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=4.7737707767126774e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.7737707767126774e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.00102388\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=5.898527192038466e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.898527192038466e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=4.7737707767126774e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.7737707767126774e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.00065166\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=5.898527192038466e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.898527192038466e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=4.7737707767126774e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.7737707767126774e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=5.898527192038466e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.898527192038466e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=4.7737707767126774e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.7737707767126774e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[37]\tvalid_0's l2: 0.000454168\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=5.898527192038466e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.898527192038466e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=4.7737707767126774e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.7737707767126774e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.03660297747120807, 0.08097541960987913, 0.09686051489658135, 0.17332073197612824, -0.05370081191673103]\nmean score: 0.06681176640741315\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.014513808760157e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.014513808760157e-07\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=3.616974261103616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.616974261103616e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.00102389\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.014513808760157e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.014513808760157e-07\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=3.616974261103616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.616974261103616e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[28]\tvalid_0's l2: 0.000651669\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.014513808760157e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.014513808760157e-07\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=3.616974261103616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.616974261103616e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497776\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.014513808760157e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.014513808760157e-07\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=3.616974261103616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.616974261103616e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[95]\tvalid_0's l2: 0.000454173\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.014513808760157e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.014513808760157e-07\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400\n[LightGBM] [Warning] lambda_l2 is set=3.616974261103616e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.616974261103616e-08\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [0.03660297747120807, 0.07919622016053285, 0.09686051489658135, 0.16879507228199386, -0.05370081191673103]\nmean score: 0.06555079457871701\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.0022707801258294307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0022707801258294307\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n[LightGBM] [Warning] lambda_l2 is set=2.080522310686405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.080522310686405e-07\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.00102372\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.0022707801258294307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0022707801258294307\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n[LightGBM] [Warning] lambda_l2 is set=2.080522310686405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.080522310686405e-07\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[31]\tvalid_0's l2: 0.000651486\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.0022707801258294307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0022707801258294307\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n[LightGBM] [Warning] lambda_l2 is set=2.080522310686405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.080522310686405e-07\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.0022707801258294307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0022707801258294307\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n[LightGBM] [Warning] lambda_l2 is set=2.080522310686405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.080522310686405e-07\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[40]\tvalid_0's l2: 0.00045415\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.0022707801258294307, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0022707801258294307\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=6300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6300\n[LightGBM] [Warning] lambda_l2 is set=2.080522310686405e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.080522310686405e-07\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.0610703053947632, 0.07345716437570386, 0.052559054116467954, 0.11744001130191989, -0.10762119085056848]\nmean score: 0.039381068867657285\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=7.198141215465657e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.198141215465657e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200\n[LightGBM] [Warning] lambda_l2 is set=1.016505559540519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.016505559540519e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[28]\tvalid_0's l2: 0.00102388\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=7.198141215465657e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.198141215465657e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200\n[LightGBM] [Warning] lambda_l2 is set=1.016505559540519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.016505559540519e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[31]\tvalid_0's l2: 0.000651661\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=7.198141215465657e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.198141215465657e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200\n[LightGBM] [Warning] lambda_l2 is set=1.016505559540519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.016505559540519e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.000497779\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=7.198141215465657e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.198141215465657e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200\n[LightGBM] [Warning] lambda_l2 is set=1.016505559540519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.016505559540519e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[40]\tvalid_0's l2: 0.000454169\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=7.198141215465657e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.198141215465657e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200\n[LightGBM] [Warning] lambda_l2 is set=1.016505559540519e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.016505559540519e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.04911841807941118, 0.0845411940725732, 0.05959966947816268, 0.13218599386978566, -0.0349687512313365]\nmean score: 0.058095304853719255\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=0.0009837792429315863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009837792429315863\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500\n[LightGBM] [Warning] lambda_l2 is set=5.816907887933661e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.816907887933661e-05\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[95]\tvalid_0's l2: 0.00102297\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=0.0009837792429315863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009837792429315863\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500\n[LightGBM] [Warning] lambda_l2 is set=5.816907887933661e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.816907887933661e-05\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[31]\tvalid_0's l2: 0.000651295\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=0.0009837792429315863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009837792429315863\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500\n[LightGBM] [Warning] lambda_l2 is set=5.816907887933661e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.816907887933661e-05\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[7]\tvalid_0's l2: 0.000497771\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=0.0009837792429315863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009837792429315863\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500\n[LightGBM] [Warning] lambda_l2 is set=5.816907887933661e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.816907887933661e-05\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[37]\tvalid_0's l2: 0.000454146\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=0.0009837792429315863, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0009837792429315863\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500\n[LightGBM] [Warning] lambda_l2 is set=5.816907887933661e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.816907887933661e-05\n[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595286\ncv completed with scores: [0.04532843583522445, 0.07897372086495895, 0.05378872464983696, 0.11967324992276078, -0.11776484428689717]\nmean score: 0.0359998573971768\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=5.688031504377088e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.688031504377088e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n[LightGBM] [Warning] lambda_l2 is set=2.468654681449062e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.468654681449062e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[24]\tvalid_0's l2: 0.00102389\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=5.688031504377088e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.688031504377088e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n[LightGBM] [Warning] lambda_l2 is set=2.468654681449062e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.468654681449062e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[21]\tvalid_0's l2: 0.000651649\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=5.688031504377088e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.688031504377088e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n[LightGBM] [Warning] lambda_l2 is set=2.468654681449062e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.468654681449062e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[5]\tvalid_0's l2: 0.000497775\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=5.688031504377088e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.688031504377088e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n[LightGBM] [Warning] lambda_l2 is set=2.468654681449062e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.468654681449062e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[40]\tvalid_0's l2: 0.000454154\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=5.688031504377088e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.688031504377088e-08\n[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n[LightGBM] [Warning] min_data_in_leaf is set=4900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4900\n[LightGBM] [Warning] lambda_l2 is set=2.468654681449062e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.468654681449062e-06\n[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595284\ncv completed with scores: [0.03861608208169024, 0.08685280492989467, 0.05281229943417299, 0.1071299024694383, -0.10642013265494138]\nmean score: 0.03579819125205096\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=8.22929218918277e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.22929218918277e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n[LightGBM] [Warning] lambda_l2 is set=8.893696998553508e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.893696998553508e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[61]\tvalid_0's l2: 0.00102387\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=8.22929218918277e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.22929218918277e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n[LightGBM] [Warning] lambda_l2 is set=8.893696998553508e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.893696998553508e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[13]\tvalid_0's l2: 0.000651679\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=8.22929218918277e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.22929218918277e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n[LightGBM] [Warning] lambda_l2 is set=8.893696998553508e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.893696998553508e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[4]\tvalid_0's l2: 0.000497778\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=8.22929218918277e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.22929218918277e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n[LightGBM] [Warning] lambda_l2 is set=8.893696998553508e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.893696998553508e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[22]\tvalid_0's l2: 0.000454175\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=8.22929218918277e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.22929218918277e-07\n[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001\n[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300\n[LightGBM] [Warning] lambda_l2 is set=8.893696998553508e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.893696998553508e-08\n[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595283\ncv completed with scores: [-0.00926410293986851, 0.07744981751332687, 0.08700338720989868, 0.14417096617194594, -0.059891973364597825]\nmean score: 0.047893618918141034\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=2.73092068840497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.73092068840497e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n[LightGBM] [Warning] lambda_l2 is set=3.4686350588221645e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4686350588221645e-07\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[2]\tvalid_0's l2: 0.00102383\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=2.73092068840497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.73092068840497e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n[LightGBM] [Warning] lambda_l2 is set=3.4686350588221645e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4686350588221645e-07\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000651775\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=2.73092068840497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.73092068840497e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n[LightGBM] [Warning] lambda_l2 is set=3.4686350588221645e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4686350588221645e-07\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000497862\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=2.73092068840497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.73092068840497e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n[LightGBM] [Warning] lambda_l2 is set=3.4686350588221645e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4686350588221645e-07\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000454234\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=2.73092068840497e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.73092068840497e-05\n[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004\n[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100\n[LightGBM] [Warning] lambda_l2 is set=3.4686350588221645e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4686350588221645e-07\n[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595373\ncv completed with scores: [0.09050967364375438, 0.002002933410237138, 0.009829987157889597, 0.027840467539811887, -0.05711612820285681]\nmean score: 0.01461338670976724\n\n============== Fold 1 ================\nTrain Date range: 2017-01-04 to 2019-12-06\nValid Date range: 2019-12-09 to 2020-06-09\n[LightGBM] [Warning] lambda_l1 is set=1.3984879470560427e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3984879470560427e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3700\n[LightGBM] [Warning] lambda_l2 is set=3.1315989442272404e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1315989442272404e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[23]\tvalid_0's l2: 0.00102386\n\n============== Fold 2 ================\nTrain Date range: 2017-01-04 to 2020-06-09\nValid Date range: 2020-06-10 to 2020-12-03\n[LightGBM] [Warning] lambda_l1 is set=1.3984879470560427e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3984879470560427e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3700\n[LightGBM] [Warning] lambda_l2 is set=3.1315989442272404e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1315989442272404e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[21]\tvalid_0's l2: 0.000651589\n\n============== Fold 3 ================\nTrain Date range: 2017-01-04 to 2020-12-03\nValid Date range: 2020-12-04 to 2021-06-02\n[LightGBM] [Warning] lambda_l1 is set=1.3984879470560427e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3984879470560427e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3700\n[LightGBM] [Warning] lambda_l2 is set=3.1315989442272404e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1315989442272404e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[7]\tvalid_0's l2: 0.000497769\n\n============== Fold 4 ================\nTrain Date range: 2017-01-04 to 2021-06-02\nValid Date range: 2021-06-03 to 2021-11-26\n[LightGBM] [Warning] lambda_l1 is set=1.3984879470560427e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3984879470560427e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3700\n[LightGBM] [Warning] lambda_l2 is set=3.1315989442272404e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1315989442272404e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[15]\tvalid_0's l2: 0.000454162\n\n============== Fold 5 ================\nTrain Date range: 2017-01-04 to 2021-11-26\nValid Date range: 2021-11-29 to 2022-05-27\n[LightGBM] [Warning] lambda_l1 is set=1.3984879470560427e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3984879470560427e-05\n[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n[LightGBM] [Warning] min_data_in_leaf is set=3700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3700\n[LightGBM] [Warning] lambda_l2 is set=3.1315989442272404e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.1315989442272404e-08\n[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001\nTraining until validation scores don't improve for 20 rounds\nEarly stopping, best iteration is:\n[1]\tvalid_0's l2: 0.000595289\ncv completed with scores: [0.018402362308946686, 0.09555261587901187, 0.09025570347531181, 0.06464606240827413, -0.11208715424246134]\nmean score: 0.03135391796581662\n","output_type":"stream"}]},{"cell_type":"code","source":"# visualization = 30 trials\noptuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:31:35.102440Z","iopub.execute_input":"2022-06-27T06:31:35.103510Z","iopub.status.idle":"2022-06-27T06:31:35.124069Z","shell.execute_reply.started":"2022-06-27T06:31:35.103467Z","shell.execute_reply":"2022-06-27T06:31:35.122661Z"},"trusted":true},"execution_count":79,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"2a63236d-80f3-4ec4-9880-85e9e54519ba\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"2a63236d-80f3-4ec4-9880-85e9e54519ba\")) {                    Plotly.newPlot(                        \"2a63236d-80f3-4ec4-9880-85e9e54519ba\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.04486989108385261,0.03631208002144955,0.029160557392411378,0.06792313828675448,0.03915944318924147,0.03370693840184739,0.04653268189680757,0.0064708717836480245,0.011052919488045033,0.03533151044993836,0.07973683841477695,0.07208311118319644,0.030694931792786106,-0.012850861688104778,0.024903471965630426,0.028314959104291337,0.05586436380811564,0.01282670416501038,0.0566034908643737,0.0562386930354804,0.029291143394913444,0.06681176640741315,0.06555079457871701,0.039381068867657285,0.058095304853719255,0.0359998573971768,0.03579819125205096,0.047893618918141034,0.01461338670976724,0.03135391796581662],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],\"y\":[0.04486989108385261,0.04486989108385261,0.04486989108385261,0.06792313828675448,0.06792313828675448,0.06792313828675448,0.06792313828675448,0.06792313828675448,0.06792313828675448,0.06792313828675448,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695,0.07973683841477695],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('2a63236d-80f3-4ec4-9880-85e9e54519ba');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"# visualization - 20 trials\noptuna.visualization.plot_optimization_history(study)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:08:51.962377Z","iopub.execute_input":"2022-06-27T06:08:51.964272Z","iopub.status.idle":"2022-06-27T06:08:51.995284Z","shell.execute_reply.started":"2022-06-27T06:08:51.964208Z","shell.execute_reply":"2022-06-27T06:08:51.994003Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"46f5d84f-e340-4bde-954f-dadf008bfe71\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"46f5d84f-e340-4bde-954f-dadf008bfe71\")) {                    Plotly.newPlot(                        \"46f5d84f-e340-4bde-954f-dadf008bfe71\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[-0.005768342136612248,0.030003643322130052,0.040411691133317884,0.02945660786728152,0.0358117973465149,0.002586562698459105,0.00585308401372984,-0.0028362275352600912,0.03896954653631661,0.035551864145890254,0.04305134505339404,0.041488364909008986,0.04898836767005077,0.03486105243697299,0.05693381303682345,0.05384348450931762,0.06169225760936149,0.06163957546021831,0.025701382808343932,-0.0015748301131364357],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"y\":[-0.005768342136612248,0.030003643322130052,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.040411691133317884,0.04305134505339404,0.04305134505339404,0.04898836767005077,0.04898836767005077,0.05693381303682345,0.05693381303682345,0.06169225760936149,0.06169225760936149,0.06169225760936149,0.06169225760936149],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('46f5d84f-e340-4bde-954f-dadf008bfe71');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"study.best_trial","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:10:10.687232Z","iopub.execute_input":"2022-06-27T06:10:10.687634Z","iopub.status.idle":"2022-06-27T06:10:10.695560Z","shell.execute_reply.started":"2022-06-27T06:10:10.687587Z","shell.execute_reply":"2022-06-27T06:10:10.694670Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"FrozenTrial(number=16, values=[0.06169225760936149], datetime_start=datetime.datetime(2022, 6, 27, 6, 6, 34, 545449), datetime_complete=datetime.datetime(2022, 6, 27, 6, 7, 2, 247222), params={'n_estimators': 4000, 'learning_rate': 0.004379132199629696, 'num_leaves': 63, 'max_depth': 4, 'min_data_in_leaf': 4100, 'lambda_l1': 1.1236255817173426e-05, 'lambda_l2': 0.0001854961158379152, 'bagging_fraction': 0.5, 'feature_fraction': 0.4}, distributions={'n_estimators': CategoricalDistribution(choices=(4000,)), 'learning_rate': LogUniformDistribution(high=0.5, low=0.001), 'num_leaves': IntUniformDistribution(high=256, low=2, step=1), 'max_depth': IntUniformDistribution(high=12, low=3, step=1), 'min_data_in_leaf': IntUniformDistribution(high=10000, low=200, step=100), 'lambda_l1': LogUniformDistribution(high=10.0, low=1e-08), 'lambda_l2': LogUniformDistribution(high=10.0, low=1e-08), 'bagging_fraction': DiscreteUniformDistribution(high=0.9, low=0.2, q=0.1), 'feature_fraction': DiscreteUniformDistribution(high=0.9, low=0.2, q=0.1)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=16, state=TrialState.COMPLETE, value=None)"},"metadata":{}}]},{"cell_type":"code","source":"study.trials_dataframe().sort_values('value', ascending=False).drop(\n        columns=['datetime_start', 'datetime_complete', 'duration'])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:43:03.296491Z","iopub.execute_input":"2022-06-27T06:43:03.297035Z","iopub.status.idle":"2022-06-27T06:43:03.336507Z","shell.execute_reply.started":"2022-06-27T06:43:03.296992Z","shell.execute_reply":"2022-06-27T06:43:03.335351Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"    number     value  params_bagging_fraction  params_feature_fraction  \\\n10      10  0.079737                      0.2                      0.4   \n11      11  0.072083                      0.2                      0.4   \n3        3  0.067923                      0.4                      0.4   \n21      21  0.066812                      0.4                      0.4   \n22      22  0.065551                      0.4                      0.4   \n24      24  0.058095                      0.2                      0.3   \n18      18  0.056603                      0.9                      0.3   \n19      19  0.056239                      0.2                      0.3   \n16      16  0.055864                      0.3                      0.3   \n27      27  0.047894                      0.2                      0.6   \n6        6  0.046533                      0.6                      0.2   \n0        0  0.044870                      0.6                      0.2   \n23      23  0.039381                      0.3                      0.5   \n4        4  0.039159                      0.5                      0.7   \n1        1  0.036312                      0.8                      0.2   \n25      25  0.036000                      0.5                      0.4   \n26      26  0.035798                      0.3                      0.5   \n9        9  0.035332                      0.7                      0.7   \n5        5  0.033707                      0.4                      0.2   \n29      29  0.031354                      0.6                      0.4   \n12      12  0.030695                      0.2                      0.4   \n20      20  0.029291                      0.3                      0.7   \n2        2  0.029161                      0.3                      0.4   \n15      15  0.028315                      0.2                      0.5   \n14      14  0.024903                      0.3                      0.6   \n28      28  0.014613                      0.4                      0.3   \n17      17  0.012827                      0.4                      0.6   \n8        8  0.011053                      0.8                      0.9   \n7        7  0.006471                      0.5                      0.9   \n13      13 -0.012851                      0.2                      0.5   \n\n    params_lambda_l1  params_lambda_l2  params_learning_rate  \\\n10      3.576535e-08      1.961992e-08              0.001035   \n11      3.502459e-08      1.068109e-08              0.001041   \n3       7.762357e-05      5.595487e-08              0.001775   \n21      5.898527e-05      4.773771e-08              0.001671   \n22      1.014514e-07      3.616974e-08              0.001004   \n24      7.198141e-05      1.016506e-08              0.001624   \n18      2.424806e-07      1.207526e-07              0.003387   \n19      1.863228e-06      1.636523e-06              0.001912   \n16      3.442835e-06      8.866460e-06              0.001088   \n27      8.229292e-07      8.893697e-08              0.001556   \n6       2.146917e-04      1.139459e-03              0.011898   \n0       1.531368e-05      1.448930e-08              0.010084   \n23      2.270780e-03      2.080522e-07              0.002763   \n4       1.765384e-03      9.374852e-06              0.008381   \n1       2.626274e-01      6.271164e-04              0.013176   \n25      9.837792e-04      5.816908e-05              0.004219   \n26      5.688032e-08      2.468655e-06              0.002119   \n9       4.561714e-02      2.272810e+00              0.001935   \n5       1.239592e-07      4.810290e-03              0.006951   \n29      1.398488e-05      3.131599e-08              0.005851   \n12      1.726981e-08      7.130827e-07              0.001020   \n20      4.539665e+00      4.026335e-02              0.005082   \n2       6.851098e-06      9.850624e-01              0.150465   \n15      2.362038e-08      2.394505e-07              0.046215   \n14      7.712668e-07      1.158763e-08              0.002836   \n28      2.730921e-05      3.468635e-07              0.039285   \n17      1.104079e-08      1.631746e-05              0.483253   \n8       1.515106e-02      1.229513e-04              0.020602   \n7       7.069947e-01      1.012405e-01              0.004601   \n13      3.075211e-07      1.046554e-06              0.076207   \n\n    params_max_depth  params_min_data_in_leaf  params_n_estimators  \\\n10                 3                     3600                 4000   \n11                 3                     2800                 4000   \n3                  3                     5600                 4000   \n21                 3                     5400                 4000   \n22                 3                     5400                 4000   \n24                 3                     3200                 4000   \n18                 4                     6600                 4000   \n19                 6                     4300                 4000   \n16                 5                     4000                 4000   \n27                 3                     3300                 4000   \n6                  8                      300                 4000   \n0                 10                     9000                 4000   \n23                 4                     6300                 4000   \n4                  4                     4200                 4000   \n1                  7                     9400                 4000   \n25                 5                     7500                 4000   \n26                 4                     4900                 4000   \n9                  9                     6400                 4000   \n5                  5                     9200                 4000   \n29                 9                     3700                 4000   \n12                12                     2600                 4000   \n20                 6                     1500                 4000   \n2                  4                     8100                 4000   \n15                 3                      700                 4000   \n14                 5                     2900                 4000   \n28                 8                     2100                 4000   \n17                11                     1600                 4000   \n8                  6                     9400                 4000   \n7                  7                     9600                 4000   \n13                 3                     2700                 4000   \n\n    params_num_leaves     state  \n10                149  COMPLETE  \n11                161  COMPLETE  \n3                 116  COMPLETE  \n21                118  COMPLETE  \n22                116  COMPLETE  \n24                194  COMPLETE  \n18                 97  COMPLETE  \n19                 58  COMPLETE  \n16                143  COMPLETE  \n27                115  COMPLETE  \n6                 240  COMPLETE  \n0                  27  COMPLETE  \n23                144  COMPLETE  \n4                  47  COMPLETE  \n1                  94  COMPLETE  \n25                146  COMPLETE  \n26                 72  COMPLETE  \n9                 128  COMPLETE  \n5                 214  COMPLETE  \n29                191  COMPLETE  \n12                173  COMPLETE  \n20                244  COMPLETE  \n2                  84  COMPLETE  \n15                209  COMPLETE  \n14                158  COMPLETE  \n28                103  COMPLETE  \n17                202  COMPLETE  \n8                  11  COMPLETE  \n7                 176  COMPLETE  \n13                168  COMPLETE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>params_bagging_fraction</th>\n      <th>params_feature_fraction</th>\n      <th>params_lambda_l1</th>\n      <th>params_lambda_l2</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_min_data_in_leaf</th>\n      <th>params_n_estimators</th>\n      <th>params_num_leaves</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.079737</td>\n      <td>0.2</td>\n      <td>0.4</td>\n      <td>3.576535e-08</td>\n      <td>1.961992e-08</td>\n      <td>0.001035</td>\n      <td>3</td>\n      <td>3600</td>\n      <td>4000</td>\n      <td>149</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.072083</td>\n      <td>0.2</td>\n      <td>0.4</td>\n      <td>3.502459e-08</td>\n      <td>1.068109e-08</td>\n      <td>0.001041</td>\n      <td>3</td>\n      <td>2800</td>\n      <td>4000</td>\n      <td>161</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.067923</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>7.762357e-05</td>\n      <td>5.595487e-08</td>\n      <td>0.001775</td>\n      <td>3</td>\n      <td>5600</td>\n      <td>4000</td>\n      <td>116</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>21</td>\n      <td>0.066812</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>5.898527e-05</td>\n      <td>4.773771e-08</td>\n      <td>0.001671</td>\n      <td>3</td>\n      <td>5400</td>\n      <td>4000</td>\n      <td>118</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>22</td>\n      <td>0.065551</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>1.014514e-07</td>\n      <td>3.616974e-08</td>\n      <td>0.001004</td>\n      <td>3</td>\n      <td>5400</td>\n      <td>4000</td>\n      <td>116</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>24</td>\n      <td>0.058095</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>7.198141e-05</td>\n      <td>1.016506e-08</td>\n      <td>0.001624</td>\n      <td>3</td>\n      <td>3200</td>\n      <td>4000</td>\n      <td>194</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.056603</td>\n      <td>0.9</td>\n      <td>0.3</td>\n      <td>2.424806e-07</td>\n      <td>1.207526e-07</td>\n      <td>0.003387</td>\n      <td>4</td>\n      <td>6600</td>\n      <td>4000</td>\n      <td>97</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>0.056239</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>1.863228e-06</td>\n      <td>1.636523e-06</td>\n      <td>0.001912</td>\n      <td>6</td>\n      <td>4300</td>\n      <td>4000</td>\n      <td>58</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.055864</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>3.442835e-06</td>\n      <td>8.866460e-06</td>\n      <td>0.001088</td>\n      <td>5</td>\n      <td>4000</td>\n      <td>4000</td>\n      <td>143</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>27</td>\n      <td>0.047894</td>\n      <td>0.2</td>\n      <td>0.6</td>\n      <td>8.229292e-07</td>\n      <td>8.893697e-08</td>\n      <td>0.001556</td>\n      <td>3</td>\n      <td>3300</td>\n      <td>4000</td>\n      <td>115</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.046533</td>\n      <td>0.6</td>\n      <td>0.2</td>\n      <td>2.146917e-04</td>\n      <td>1.139459e-03</td>\n      <td>0.011898</td>\n      <td>8</td>\n      <td>300</td>\n      <td>4000</td>\n      <td>240</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.044870</td>\n      <td>0.6</td>\n      <td>0.2</td>\n      <td>1.531368e-05</td>\n      <td>1.448930e-08</td>\n      <td>0.010084</td>\n      <td>10</td>\n      <td>9000</td>\n      <td>4000</td>\n      <td>27</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>23</td>\n      <td>0.039381</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>2.270780e-03</td>\n      <td>2.080522e-07</td>\n      <td>0.002763</td>\n      <td>4</td>\n      <td>6300</td>\n      <td>4000</td>\n      <td>144</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.039159</td>\n      <td>0.5</td>\n      <td>0.7</td>\n      <td>1.765384e-03</td>\n      <td>9.374852e-06</td>\n      <td>0.008381</td>\n      <td>4</td>\n      <td>4200</td>\n      <td>4000</td>\n      <td>47</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.036312</td>\n      <td>0.8</td>\n      <td>0.2</td>\n      <td>2.626274e-01</td>\n      <td>6.271164e-04</td>\n      <td>0.013176</td>\n      <td>7</td>\n      <td>9400</td>\n      <td>4000</td>\n      <td>94</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>25</td>\n      <td>0.036000</td>\n      <td>0.5</td>\n      <td>0.4</td>\n      <td>9.837792e-04</td>\n      <td>5.816908e-05</td>\n      <td>0.004219</td>\n      <td>5</td>\n      <td>7500</td>\n      <td>4000</td>\n      <td>146</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>0.035798</td>\n      <td>0.3</td>\n      <td>0.5</td>\n      <td>5.688032e-08</td>\n      <td>2.468655e-06</td>\n      <td>0.002119</td>\n      <td>4</td>\n      <td>4900</td>\n      <td>4000</td>\n      <td>72</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.035332</td>\n      <td>0.7</td>\n      <td>0.7</td>\n      <td>4.561714e-02</td>\n      <td>2.272810e+00</td>\n      <td>0.001935</td>\n      <td>9</td>\n      <td>6400</td>\n      <td>4000</td>\n      <td>128</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.033707</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>1.239592e-07</td>\n      <td>4.810290e-03</td>\n      <td>0.006951</td>\n      <td>5</td>\n      <td>9200</td>\n      <td>4000</td>\n      <td>214</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>29</td>\n      <td>0.031354</td>\n      <td>0.6</td>\n      <td>0.4</td>\n      <td>1.398488e-05</td>\n      <td>3.131599e-08</td>\n      <td>0.005851</td>\n      <td>9</td>\n      <td>3700</td>\n      <td>4000</td>\n      <td>191</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.030695</td>\n      <td>0.2</td>\n      <td>0.4</td>\n      <td>1.726981e-08</td>\n      <td>7.130827e-07</td>\n      <td>0.001020</td>\n      <td>12</td>\n      <td>2600</td>\n      <td>4000</td>\n      <td>173</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>0.029291</td>\n      <td>0.3</td>\n      <td>0.7</td>\n      <td>4.539665e+00</td>\n      <td>4.026335e-02</td>\n      <td>0.005082</td>\n      <td>6</td>\n      <td>1500</td>\n      <td>4000</td>\n      <td>244</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.029161</td>\n      <td>0.3</td>\n      <td>0.4</td>\n      <td>6.851098e-06</td>\n      <td>9.850624e-01</td>\n      <td>0.150465</td>\n      <td>4</td>\n      <td>8100</td>\n      <td>4000</td>\n      <td>84</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.028315</td>\n      <td>0.2</td>\n      <td>0.5</td>\n      <td>2.362038e-08</td>\n      <td>2.394505e-07</td>\n      <td>0.046215</td>\n      <td>3</td>\n      <td>700</td>\n      <td>4000</td>\n      <td>209</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.024903</td>\n      <td>0.3</td>\n      <td>0.6</td>\n      <td>7.712668e-07</td>\n      <td>1.158763e-08</td>\n      <td>0.002836</td>\n      <td>5</td>\n      <td>2900</td>\n      <td>4000</td>\n      <td>158</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>28</td>\n      <td>0.014613</td>\n      <td>0.4</td>\n      <td>0.3</td>\n      <td>2.730921e-05</td>\n      <td>3.468635e-07</td>\n      <td>0.039285</td>\n      <td>8</td>\n      <td>2100</td>\n      <td>4000</td>\n      <td>103</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.012827</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>1.104079e-08</td>\n      <td>1.631746e-05</td>\n      <td>0.483253</td>\n      <td>11</td>\n      <td>1600</td>\n      <td>4000</td>\n      <td>202</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.011053</td>\n      <td>0.8</td>\n      <td>0.9</td>\n      <td>1.515106e-02</td>\n      <td>1.229513e-04</td>\n      <td>0.020602</td>\n      <td>6</td>\n      <td>9400</td>\n      <td>4000</td>\n      <td>11</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>0.006471</td>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>7.069947e-01</td>\n      <td>1.012405e-01</td>\n      <td>0.004601</td>\n      <td>7</td>\n      <td>9600</td>\n      <td>4000</td>\n      <td>176</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>-0.012851</td>\n      <td>0.2</td>\n      <td>0.5</td>\n      <td>3.075211e-07</td>\n      <td>1.046554e-06</td>\n      <td>0.076207</td>\n      <td>3</td>\n      <td>2700</td>\n      <td>4000</td>\n      <td>168</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"study.trials_dataframe().sort_values('value', ascending=False).drop(\n        columns=['datetime_start', 'datetime_complete', 'duration'])","metadata":{"execution":{"iopub.status.busy":"2022-06-27T06:12:27.071813Z","iopub.execute_input":"2022-06-27T06:12:27.072285Z","iopub.status.idle":"2022-06-27T06:12:27.103705Z","shell.execute_reply.started":"2022-06-27T06:12:27.072247Z","shell.execute_reply":"2022-06-27T06:12:27.102343Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"    number     value  params_bagging_fraction  params_feature_fraction  \\\n16      16  0.061692                      0.5                      0.4   \n17      17  0.061640                      0.5                      0.4   \n14      14  0.056934                      0.4                      0.4   \n15      15  0.053843                      0.4                      0.4   \n12      12  0.048988                      0.2                      0.3   \n10      10  0.043051                      0.2                      0.3   \n11      11  0.041488                      0.2                      0.3   \n2        2  0.040412                      0.3                      0.3   \n8        8  0.038970                      0.7                      0.5   \n4        4  0.035812                      0.8                      0.3   \n9        9  0.035552                      0.7                      0.2   \n13      13  0.034861                      0.2                      0.2   \n1        1  0.030004                      0.4                      0.6   \n3        3  0.029457                      0.7                      0.5   \n18      18  0.025701                      0.5                      0.9   \n6        6  0.005853                      0.8                      0.8   \n5        5  0.002587                      0.6                      0.7   \n19      19 -0.001575                      0.5                      0.4   \n7        7 -0.002836                      0.9                      0.5   \n0        0 -0.005768                      0.3                      0.7   \n\n    params_lambda_l1  params_lambda_l2  params_learning_rate  \\\n16      1.123626e-05      1.854961e-04              0.004379   \n17      4.508603e+00      2.826215e-04              0.003919   \n14      2.370974e-05      5.580635e-01              0.003284   \n15      1.405765e-05      2.313517e-01              0.003822   \n12      1.927395e-04      3.463036e+00              0.001244   \n10      1.183687e-04      9.497079e+00              0.001427   \n11      2.103966e-04      4.548742e+00              0.001559   \n2       7.497965e-07      2.263153e-06              0.010433   \n8       2.872394e-08      1.710006e-08              0.037880   \n4       3.874734e-07      3.038682e-07              0.106937   \n9       2.461304e-01      2.776429e-07              0.014005   \n13      3.006573e-03      8.402764e+00              0.001003   \n1       1.412777e-06      7.098101e-06              0.008333   \n3       1.163532e-04      1.426696e-02              0.012481   \n18      1.287743e+00      1.771267e-04              0.005492   \n6       6.983730e-03      1.119276e-02              0.002660   \n5       1.128654e-08      8.894924e-08              0.031935   \n19      5.483196e-02      4.125114e-04              0.020277   \n7       1.766641e-06      1.919398e-07              0.217601   \n0       1.488656e-07      1.339220e-01              0.100458   \n\n    params_max_depth  params_min_data_in_leaf  params_n_estimators  \\\n16                 4                     4100                 4000   \n17                 5                     4600                 4000   \n14                 5                     3800                 4000   \n15                 4                     3700                 4000   \n12                12                     2500                 4000   \n10                12                     3000                 4000   \n11                12                     3100                 4000   \n2                 11                     6200                 4000   \n8                  7                     6000                 4000   \n4                  9                     6600                 4000   \n9                  3                     8200                 4000   \n13                12                      400                 4000   \n1                  8                     9300                 4000   \n3                  7                     7500                 4000   \n18                 5                     4800                 4000   \n6                  9                     8700                 4000   \n5                  8                     9100                 4000   \n19                 5                     1500                 4000   \n7                 10                     8600                 4000   \n0                  9                     8500                 4000   \n\n    params_num_leaves     state  \n16                 63  COMPLETE  \n17                 56  COMPLETE  \n14                 72  COMPLETE  \n15                 62  COMPLETE  \n12                141  COMPLETE  \n10                 92  COMPLETE  \n11                118  COMPLETE  \n2                  76  COMPLETE  \n8                 153  COMPLETE  \n4                  15  COMPLETE  \n9                  27  COMPLETE  \n13                161  COMPLETE  \n1                 203  COMPLETE  \n3                 215  COMPLETE  \n18                 52  COMPLETE  \n6                 101  COMPLETE  \n5                  32  COMPLETE  \n19                  3  COMPLETE  \n7                 233  COMPLETE  \n0                 209  COMPLETE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>params_bagging_fraction</th>\n      <th>params_feature_fraction</th>\n      <th>params_lambda_l1</th>\n      <th>params_lambda_l2</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_min_data_in_leaf</th>\n      <th>params_n_estimators</th>\n      <th>params_num_leaves</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>0.061692</td>\n      <td>0.5</td>\n      <td>0.4</td>\n      <td>1.123626e-05</td>\n      <td>1.854961e-04</td>\n      <td>0.004379</td>\n      <td>4</td>\n      <td>4100</td>\n      <td>4000</td>\n      <td>63</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17</td>\n      <td>0.061640</td>\n      <td>0.5</td>\n      <td>0.4</td>\n      <td>4.508603e+00</td>\n      <td>2.826215e-04</td>\n      <td>0.003919</td>\n      <td>5</td>\n      <td>4600</td>\n      <td>4000</td>\n      <td>56</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>0.056934</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>2.370974e-05</td>\n      <td>5.580635e-01</td>\n      <td>0.003284</td>\n      <td>5</td>\n      <td>3800</td>\n      <td>4000</td>\n      <td>72</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>0.053843</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>1.405765e-05</td>\n      <td>2.313517e-01</td>\n      <td>0.003822</td>\n      <td>4</td>\n      <td>3700</td>\n      <td>4000</td>\n      <td>62</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>0.048988</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>1.927395e-04</td>\n      <td>3.463036e+00</td>\n      <td>0.001244</td>\n      <td>12</td>\n      <td>2500</td>\n      <td>4000</td>\n      <td>141</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>0.043051</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>1.183687e-04</td>\n      <td>9.497079e+00</td>\n      <td>0.001427</td>\n      <td>12</td>\n      <td>3000</td>\n      <td>4000</td>\n      <td>92</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>0.041488</td>\n      <td>0.2</td>\n      <td>0.3</td>\n      <td>2.103966e-04</td>\n      <td>4.548742e+00</td>\n      <td>0.001559</td>\n      <td>12</td>\n      <td>3100</td>\n      <td>4000</td>\n      <td>118</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.040412</td>\n      <td>0.3</td>\n      <td>0.3</td>\n      <td>7.497965e-07</td>\n      <td>2.263153e-06</td>\n      <td>0.010433</td>\n      <td>11</td>\n      <td>6200</td>\n      <td>4000</td>\n      <td>76</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.038970</td>\n      <td>0.7</td>\n      <td>0.5</td>\n      <td>2.872394e-08</td>\n      <td>1.710006e-08</td>\n      <td>0.037880</td>\n      <td>7</td>\n      <td>6000</td>\n      <td>4000</td>\n      <td>153</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.035812</td>\n      <td>0.8</td>\n      <td>0.3</td>\n      <td>3.874734e-07</td>\n      <td>3.038682e-07</td>\n      <td>0.106937</td>\n      <td>9</td>\n      <td>6600</td>\n      <td>4000</td>\n      <td>15</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>0.035552</td>\n      <td>0.7</td>\n      <td>0.2</td>\n      <td>2.461304e-01</td>\n      <td>2.776429e-07</td>\n      <td>0.014005</td>\n      <td>3</td>\n      <td>8200</td>\n      <td>4000</td>\n      <td>27</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>0.034861</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>3.006573e-03</td>\n      <td>8.402764e+00</td>\n      <td>0.001003</td>\n      <td>12</td>\n      <td>400</td>\n      <td>4000</td>\n      <td>161</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.030004</td>\n      <td>0.4</td>\n      <td>0.6</td>\n      <td>1.412777e-06</td>\n      <td>7.098101e-06</td>\n      <td>0.008333</td>\n      <td>8</td>\n      <td>9300</td>\n      <td>4000</td>\n      <td>203</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.029457</td>\n      <td>0.7</td>\n      <td>0.5</td>\n      <td>1.163532e-04</td>\n      <td>1.426696e-02</td>\n      <td>0.012481</td>\n      <td>7</td>\n      <td>7500</td>\n      <td>4000</td>\n      <td>215</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>0.025701</td>\n      <td>0.5</td>\n      <td>0.9</td>\n      <td>1.287743e+00</td>\n      <td>1.771267e-04</td>\n      <td>0.005492</td>\n      <td>5</td>\n      <td>4800</td>\n      <td>4000</td>\n      <td>52</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>0.005853</td>\n      <td>0.8</td>\n      <td>0.8</td>\n      <td>6.983730e-03</td>\n      <td>1.119276e-02</td>\n      <td>0.002660</td>\n      <td>9</td>\n      <td>8700</td>\n      <td>4000</td>\n      <td>101</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>0.002587</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>1.128654e-08</td>\n      <td>8.894924e-08</td>\n      <td>0.031935</td>\n      <td>8</td>\n      <td>9100</td>\n      <td>4000</td>\n      <td>32</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19</td>\n      <td>-0.001575</td>\n      <td>0.5</td>\n      <td>0.4</td>\n      <td>5.483196e-02</td>\n      <td>4.125114e-04</td>\n      <td>0.020277</td>\n      <td>5</td>\n      <td>1500</td>\n      <td>4000</td>\n      <td>3</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>-0.002836</td>\n      <td>0.9</td>\n      <td>0.5</td>\n      <td>1.766641e-06</td>\n      <td>1.919398e-07</td>\n      <td>0.217601</td>\n      <td>10</td>\n      <td>8600</td>\n      <td>4000</td>\n      <td>233</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>-0.005768</td>\n      <td>0.3</td>\n      <td>0.7</td>\n      <td>1.488656e-07</td>\n      <td>1.339220e-01</td>\n      <td>0.100458</td>\n      <td>9</td>\n      <td>8500</td>\n      <td>4000</td>\n      <td>209</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}