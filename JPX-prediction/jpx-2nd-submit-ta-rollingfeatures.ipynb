{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bff4ed73",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:07.074105Z",
     "iopub.status.busy": "2022-06-10T07:18:07.073478Z",
     "iopub.status.idle": "2022-06-10T07:18:07.086702Z",
     "shell.execute_reply": "2022-06-10T07:18:07.085848Z"
    },
    "papermill": {
     "duration": 0.026599,
     "end_time": "2022-06-10T07:18:07.088733",
     "exception": false,
     "start_time": "2022-06-10T07:18:07.062134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f34277",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:07.102537Z",
     "iopub.status.busy": "2022-06-10T07:18:07.101978Z",
     "iopub.status.idle": "2022-06-10T07:18:39.666162Z",
     "shell.execute_reply": "2022-06-10T07:18:39.664054Z"
    },
    "papermill": {
     "duration": 32.577331,
     "end_time": "2022-06-10T07:18:39.672443",
     "exception": false,
     "start_time": "2022-06-10T07:18:07.095112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/talib-package/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from talib-binary==0.4.19) (1.21.6)\r\n",
      "Installing collected packages: talib-binary\r\n",
      "Successfully installed talib-binary-0.4.19\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install ../input/talib-package/talib_binary-0.4.19-cp37-cp37m-manylinux1_x86_64.whl\n",
    "import talib as ta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31a5cb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:39.691676Z",
     "iopub.status.busy": "2022-06-10T07:18:39.691231Z",
     "iopub.status.idle": "2022-06-10T07:18:42.720080Z",
     "shell.execute_reply": "2022-06-10T07:18:42.718721Z"
    },
    "papermill": {
     "duration": 3.040282,
     "end_time": "2022-06-10T07:18:42.722968",
     "exception": false,
     "start_time": "2022-06-10T07:18:39.682686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, MinMaxScaler\n",
    "import missingno as msno\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from pylab import rcParams\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import ta\n",
    "from talib import abstract\n",
    "\n",
    "\n",
    "import time\n",
    "import gc\n",
    "import sys\n",
    "\n",
    "# sys.path.insert(0, '../input/jpx-local-api')\n",
    "# from local_api import local_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1f9a7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:42.739914Z",
     "iopub.status.busy": "2022-06-10T07:18:42.738852Z",
     "iopub.status.idle": "2022-06-10T07:18:51.712896Z",
     "shell.execute_reply": "2022-06-10T07:18:51.711803Z"
    },
    "papermill": {
     "duration": 8.985423,
     "end_time": "2022-06-10T07:18:51.715669",
     "exception": false,
     "start_time": "2022-06-10T07:18:42.730246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/train_files/stock_prices.csv')\n",
    "# display(data)\n",
    "train = data.copy()\n",
    "\n",
    "# using supplement data as test data\n",
    "supp_data = pd.read_csv('/kaggle/input/jpx-tokyo-stock-exchange-prediction/supplemental_files/stock_prices.csv')\n",
    "\n",
    "# train_with_supp = pd.concat([train, supp_data]).reset_index(drop=True)\n",
    "train_with_supp = train.copy()\n",
    "# train_with_supp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b78a2ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:51.731507Z",
     "iopub.status.busy": "2022-06-10T07:18:51.731111Z",
     "iopub.status.idle": "2022-06-10T07:18:51.735723Z",
     "shell.execute_reply": "2022-06-10T07:18:51.734647Z"
    },
    "papermill": {
     "duration": 0.014964,
     "end_time": "2022-06-10T07:18:51.737733",
     "exception": false,
     "start_time": "2022-06-10T07:18:51.722769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def time_elapsed(t0):\n",
    "#     t1 = time.time()\n",
    "#     print(time.time() - t0)\n",
    "#     return t1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1c669",
   "metadata": {
    "papermill": {
     "duration": 0.006467,
     "end_time": "2022-06-10T07:18:51.751290",
     "exception": false,
     "start_time": "2022-06-10T07:18:51.744823",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "SecuritiesCode 에 따라 인덱싱하는 것이 시간 소요가 너무 크다.  \n",
    "미리 Data를 종목마다 쪼개서 넣어 놓는게 좋겠다. - > 리스트 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27c8336a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:18:51.767346Z",
     "iopub.status.busy": "2022-06-10T07:18:51.766285Z",
     "iopub.status.idle": "2022-06-10T07:19:01.975386Z",
     "shell.execute_reply": "2022-06-10T07:19:01.974301Z"
    },
    "papermill": {
     "duration": 10.220028,
     "end_time": "2022-06-10T07:19:01.978063",
     "exception": false,
     "start_time": "2022-06-10T07:18:51.758035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def divideSecurities(df):\n",
    "    sec_list = []\n",
    "#     print('Divide securities individually..')\n",
    "    for code in np.sort(df.SecuritiesCode.unique()):\n",
    "        sec_list.append(df.loc[df.SecuritiesCode == code, :].reset_index(drop=True))\n",
    "    return sec_list\n",
    "\n",
    "sec_list = divideSecurities(train_with_supp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c550fd06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:01.994461Z",
     "iopub.status.busy": "2022-06-10T07:19:01.994056Z",
     "iopub.status.idle": "2022-06-10T07:19:02.004099Z",
     "shell.execute_reply": "2022-06-10T07:19:02.003386Z"
    },
    "papermill": {
     "duration": 0.020518,
     "end_time": "2022-06-10T07:19:02.005975",
     "exception": false,
     "start_time": "2022-06-10T07:19:01.985457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features_train(input_df, sec_list):\n",
    "    df_list = []\n",
    "    for df in sec_list:\n",
    "        \n",
    "        # shadows\n",
    "        df['upper_shadow'] = df['High'] - np.maximum(df['Open'], df['Close'])\n",
    "        df['lower_shadow'] = np.minimum(df['Open'], df['Close']) - df['Low']\n",
    "        \n",
    "\n",
    "        \n",
    "        # lagged features\n",
    "        # 날짜 단위이므로 7일전, 30일전, 180일전, 360일전 \n",
    "        # lagged close, target (target 은 정확히 무엇? return인가)\n",
    "        \n",
    "        # lagged feature 계산하기 전 결측치 채워넣기\n",
    "        df = df.fillna(method='ffill')\n",
    "        \n",
    "\n",
    "        \n",
    "        # TA-lib features - RSI, EMA 7-90\n",
    "        df['RSI'] = ta.RSI(df['Close'])\n",
    "        df['EMA7'] = ta.EMA(df['Close'], 7)\n",
    "        df['EMA15'] = ta.EMA(df['Close'], 15)\n",
    "        df['EMA30'] = ta.EMA(df['Close'], 30)\n",
    "        df['EMA90'] = ta.EMA(df['Close'], 90)\n",
    "        \n",
    "\n",
    "        \n",
    "#         for indicator in ta.get_function_groups()['Pattern Recognition']:\n",
    "#             df[str(indicator)] = getattr(ta,str(indicator))(df.Open, df.High, df.Low, df.Close)\n",
    "\n",
    "\n",
    "        # fill ema features by backward -- 이렇게 채워진 것은 false data 이므로 일단 test 해보고 없애는 것을 검토하자.\n",
    "        df = df.fillna(method='bfill')\n",
    "\n",
    "    \n",
    "        # volatility\n",
    "        \n",
    "        df_list.append(df)\n",
    "\n",
    "        \n",
    "    df_feature_added = pd.concat(df_list)\n",
    "    \n",
    "    return df_feature_added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ab0890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:02.021322Z",
     "iopub.status.busy": "2022-06-10T07:19:02.020827Z",
     "iopub.status.idle": "2022-06-10T07:19:19.095715Z",
     "shell.execute_reply": "2022-06-10T07:19:19.094638Z"
    },
    "papermill": {
     "duration": 17.085412,
     "end_time": "2022-06-10T07:19:19.098368",
     "exception": false,
     "start_time": "2022-06-10T07:19:02.012956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add feature to data\n",
    "\n",
    "df_added = add_features_train(train_with_supp, sec_list)\n",
    "# df_added.to_csv('train_with_supp_feature_added.csv', index=False)\n",
    "\n",
    "# load data\n",
    "# df_added = pd.read_csv('/kaggle/input/train-with-supp-feature-added-v1-all-cdl/train_with_supp_feature_added.csv')\n",
    "\n",
    "# df_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13617ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:19.114807Z",
     "iopub.status.busy": "2022-06-10T07:19:19.114071Z",
     "iopub.status.idle": "2022-06-10T07:19:19.127407Z",
     "shell.execute_reply": "2022-06-10T07:19:19.126322Z"
    },
    "papermill": {
     "duration": 0.02422,
     "end_time": "2022-06-10T07:19:19.129750",
     "exception": false,
     "start_time": "2022-06-10T07:19:19.105530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features_infer(input_df, close_df): #input df 는 price 데이터\n",
    "    \n",
    "    df_list = []\n",
    "    sec_list = divideSecurities(input_df)\n",
    "    \n",
    "    close_list = divideSecurities(close_df)\n",
    "    \n",
    "    for i in range(len(sec_list)):\n",
    "        \n",
    "        \n",
    "        close = close_list[i] #.loc[close_df.SecuritiesCode == code, :].fillna(method='ffill')\n",
    "        df = sec_list[i]\n",
    "#         # test data의 open, high, low, close 중 nan 있으면 이전 값에서 가져와 채움\n",
    "        if df.loc[:, ['Open', 'High', 'Low', 'Close']].isna().any().any():\n",
    "#             display(df)\n",
    "#             display(close)\n",
    "# #             print(close.iloc[-2]['Open', 'High', 'Low', 'Close'].values())\n",
    "            df.loc[:, ['Open', 'High', 'Low', 'Close']] = close.loc[close['Date'] == close.iloc[-1]['Date'], ['Open', 'High', 'Low', 'Close']].values \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        # shadows\n",
    "        df['upper_shadow'] = df['High'] - np.maximum(df['Open'], df['Close'])\n",
    "        df['lower_shadow'] = np.minimum(df['Open'], df['Close']) - df['Low']\n",
    "\n",
    "        # lagged features\n",
    "        # 날짜 단위이므로 7일전, 30일전, 180일전, 360일전 \n",
    "        # lagged close, target (target 은 정확히 무엇? return인가)\n",
    "        \n",
    "        ## Rolling features ##\n",
    "        \n",
    "        \n",
    "        # TA-lib features - RSI, EMA 7-90\n",
    "        df['RSI'] = ta.RSI(close['Close']).iloc[-1]\n",
    "        df['EMA7'] = ta.EMA(close['Close'], 7).iloc[-1]\n",
    "        df['EMA15'] = ta.EMA(close['Close'], 15).iloc[-1]\n",
    "        df['EMA30'] = ta.EMA(close['Close'], 30).iloc[-1]\n",
    "        df['EMA90'] = ta.EMA(close['Close'], 90).iloc[-1]\n",
    "        \n",
    "        \n",
    "#         for indicator in ta.get_function_groups()['Pattern Recognition']:\n",
    "#             df[str(indicator)] = getattr(ta,str(indicator))(df.Open, df.High, df.Low, df.Close)\n",
    "\n",
    "\n",
    "        # volatility\n",
    "        \n",
    "        df_list.append(df)\n",
    "    \n",
    "    df_feature_added = pd.concat(df_list)\n",
    "    \n",
    "    return df_feature_added\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1025b7f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:19.145535Z",
     "iopub.status.busy": "2022-06-10T07:19:19.145078Z",
     "iopub.status.idle": "2022-06-10T07:19:22.440258Z",
     "shell.execute_reply": "2022-06-10T07:19:22.439037Z"
    },
    "papermill": {
     "duration": 3.306171,
     "end_time": "2022-06-10T07:19:22.442841",
     "exception": false,
     "start_time": "2022-06-10T07:19:19.136670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_train(df):\n",
    "    \n",
    "    # remove columns - Date removed temporarily\n",
    "    dfc = df.drop(columns=['RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag'])\n",
    "    \n",
    "    \n",
    "#     minmax = MinMaxScaler()\n",
    "    stdsc = StandardScaler()\n",
    "    ordinal = OrdinalEncoder()\n",
    "\n",
    "    target = ['Target']\n",
    "#     minmax_features = ['Date']\n",
    "    ord_features = ['SecuritiesCode'] \n",
    "    scaled_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'upper_shadow', 'lower_shadow',\n",
    "                      'RSI', 'EMA7', 'EMA15', 'EMA30', 'EMA90'] #+ [c for c in df.columns if c.startswith('CDL')] # pattern recognition features\n",
    "    \n",
    "#     date_scaled = minmax.fit_transform(dfc.loc[:,minmax_features])\n",
    "    date_code_ord = ordinal.fit_transform(dfc.loc[:,ord_features])\n",
    "    scaled = stdsc.fit_transform(dfc.loc[:,scaled_features])\n",
    "    \n",
    "#     display(pd.DataFrame(date_code_ord, columns=ord_features))\n",
    "#     display(pd.DataFrame(scaled, columns=scaled_features))\n",
    "    \n",
    "    \n",
    "    dfc_scaled = pd.concat([# pd.DataFrame(date_scaled, columns=minmax_features),\n",
    "                            pd.DataFrame(date_code_ord, columns=ord_features),\n",
    "                            pd.DataFrame(scaled, columns=scaled_features)], axis=1)\n",
    "\n",
    "    y = dfc.loc[:,target]\n",
    "    return dfc_scaled, y, [ordinal, stdsc]\n",
    "    \n",
    "\n",
    "X_scaled, y, trained_scalers = preprocess_train(df_added)  # 2021-12-06부터 test 시작이므로 그 전까지만 이용한다.\n",
    "\n",
    "# X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "135dd08e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:22.458723Z",
     "iopub.status.busy": "2022-06-10T07:19:22.458215Z",
     "iopub.status.idle": "2022-06-10T07:19:22.467439Z",
     "shell.execute_reply": "2022-06-10T07:19:22.466422Z"
    },
    "papermill": {
     "duration": 0.019575,
     "end_time": "2022-06-10T07:19:22.469389",
     "exception": false,
     "start_time": "2022-06-10T07:19:22.449814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_inference(df, trained_scalers: list):\n",
    "    ordinal = trained_scalers[0]\n",
    "    stdsc = trained_scalers[1]\n",
    "    \n",
    "      \n",
    "    # remove columns - Date removed temporarily\n",
    "    dfc = df.drop(columns=['RowId', 'AdjustmentFactor', 'ExpectedDividend', 'SupervisionFlag'])\n",
    "    \n",
    "    \n",
    "    target = ['Target']\n",
    "    ord_features = ['SecuritiesCode'] \n",
    "    scaled_features = ['Open', 'High', 'Low', 'Close', 'Volume', 'upper_shadow', 'lower_shadow',\n",
    "                      'RSI', 'EMA7', 'EMA15', 'EMA30', 'EMA90'] #+ [c for c in df.columns if c.startswith('CDL')] # pattern recognition features\n",
    "    \n",
    "    \n",
    "    date_code_ord = ordinal.transform(dfc.loc[:,ord_features])\n",
    "    scaled = stdsc.transform(dfc.loc[:,scaled_features])\n",
    "    dfc_scaled = pd.concat([pd.DataFrame(date_code_ord, columns=ord_features),\n",
    "                            pd.DataFrame(scaled, columns=scaled_features)], axis=1)\n",
    "\n",
    "    \n",
    "    return dfc_scaled\n",
    "    \n",
    "\n",
    "# X_test_scaled = preprocess_train(df_added, trained_scalers)\n",
    "\n",
    "# X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ba1e10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:22.485083Z",
     "iopub.status.busy": "2022-06-10T07:19:22.484373Z",
     "iopub.status.idle": "2022-06-10T07:19:29.692990Z",
     "shell.execute_reply": "2022-06-10T07:19:29.691448Z"
    },
    "papermill": {
     "duration": 7.219516,
     "end_time": "2022-06-10T07:19:29.695617",
     "exception": false,
     "start_time": "2022-06-10T07:19:22.476101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# base model - lgbm \n",
    "lgb = LGBMRegressor().fit(X_scaled, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fea68cf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:29.712142Z",
     "iopub.status.busy": "2022-06-10T07:19:29.711729Z",
     "iopub.status.idle": "2022-06-10T07:19:29.969642Z",
     "shell.execute_reply": "2022-06-10T07:19:29.968645Z"
    },
    "papermill": {
     "duration": 0.268312,
     "end_time": "2022-06-10T07:19:29.971797",
     "exception": false,
     "start_time": "2022-06-10T07:19:29.703485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data, train, supp_data, y, X_scaled\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2febc926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:29.987277Z",
     "iopub.status.busy": "2022-06-10T07:19:29.986906Z",
     "iopub.status.idle": "2022-06-10T07:19:29.993318Z",
     "shell.execute_reply": "2022-06-10T07:19:29.992119Z"
    },
    "papermill": {
     "duration": 0.016479,
     "end_time": "2022-06-10T07:19:29.995421",
     "exception": false,
     "start_time": "2022-06-10T07:19:29.978942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # local-api\n",
    "# myapi = local_api('../input/jpx-tokyo-stock-exchange-prediction/supplemental_files')\n",
    "# env = myapi.make_env()\n",
    "# iter_test = env.iter_test()\n",
    "# for i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(tqdm(iter_test)):\n",
    "# #     t0 = time.time()\n",
    "    \n",
    "#     # 이전 데이터와 합치고 최근 140일치만 이용한다\n",
    "#     today = prices.iloc[0]['Date']\n",
    "#     lastday = str(pd.to_datetime(today) - pd.DateOffset(140))\n",
    "    \n",
    "#     if i == 0:\n",
    "#         close_df = pd.concat([\n",
    "#             train_with_supp.loc[\n",
    "#                 (train_with_supp['Date'] > lastday) & (train_with_supp['Date'] < today), \n",
    "#                     ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']],\n",
    "#                 prices.loc[:, ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']]\n",
    "#             ]).reset_index(drop=True)\n",
    "        \n",
    "#     else:\n",
    "#         close_df = pd.concat([\n",
    "#             close_df.loc[\n",
    "#                 (close_df['Date'] > lastday) & (close_df['Date'] < today), \n",
    "#                     ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']],\n",
    "#                 prices.loc[:, ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']]\n",
    "#             ]).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "#     feat = add_features_infer(prices, close_df)\n",
    "#     X = preprocess_inference(feat, trained_scalers)\n",
    "\n",
    "#     # X, y\n",
    "#     X['Target'] = lgb.predict(X)\n",
    "#     X['Rank'] = (X['Target'].rank(method='average', ascending=False)-1).astype(int)\n",
    "#     sample_prediction['Rank'] = X['Rank'].values\n",
    "    \n",
    "#     # check Rank\n",
    "#     assert sample_prediction[\"Rank\"].notna().all()\n",
    "#     assert sample_prediction[\"Rank\"].min() == 0\n",
    "#     assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n",
    "    \n",
    "# #     display(sample_prediction)\n",
    "#     env.predict(sample_prediction)\n",
    "# #     print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f017db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:30.010377Z",
     "iopub.status.busy": "2022-06-10T07:19:30.009997Z",
     "iopub.status.idle": "2022-06-10T07:19:30.039298Z",
     "shell.execute_reply": "2022-06-10T07:19:30.038042Z"
    },
    "papermill": {
     "duration": 0.039592,
     "end_time": "2022-06-10T07:19:30.041738",
     "exception": false,
     "start_time": "2022-06-10T07:19:30.002146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import jpx_tokyo_market_prediction\n",
    "env = jpx_tokyo_market_prediction.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a96f1cd",
   "metadata": {
    "papermill": {
     "duration": 0.006955,
     "end_time": "2022-06-10T07:19:30.055904",
     "exception": false,
     "start_time": "2022-06-10T07:19:30.048949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "pd.to_datetime 최소한도로 쓸것. 연산 cost가 너무 큼. 특히 inference 단계에서는 쓰지 않기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63052bfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:30.072338Z",
     "iopub.status.busy": "2022-06-10T07:19:30.071552Z",
     "iopub.status.idle": "2022-06-10T07:19:30.075935Z",
     "shell.execute_reply": "2022-06-10T07:19:30.075001Z"
    },
    "papermill": {
     "duration": 0.014919,
     "end_time": "2022-06-10T07:19:30.077723",
     "exception": false,
     "start_time": "2022-06-10T07:19:30.062804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2000개 종목 리스트에서 날짜 하나씩 빼고 뒷날짜 추가 구현?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "451d052c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-10T07:19:30.094129Z",
     "iopub.status.busy": "2022-06-10T07:19:30.093457Z",
     "iopub.status.idle": "2022-06-10T07:20:00.064786Z",
     "shell.execute_reply": "2022-06-10T07:20:00.063803Z"
    },
    "papermill": {
     "duration": 29.982802,
     "end_time": "2022-06-10T07:20:00.067238",
     "exception": false,
     "start_time": "2022-06-10T07:19:30.084436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n"
     ]
    }
   ],
   "source": [
    "for i, (prices, options, financials, trades, secondary_prices, sample_prediction) in enumerate(iter_test):\n",
    "#     t0 = time.time()\n",
    "    \n",
    "    # 이전 데이터와 합치고 최근 140일치만 이용한다\n",
    "    today = prices.iloc[0]['Date']\n",
    "    lastday = str(pd.to_datetime(today) - pd.DateOffset(140))\n",
    "    \n",
    "    if i == 0:\n",
    "        close_df = pd.concat([\n",
    "            train_with_supp.loc[\n",
    "                (train_with_supp['Date'] > lastday) & (train_with_supp['Date'] < today), \n",
    "                    ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']],\n",
    "                prices.loc[:, ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']]\n",
    "            ]).reset_index(drop=True)\n",
    "        \n",
    "    else:\n",
    "        close_df = pd.concat([\n",
    "            close_df.loc[\n",
    "                (close_df['Date'] > lastday) & (close_df['Date'] < today), \n",
    "                    ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']],\n",
    "                prices.loc[:, ['Date', 'SecuritiesCode', 'Open', 'High', 'Low', 'Close']]\n",
    "            ]).reset_index(drop=True)\n",
    "        \n",
    "\n",
    "    feat = add_features_infer(prices, close_df)\n",
    "    X = preprocess_inference(feat, trained_scalers)\n",
    "\n",
    "    # X, y\n",
    "    X['Target'] = lgb.predict(X)\n",
    "    X['Rank'] = (X['Target'].rank(method='first', ascending=False)-1).astype(int)\n",
    "    sample_prediction['Rank'] = X['Rank'].values\n",
    "    # check Rank\n",
    "    assert sample_prediction[\"Rank\"].notna().all()\n",
    "    assert sample_prediction[\"Rank\"].min() == 0\n",
    "    assert sample_prediction[\"Rank\"].max() == len(sample_prediction[\"Rank\"]) - 1\n",
    "#     display(sample_prediction)\n",
    "    env.predict(sample_prediction)\n",
    "#     print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a804a7e",
   "metadata": {
    "papermill": {
     "duration": 0.006632,
     "end_time": "2022-06-10T07:20:00.080839",
     "exception": false,
     "start_time": "2022-06-10T07:20:00.074207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 123.907231,
   "end_time": "2022-06-10T07:20:01.311925",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-10T07:17:57.404694",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
