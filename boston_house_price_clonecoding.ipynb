{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "boston-house-price-clonecoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4Yn6Zsd4t4msZ6yPN/XQQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoeen/kaggle/blob/main/boston_house_price_clonecoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MLadCJJ1Yz4C"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets.boston_housing import load_data\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로드\n",
        "\n",
        "- 데이터의 수가 적기 때문에 test의 비율을 20%로 지정\n",
        "- 13개의 특성을 가짐\n",
        "- 각각의 특성이 스케일이 다 다름\n",
        "- 정답 레이블은 주택 가격의 중간가격"
      ],
      "metadata": {
        "id": "S0I4o8QWZGub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2, seed=111)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsBXuCmTZDgb",
        "outputId": "eaff172b-1198-47e1-d36a-09128899a2de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57344/57026 [==============================] - 0s 0us/step\n",
            "65536/57026 [==================================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('학습 데이터: {}\\t레이블: {}'.format(x_train_full.shape, y_train_full.shape))\n",
        "print('테스트 데이터: {}\\t레이블: {}'.format(x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YB5lw42KZ4X2",
        "outputId": "faad33d4-c48e-4293-90b9-4e140908ef54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_full[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs_1TfWcZ5_d",
        "outputId": "95784fd5-1de5-4d6a-f23e-dc56692afbc9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2.8750e-02 2.8000e+01 1.5040e+01 0.0000e+00 4.6400e-01 6.2110e+00\n",
            " 2.8900e+01 3.6659e+00 4.0000e+00 2.7000e+02 1.8200e+01 3.9633e+02\n",
            " 6.2100e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train_full[0])  # 1000달러 단위"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdbyrQXoaOrU",
        "outputId": "7d369a12-82ee-407b-e451-1498075d7c0e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 전처리\n",
        "- Standardization\n",
        "- 동일한 범위로 조정"
      ],
      "metadata": {
        "id": "LfPuNHSUaiFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_preprocessed, y_train_full,\n",
        "                                                  test_size=0.3,\n",
        "                                                  random_state=111)"
      ],
      "metadata": {
        "id": "pxDN76FLaRb6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"학습 데이터: {}\\t레이블: {}\".format(x_train_full.shape, y_train_full.shape))\n",
        "print(\"학습 데이터: {}\\t레이블: {}\".format(x_train.shape, y_train.shape))\n",
        "print(\"검증 데이터: {}\\t레이블: {}\".format(x_val.shape, y_val.shape))\n",
        "print(\"테스트 데이터: {}\\t레이블: {}\".format(x_test.shape, y_test.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fci-HCl6a1FE",
        "outputId": "6eaaf2fa-4136-444b-8b78-fb69dfc770df"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터: (404, 13)\t레이블: (404,)\n",
            "학습 데이터: (282, 13)\t레이블: (282,)\n",
            "검증 데이터: (122, 13)\t레이블: (122,)\n",
            "테스트 데이터: (102, 13)\t레이블: (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구성\n",
        "- 학습 데이터가 매우 적은 경우에 모델의 깊이를 깊게 할수록  \n",
        "과대적합(Overfitting)이 일어날 확률이 높음"
      ],
      "metadata": {
        "id": "1h8ljlXlbSli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([Dense(100, activation='relu', input_shape=(13, ), name='dense1'),\n",
        "                    Dense(64, activation='relu', name='dense2'),\n",
        "                    Dense(32, activation='relu', name='dense3'),\n",
        "                    Dense(1, name='output')])"
      ],
      "metadata": {
        "id": "mlSDx8Oma1zm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsfwtI69bryA",
        "outputId": "40f17c11-242f-46d8-cffe-ac076482b43d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense1 (Dense)              (None, 100)               1400      \n",
            "                                                                 \n",
            " dense2 (Dense)              (None, 64)                6464      \n",
            "                                                                 \n",
            " dense3 (Dense)              (None, 32)                2080      \n",
            "                                                                 \n",
            " output (Dense)              (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,977\n",
            "Trainable params: 9,977\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "MDzikO3nbt34",
        "outputId": "d3a238e8-8665-4adf-817e-120a1ea51d23"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 컴파일\n",
        "- 회귀 문제에서는 주로 mse를 손실함수로, 평균절대오차(mae)를 평가지표로 많이 사용한다."
      ],
      "metadata": {
        "id": "0-M91xsnb1rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='mse', \n",
        "              optimizer=Adam(learning_rate=1e-2),\n",
        "              metrics=['mae'])"
      ],
      "metadata": {
        "id": "HB1bJf9Pb1dX"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "8XJeh5gPcPpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=300,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORlL5VRCb1br",
        "outputId": "cd860d98-25a7-4393-d6fb-e1c62e2d2e9b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 45ms/step - loss: 285.1888 - mae: 14.0729 - val_loss: 132.4612 - val_mae: 9.1090\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 60.9891 - mae: 5.9218 - val_loss: 31.4368 - val_mae: 4.4589\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 33.7114 - mae: 4.2293 - val_loss: 22.2753 - val_mae: 3.6017\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 21.5946 - mae: 3.4391 - val_loss: 13.9826 - val_mae: 2.9190\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 16.3538 - mae: 2.8935 - val_loss: 11.7222 - val_mae: 2.7147\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 13.6432 - mae: 2.5889 - val_loss: 10.9746 - val_mae: 2.5883\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 12.6475 - mae: 2.4426 - val_loss: 9.1843 - val_mae: 2.3985\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 12.5112 - mae: 2.5104 - val_loss: 9.8296 - val_mae: 2.4060\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3260 - mae: 2.3506 - val_loss: 8.1732 - val_mae: 2.2383\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.1601 - mae: 2.3899 - val_loss: 8.3317 - val_mae: 2.2944\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 11.3497 - mae: 2.3828 - val_loss: 9.6377 - val_mae: 2.3146\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 10.4039 - mae: 2.3526 - val_loss: 8.3838 - val_mae: 2.3106\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 9.6115 - mae: 2.1968 - val_loss: 8.4295 - val_mae: 2.2763\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 9.5119 - mae: 2.1870 - val_loss: 9.0308 - val_mae: 2.4176\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.5966 - mae: 2.0715 - val_loss: 8.1153 - val_mae: 2.2021\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.6300 - mae: 2.1294 - val_loss: 8.3422 - val_mae: 2.2117\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 8.7119 - mae: 2.1223 - val_loss: 10.9265 - val_mae: 2.6191\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 9.6290 - mae: 2.3363 - val_loss: 8.8320 - val_mae: 2.3394\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 8.1268 - mae: 2.0547 - val_loss: 7.6580 - val_mae: 2.1378\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.1541 - mae: 1.8875 - val_loss: 9.4983 - val_mae: 2.3932\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 7.6636 - mae: 2.0445 - val_loss: 7.8261 - val_mae: 2.1954\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2970 - mae: 1.9602 - val_loss: 9.3017 - val_mae: 2.4027\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6526 - mae: 2.0690 - val_loss: 8.9616 - val_mae: 2.2930\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 7.1070 - mae: 1.9766 - val_loss: 9.3341 - val_mae: 2.4466\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.2434 - mae: 1.9778 - val_loss: 8.0337 - val_mae: 2.1472\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.0202 - mae: 1.9266 - val_loss: 9.5019 - val_mae: 2.4783\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7250 - mae: 2.0076 - val_loss: 8.8930 - val_mae: 2.2959\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 6.0065 - mae: 1.8350 - val_loss: 8.3984 - val_mae: 2.3100\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.2788 - mae: 1.7311 - val_loss: 7.6616 - val_mae: 2.1417\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.7267 - mae: 1.6697 - val_loss: 8.6152 - val_mae: 2.2187\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3804 - mae: 1.5647 - val_loss: 8.6618 - val_mae: 2.2299\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1287 - mae: 1.5456 - val_loss: 9.1019 - val_mae: 2.3014\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.2564 - mae: 1.5684 - val_loss: 8.3172 - val_mae: 2.2020\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 4.0268 - mae: 1.4928 - val_loss: 7.7193 - val_mae: 2.1266\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.3587 - mae: 1.5772 - val_loss: 8.6461 - val_mae: 2.2870\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.7208 - mae: 1.4466 - val_loss: 8.7016 - val_mae: 2.2682\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.4474 - mae: 1.3969 - val_loss: 7.7028 - val_mae: 2.1663\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.5473 - mae: 1.4469 - val_loss: 9.2293 - val_mae: 2.3254\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1164 - mae: 1.5364 - val_loss: 7.5516 - val_mae: 2.1471\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.1612 - mae: 1.5391 - val_loss: 9.0860 - val_mae: 2.2800\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.8975 - mae: 1.7234 - val_loss: 14.1046 - val_mae: 2.7156\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.4876 - mae: 2.0237 - val_loss: 11.8633 - val_mae: 2.5463\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.7282 - mae: 1.9226 - val_loss: 11.1312 - val_mae: 2.3476\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 6.5698 - mae: 1.8489 - val_loss: 10.5545 - val_mae: 2.5355\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.9226 - mae: 1.8198 - val_loss: 9.9145 - val_mae: 2.5194\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 5.3605 - mae: 1.8161 - val_loss: 10.8243 - val_mae: 2.4174\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.6700 - mae: 1.7251 - val_loss: 8.7168 - val_mae: 2.1118\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.5694 - mae: 1.6758 - val_loss: 10.2233 - val_mae: 2.3588\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.5289 - mae: 1.4010 - val_loss: 8.8952 - val_mae: 2.2460\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3496 - mae: 1.3750 - val_loss: 8.7896 - val_mae: 2.2495\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1284 - mae: 1.3290 - val_loss: 9.6549 - val_mae: 2.3212\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3039 - mae: 1.3504 - val_loss: 10.4077 - val_mae: 2.4115\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9633 - mae: 1.3231 - val_loss: 8.4694 - val_mae: 2.1882\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.7208 - mae: 1.2373 - val_loss: 10.2249 - val_mae: 2.3849\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.6439 - mae: 1.2001 - val_loss: 9.0479 - val_mae: 2.2614\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7171 - mae: 1.2412 - val_loss: 9.0285 - val_mae: 2.3163\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8780 - mae: 1.2970 - val_loss: 9.9899 - val_mae: 2.3006\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9088 - mae: 1.2944 - val_loss: 9.3331 - val_mae: 2.2928\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 3.1556 - mae: 1.3606 - val_loss: 8.6352 - val_mae: 2.2724\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9424 - mae: 1.3052 - val_loss: 9.0182 - val_mae: 2.3817\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7571 - mae: 1.2281 - val_loss: 9.6503 - val_mae: 2.2940\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.6481 - mae: 1.2213 - val_loss: 10.2703 - val_mae: 2.3134\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8007 - mae: 1.2464 - val_loss: 11.5448 - val_mae: 2.3868\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8765 - mae: 1.2628 - val_loss: 7.8443 - val_mae: 2.1077\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5797 - mae: 1.2197 - val_loss: 10.0385 - val_mae: 2.4065\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.8164 - mae: 1.2721 - val_loss: 8.8858 - val_mae: 2.3324\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3793 - mae: 1.3949 - val_loss: 10.0863 - val_mae: 2.3325\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.1334 - mae: 1.3416 - val_loss: 9.1890 - val_mae: 2.2378\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.7248 - mae: 1.2136 - val_loss: 9.8590 - val_mae: 2.2711\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3818 - mae: 1.1229 - val_loss: 9.3658 - val_mae: 2.2573\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.5122 - mae: 1.1780 - val_loss: 9.0746 - val_mae: 2.2417\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8295 - mae: 1.2673 - val_loss: 14.5440 - val_mae: 2.8623\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.5592 - mae: 1.4149 - val_loss: 9.4024 - val_mae: 2.3350\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.7696 - mae: 1.2703 - val_loss: 9.8979 - val_mae: 2.3131\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.2436 - mae: 1.1286 - val_loss: 10.1262 - val_mae: 2.2962\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3050 - mae: 1.1445 - val_loss: 10.4645 - val_mae: 2.4467\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.4235 - mae: 1.1813 - val_loss: 11.7117 - val_mae: 2.5700\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.6634 - mae: 1.2345 - val_loss: 11.6203 - val_mae: 2.4593\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.5594 - mae: 1.1984 - val_loss: 9.0527 - val_mae: 2.2232\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.0361 - mae: 1.3473 - val_loss: 15.3192 - val_mae: 2.8569\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 5.2432 - mae: 1.6886 - val_loss: 8.5993 - val_mae: 2.1877\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 5.4689 - mae: 1.6499 - val_loss: 19.4235 - val_mae: 3.0101\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 7.6341 - mae: 2.0480 - val_loss: 9.5406 - val_mae: 2.3381\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.0174 - mae: 1.5725 - val_loss: 9.8996 - val_mae: 2.3267\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1671 - mae: 1.3826 - val_loss: 9.7036 - val_mae: 2.4429\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 3.1534 - mae: 1.2988 - val_loss: 11.2541 - val_mae: 2.3611\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.4493 - mae: 1.1906 - val_loss: 10.7775 - val_mae: 2.3489\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.2138 - mae: 1.1236 - val_loss: 9.3196 - val_mae: 2.2731\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.5308 - mae: 1.1848 - val_loss: 10.5826 - val_mae: 2.3135\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.3683 - mae: 1.2970 - val_loss: 10.4796 - val_mae: 2.4373\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 3.3313 - mae: 1.3546 - val_loss: 8.4616 - val_mae: 2.1069\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.3971 - mae: 1.1783 - val_loss: 8.5146 - val_mae: 2.2767\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.4490 - mae: 1.1593 - val_loss: 11.2875 - val_mae: 2.4678\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.6889 - mae: 1.1993 - val_loss: 9.0512 - val_mae: 2.1603\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.4708 - mae: 1.2077 - val_loss: 10.2199 - val_mae: 2.3292\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.4068 - mae: 1.1815 - val_loss: 9.8834 - val_mae: 2.3692\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.4002 - mae: 1.2268 - val_loss: 8.5077 - val_mae: 2.2729\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.9534 - mae: 1.2740 - val_loss: 10.6069 - val_mae: 2.4381\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 4.5216 - mae: 1.4921 - val_loss: 7.6226 - val_mae: 2.1386\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 3.0655 - mae: 1.3576 - val_loss: 13.2123 - val_mae: 2.7192\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.8318 - mae: 1.2687 - val_loss: 11.1519 - val_mae: 2.4405\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.2412 - mae: 1.1342 - val_loss: 8.3464 - val_mae: 2.2781\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.6984 - mae: 1.2584 - val_loss: 13.4355 - val_mae: 2.5925\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8748 - mae: 1.2671 - val_loss: 11.4898 - val_mae: 2.3909\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.8787 - mae: 1.2167 - val_loss: 11.0240 - val_mae: 2.4362\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9803 - mae: 1.3276 - val_loss: 13.4915 - val_mae: 2.8231\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.6583 - mae: 1.5248 - val_loss: 9.7116 - val_mae: 2.3223\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.2276 - mae: 1.0796 - val_loss: 9.6829 - val_mae: 2.2241\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.9147 - mae: 1.0205 - val_loss: 10.6154 - val_mae: 2.2966\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4704 - mae: 0.8819 - val_loss: 9.1596 - val_mae: 2.2168\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.5662 - mae: 0.9292 - val_loss: 9.7795 - val_mae: 2.2799\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4589 - mae: 0.8731 - val_loss: 9.8951 - val_mae: 2.2951\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3554 - mae: 0.8381 - val_loss: 10.0044 - val_mae: 2.2486\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5238 - mae: 0.9141 - val_loss: 11.0705 - val_mae: 2.3368\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4571 - mae: 0.8965 - val_loss: 8.2830 - val_mae: 2.1488\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6981 - mae: 0.9518 - val_loss: 10.6390 - val_mae: 2.4307\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.6584 - mae: 0.9253 - val_loss: 11.0551 - val_mae: 2.3367\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.3905 - mae: 0.8854 - val_loss: 10.0462 - val_mae: 2.2473\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.6859 - mae: 0.9671 - val_loss: 11.3387 - val_mae: 2.5616\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.1025 - mae: 1.0655 - val_loss: 9.4397 - val_mae: 2.3189\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5308 - mae: 0.9220 - val_loss: 9.8855 - val_mae: 2.2269\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6079 - mae: 0.9382 - val_loss: 11.0234 - val_mae: 2.4480\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.9918 - mae: 1.0009 - val_loss: 12.0338 - val_mae: 2.5677\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5520 - mae: 0.9375 - val_loss: 9.3995 - val_mae: 2.1855\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4291 - mae: 0.8731 - val_loss: 12.3123 - val_mae: 2.4807\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3978 - mae: 0.8415 - val_loss: 9.2733 - val_mae: 2.2665\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2989 - mae: 0.8397 - val_loss: 11.1641 - val_mae: 2.3487\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2275 - mae: 0.8083 - val_loss: 9.8776 - val_mae: 2.2821\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2823 - mae: 0.8151 - val_loss: 10.1076 - val_mae: 2.3444\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.7356 - mae: 1.0027 - val_loss: 9.9785 - val_mae: 2.3835\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.8429 - mae: 1.0000 - val_loss: 11.6445 - val_mae: 2.4221\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2934 - mae: 0.8579 - val_loss: 12.0605 - val_mae: 2.4589\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.8380 - mae: 1.0313 - val_loss: 11.3691 - val_mae: 2.5150\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3721 - mae: 0.8598 - val_loss: 9.5387 - val_mae: 2.2562\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.1272 - mae: 0.7810 - val_loss: 11.1946 - val_mae: 2.3711\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0736 - mae: 0.7467 - val_loss: 11.1561 - val_mae: 2.3795\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0988 - mae: 0.7853 - val_loss: 11.7137 - val_mae: 2.4292\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6157 - mae: 0.9313 - val_loss: 11.2830 - val_mae: 2.3896\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.9579 - mae: 1.0833 - val_loss: 11.5408 - val_mae: 2.4144\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.7763 - mae: 1.0189 - val_loss: 11.4173 - val_mae: 2.3581\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4645 - mae: 0.9007 - val_loss: 10.3499 - val_mae: 2.3751\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5032 - mae: 0.9081 - val_loss: 9.9736 - val_mae: 2.2297\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1775 - mae: 0.7800 - val_loss: 11.7317 - val_mae: 2.3495\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6800 - mae: 1.0253 - val_loss: 11.8033 - val_mae: 2.4552\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.5964 - mae: 0.9591 - val_loss: 11.4509 - val_mae: 2.4285\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3537 - mae: 0.8885 - val_loss: 9.8530 - val_mae: 2.2676\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2323 - mae: 0.8100 - val_loss: 11.0658 - val_mae: 2.3914\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6964 - mae: 0.9728 - val_loss: 11.4690 - val_mae: 2.5149\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.9002 - mae: 1.0880 - val_loss: 10.4042 - val_mae: 2.3241\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.9525 - mae: 1.0708 - val_loss: 11.2086 - val_mae: 2.3304\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.2193 - mae: 0.8133 - val_loss: 11.3790 - val_mae: 2.4516\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3997 - mae: 0.8753 - val_loss: 9.5914 - val_mae: 2.2021\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3120 - mae: 0.8310 - val_loss: 10.5622 - val_mae: 2.3860\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5547 - mae: 0.9153 - val_loss: 11.2350 - val_mae: 2.3537\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.6321 - mae: 0.9035 - val_loss: 9.8628 - val_mae: 2.3208\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6179 - mae: 0.9225 - val_loss: 12.0546 - val_mae: 2.5697\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.5076 - mae: 1.1940 - val_loss: 11.5517 - val_mae: 2.5225\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 3.4652 - mae: 1.4081 - val_loss: 10.3828 - val_mae: 2.4136\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.8883 - mae: 1.0495 - val_loss: 11.1657 - val_mae: 2.5742\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.0589 - mae: 1.1045 - val_loss: 9.2011 - val_mae: 2.2416\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.2645 - mae: 1.1427 - val_loss: 12.0679 - val_mae: 2.4952\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.4086 - mae: 1.1850 - val_loss: 11.3728 - val_mae: 2.3777\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5487 - mae: 0.9417 - val_loss: 13.4307 - val_mae: 2.4878\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2508 - mae: 0.8788 - val_loss: 11.2197 - val_mae: 2.4518\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4404 - mae: 0.9114 - val_loss: 10.6687 - val_mae: 2.3234\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.2699 - mae: 0.8170 - val_loss: 10.5302 - val_mae: 2.3061\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1923 - mae: 0.7826 - val_loss: 12.2351 - val_mae: 2.3930\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0986 - mae: 0.7863 - val_loss: 10.1684 - val_mae: 2.2435\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0974 - mae: 0.7585 - val_loss: 11.4476 - val_mae: 2.3473\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0099 - mae: 0.7338 - val_loss: 11.5954 - val_mae: 2.4019\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2614 - mae: 0.8237 - val_loss: 9.2689 - val_mae: 2.2059\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3372 - mae: 0.8693 - val_loss: 9.9478 - val_mae: 2.3493\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2578 - mae: 0.8049 - val_loss: 12.1889 - val_mae: 2.3722\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.3613 - mae: 0.8572 - val_loss: 8.7341 - val_mae: 2.1556\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5765 - mae: 0.9618 - val_loss: 11.0322 - val_mae: 2.4512\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5371 - mae: 0.9458 - val_loss: 11.1684 - val_mae: 2.4505\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2761 - mae: 0.8421 - val_loss: 11.6155 - val_mae: 2.5225\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 2.9987 - mae: 1.4159 - val_loss: 10.8513 - val_mae: 2.4052\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 4.4764 - mae: 1.6862 - val_loss: 11.9126 - val_mae: 2.4536\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 6.3549 - mae: 1.9795 - val_loss: 12.5576 - val_mae: 2.6317\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 4.3042 - mae: 1.6556 - val_loss: 16.4105 - val_mae: 2.8542\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 3.1003 - mae: 1.3811 - val_loss: 10.0303 - val_mae: 2.2134\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 2.0917 - mae: 1.1014 - val_loss: 11.2444 - val_mae: 2.3788\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.7048 - mae: 0.9921 - val_loss: 10.6140 - val_mae: 2.2484\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.5331 - mae: 0.9424 - val_loss: 12.3044 - val_mae: 2.5137\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4565 - mae: 0.9198 - val_loss: 9.9070 - val_mae: 2.2510\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6426 - mae: 0.9468 - val_loss: 11.2385 - val_mae: 2.4508\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.9909 - mae: 1.1616 - val_loss: 11.0874 - val_mae: 2.4697\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.1038 - mae: 1.1112 - val_loss: 10.4385 - val_mae: 2.2719\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.0833 - mae: 1.0873 - val_loss: 11.1639 - val_mae: 2.4036\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 2.2952 - mae: 1.1518 - val_loss: 12.5117 - val_mae: 2.5570\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.2093 - mae: 1.1664 - val_loss: 10.6160 - val_mae: 2.3476\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6669 - mae: 1.0128 - val_loss: 11.9036 - val_mae: 2.5351\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.8196 - mae: 1.0577 - val_loss: 9.7268 - val_mae: 2.2486\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6177 - mae: 0.9725 - val_loss: 11.4863 - val_mae: 2.4934\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.7016 - mae: 0.9611 - val_loss: 13.7916 - val_mae: 2.4994\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.5992 - mae: 0.9365 - val_loss: 12.9039 - val_mae: 2.5538\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.4316 - mae: 0.8964 - val_loss: 11.6396 - val_mae: 2.4860\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2798 - mae: 0.8459 - val_loss: 9.9275 - val_mae: 2.2073\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1357 - mae: 0.7923 - val_loss: 9.7296 - val_mae: 2.2621\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1159 - mae: 0.7526 - val_loss: 9.5094 - val_mae: 2.1939\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0627 - mae: 0.7814 - val_loss: 11.4984 - val_mae: 2.4030\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2145 - mae: 0.8475 - val_loss: 11.0676 - val_mae: 2.3311\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 0s 14ms/step - loss: 1.1703 - mae: 0.8243 - val_loss: 10.7318 - val_mae: 2.3359\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.1679 - mae: 0.8212 - val_loss: 10.7385 - val_mae: 2.3604\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9582 - mae: 0.7257 - val_loss: 9.4844 - val_mae: 2.2907\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1109 - mae: 0.7547 - val_loss: 10.2407 - val_mae: 2.3285\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.9434 - mae: 0.6964 - val_loss: 10.0663 - val_mae: 2.2552\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.9435 - mae: 0.6827 - val_loss: 11.1252 - val_mae: 2.2758\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2273 - mae: 0.8382 - val_loss: 12.5850 - val_mae: 2.5080\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2351 - mae: 0.8325 - val_loss: 10.0236 - val_mae: 2.2859\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4677 - mae: 0.9507 - val_loss: 10.6119 - val_mae: 2.3787\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.9223 - mae: 1.0004 - val_loss: 11.0253 - val_mae: 2.5193\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.4964 - mae: 0.9257 - val_loss: 10.5848 - val_mae: 2.4262\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2945 - mae: 0.8658 - val_loss: 8.8689 - val_mae: 2.1878\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2072 - mae: 0.8118 - val_loss: 12.8838 - val_mae: 2.5860\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9598 - mae: 0.7159 - val_loss: 9.8711 - val_mae: 2.3096\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9537 - mae: 0.6771 - val_loss: 9.6879 - val_mae: 2.2928\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8626 - mae: 0.6796 - val_loss: 11.0548 - val_mae: 2.3742\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8800 - mae: 0.6868 - val_loss: 8.8649 - val_mae: 2.2602\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9735 - mae: 0.7093 - val_loss: 11.2859 - val_mae: 2.4255\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0656 - mae: 0.7532 - val_loss: 10.5953 - val_mae: 2.3597\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8483 - mae: 0.6777 - val_loss: 8.6743 - val_mae: 2.2153\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8944 - mae: 0.6829 - val_loss: 11.6652 - val_mae: 2.4604\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0377 - mae: 0.7762 - val_loss: 9.0802 - val_mae: 2.1917\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.7671 - mae: 0.6165 - val_loss: 10.3074 - val_mae: 2.3428\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8698 - mae: 0.6941 - val_loss: 11.0832 - val_mae: 2.3940\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9735 - mae: 0.7385 - val_loss: 10.3172 - val_mae: 2.3364\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9111 - mae: 0.7221 - val_loss: 9.4586 - val_mae: 2.2238\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8167 - mae: 0.6801 - val_loss: 10.8695 - val_mae: 2.4107\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1747 - mae: 0.8410 - val_loss: 11.0919 - val_mae: 2.4989\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 1.5394 - mae: 0.9516 - val_loss: 11.1460 - val_mae: 2.4423\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.6821 - mae: 0.9851 - val_loss: 8.6970 - val_mae: 2.1619\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.3443 - mae: 0.8709 - val_loss: 12.2724 - val_mae: 2.6390\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4473 - mae: 0.9247 - val_loss: 12.3180 - val_mae: 2.5068\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.3227 - mae: 0.8643 - val_loss: 10.6526 - val_mae: 2.3400\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.3756 - mae: 0.8744 - val_loss: 11.2529 - val_mae: 2.4454\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.0459 - mae: 0.7765 - val_loss: 9.9211 - val_mae: 2.2518\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0173 - mae: 0.7745 - val_loss: 9.7323 - val_mae: 2.3398\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1208 - mae: 0.8037 - val_loss: 10.3481 - val_mae: 2.2314\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0777 - mae: 0.7726 - val_loss: 10.1091 - val_mae: 2.2704\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9645 - mae: 0.7245 - val_loss: 9.5626 - val_mae: 2.2660\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8315 - mae: 0.6866 - val_loss: 11.1404 - val_mae: 2.3590\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.0771 - mae: 0.7797 - val_loss: 11.2856 - val_mae: 2.4502\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.2958 - mae: 0.8911 - val_loss: 10.6697 - val_mae: 2.3502\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9173 - mae: 0.7318 - val_loss: 9.9049 - val_mae: 2.2574\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7817 - mae: 0.6529 - val_loss: 9.9878 - val_mae: 2.2686\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.6938 - mae: 0.6007 - val_loss: 9.4337 - val_mae: 2.2358\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6779 - mae: 0.6015 - val_loss: 10.3269 - val_mae: 2.3419\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7187 - mae: 0.5744 - val_loss: 10.1775 - val_mae: 2.2830\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8033 - mae: 0.6419 - val_loss: 11.6872 - val_mae: 2.5993\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5272 - mae: 0.9557 - val_loss: 10.5265 - val_mae: 2.3697\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0917 - mae: 0.7428 - val_loss: 10.2258 - val_mae: 2.3525\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.8620 - mae: 0.7251 - val_loss: 10.7857 - val_mae: 2.3056\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.5934 - mae: 0.9944 - val_loss: 10.2795 - val_mae: 2.3959\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 2.0711 - mae: 1.1414 - val_loss: 12.5565 - val_mae: 2.5182\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 2.3357 - mae: 1.1584 - val_loss: 11.3700 - val_mae: 2.4705\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2069 - mae: 0.8598 - val_loss: 11.6385 - val_mae: 2.4239\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.1491 - mae: 0.8080 - val_loss: 9.9376 - val_mae: 2.2723\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.8680 - mae: 0.6994 - val_loss: 10.7209 - val_mae: 2.4080\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1760 - mae: 0.8421 - val_loss: 12.0842 - val_mae: 2.4067\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2480 - mae: 0.8610 - val_loss: 10.9500 - val_mae: 2.4035\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0797 - mae: 0.7989 - val_loss: 9.6105 - val_mae: 2.3164\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.4625 - mae: 0.9239 - val_loss: 9.4362 - val_mae: 2.2993\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 0s 15ms/step - loss: 0.9320 - mae: 0.7340 - val_loss: 9.6834 - val_mae: 2.3366\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8817 - mae: 0.6776 - val_loss: 11.6450 - val_mae: 2.4802\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8212 - mae: 0.6816 - val_loss: 8.5698 - val_mae: 2.2003\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0037 - mae: 0.7136 - val_loss: 14.4377 - val_mae: 2.6186\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9609 - mae: 0.6980 - val_loss: 10.2231 - val_mae: 2.3510\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.0121 - mae: 0.7364 - val_loss: 11.3518 - val_mae: 2.4008\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.1233 - mae: 0.7962 - val_loss: 9.0221 - val_mae: 2.2231\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2519 - mae: 0.8391 - val_loss: 10.1470 - val_mae: 2.5426\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 1.2218 - mae: 0.8275 - val_loss: 10.6879 - val_mae: 2.4379\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 1.3624 - mae: 0.9129 - val_loss: 11.7964 - val_mae: 2.5216\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.1614 - mae: 0.8620 - val_loss: 10.0003 - val_mae: 2.2908\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 1.2589 - mae: 0.8575 - val_loss: 11.8889 - val_mae: 2.5198\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.9441 - mae: 0.7210 - val_loss: 9.1890 - val_mae: 2.2124\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6770 - mae: 0.6080 - val_loss: 11.2255 - val_mae: 2.4182\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.5795 - mae: 0.5544 - val_loss: 10.9110 - val_mae: 2.3315\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6110 - mae: 0.5601 - val_loss: 11.1939 - val_mae: 2.4188\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5251 - mae: 0.5212 - val_loss: 10.0846 - val_mae: 2.3156\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.5923 - mae: 0.5783 - val_loss: 10.5978 - val_mae: 2.4324\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7565 - mae: 0.6654 - val_loss: 10.6242 - val_mae: 2.3283\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.9544 - mae: 0.7050 - val_loss: 10.1546 - val_mae: 2.3337\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 1.1055 - mae: 0.7849 - val_loss: 10.9921 - val_mae: 2.6113\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 1.0688 - mae: 0.7638 - val_loss: 10.0039 - val_mae: 2.3390\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.7537 - mae: 0.6496 - val_loss: 9.9613 - val_mae: 2.3422\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.6660 - mae: 0.6013 - val_loss: 10.7043 - val_mae: 2.3386\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.8802 - mae: 0.7395 - val_loss: 10.0332 - val_mae: 2.3374\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.7630 - mae: 0.6482 - val_loss: 10.4363 - val_mae: 2.3803\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.7616 - mae: 0.6901 - val_loss: 10.6755 - val_mae: 2.3586\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6225 - mae: 0.5725 - val_loss: 10.6928 - val_mae: 2.3136\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.6745 - mae: 0.6038 - val_loss: 10.2865 - val_mae: 2.3918\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.5247 - mae: 0.5177 - val_loss: 10.5948 - val_mae: 2.3451\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 0s 13ms/step - loss: 0.5201 - mae: 0.4971 - val_loss: 10.4184 - val_mae: 2.3288\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.4773 - mae: 0.4965 - val_loss: 10.3559 - val_mae: 2.3642\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4425 - mae: 0.4529 - val_loss: 10.2862 - val_mae: 2.3516\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.4474 - mae: 0.4680 - val_loss: 10.2709 - val_mae: 2.3233\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.3930 - mae: 0.4308 - val_loss: 11.0671 - val_mae: 2.3613\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 0s 11ms/step - loss: 0.4085 - mae: 0.4506 - val_loss: 10.0476 - val_mae: 2.3625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 평가\n",
        "- evaluate()"
      ],
      "metadata": {
        "id": "c741PSbicjCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dISytsATb1Zt",
        "outputId": "1a9e4ded-0dfe-4278-ccb7-62769db3759c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 5479.6675 - mae: 62.2101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5479.66748046875, 62.210079193115234]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "영상과는 다르게 test 데이터의 evaluate 에 따른 loss가 매우 높게 나옴.. 왜?"
      ],
      "metadata": {
        "id": "XYNbvMsFdCCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XTOFVjhby2p",
        "outputId": "0c6cfe1f-7261-4277-ff10-7a93a64ec8d7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "fig = plt.figure(figsize=(12,6))\n",
        "\n",
        "ax1 = fig.add_subplot(1,2,1)\n",
        "ax1.plot(epochs, loss, color='b', label='train_loss')\n",
        "ax1.plot(epochs, val_loss, color='r', label='val_loss')\n",
        "ax1.set_title('Train and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "\n",
        "mae = history_dict['mae']\n",
        "val_mae = history_dict['val_mae']\n",
        "\n",
        "ax2 = fig.add_subplot(1,2,2)\n",
        "ax2.plot(epochs, mae, color='b', label='train_mae')\n",
        "ax2.plot(epochs, val_mae, color='r', label='val_mae')\n",
        "ax2.set_title('Train and Validation MAE')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('MAE')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "RseYK8l5c7rO",
        "outputId": "f0279fd1-8deb-4dbf-829f-52ee612041c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-Fold 교차 검증\n",
        "- 데이터셋의 크기가 매우 작은 경우에  \n",
        "[훈련, 검증, 테스트] 데이터로 나누게 되면 과소적합이 일어날 확률이 높음\n",
        "- 이를 해결하기 위해 K-Fold 교차 검증 실행"
      ],
      "metadata": {
        "id": "wQoIdgSteXB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "I-v_JkyWgRa5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(111)\n",
        "\n",
        "(x_train_full, y_train_full), (x_test, y_test) = load_data(path='boston_housing.npz',\n",
        "                                                           test_split=0.2, seed=111)\n",
        "\n",
        "mean = np.mean(x_train_full, axis=0)\n",
        "std = np.std(x_train_full, axis=0)\n",
        "x_train_preprocessed = (x_train_full - mean) / std\n",
        "x_test = (x_test - mean) / std\n"
      ],
      "metadata": {
        "id": "7KmkNWfwd1Py"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3\n",
        "\n",
        "kfold = KFold(n_splits=k)"
      ],
      "metadata": {
        "id": "uN0cMtz6eXkW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    input = Input(shape=(13, ), name='input')\n",
        "    hidden1 = Dense(100, activation='relu', name='dense1')(input)\n",
        "    hidden2 = Dense(64, activation='relu', name='dense2')(hidden1)\n",
        "    hidden3 = Dense(32, activation='relu', name='dense3')(hidden2)\n",
        "    output = Dense(1, name='output')(hidden3)\n",
        "    \n",
        "    model = Model(inputs=[input], outputs=output)\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "G0dE245seXil"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q: 함수형과 Sequential로 모델 만들때의 차이점 및 장단점은?"
      ],
      "metadata": {
        "id": "X5SsdcDnhIYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_list = []"
      ],
      "metadata": {
        "id": "CgtvSdZ3eXgo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_idx, val_idx in kfold.split(x_train):\n",
        "    x_train_fold, x_val_fold = x_train[train_idx], x_train[val_idx]\n",
        "    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    model = build_model()\n",
        "\n",
        "    model.fit(x_train_fold, y_train_fold, epochs=300,\n",
        "              validation_data=(x_val_fold, y_val_fold))\n",
        "    \n",
        "    _, test_mae = model.evaluate(x_test, y_test)\n",
        "\n",
        "    mae_list.append(test_mae)\n",
        "\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk43dgqHeXeO",
        "outputId": "cd6d5c45-2e0f-437c-ca22-ff977140d960"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 36ms/step - loss: 579.3210 - mae: 22.1051 - val_loss: 506.6597 - val_mae: 21.0692\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 548.0917 - mae: 21.4028 - val_loss: 478.9495 - val_mae: 20.4060\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 514.8639 - mae: 20.6378 - val_loss: 446.4250 - val_mae: 19.5962\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 476.0873 - mae: 19.6777 - val_loss: 405.7285 - val_mae: 18.5324\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 427.9754 - mae: 18.4248 - val_loss: 353.6115 - val_mae: 17.1139\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 366.9639 - mae: 16.7816 - val_loss: 288.7289 - val_mae: 15.1829\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 294.5549 - mae: 14.7433 - val_loss: 213.2458 - val_mae: 12.7160\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 207.5285 - mae: 12.1436 - val_loss: 137.3456 - val_mae: 9.9224\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 127.2520 - mae: 9.1810 - val_loss: 77.1314 - val_mae: 7.2101\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 78.9632 - mae: 6.9990 - val_loss: 51.7385 - val_mae: 5.8097\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 64.7086 - mae: 6.3631 - val_loss: 48.8113 - val_mae: 5.4900\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 56.2039 - mae: 5.8421 - val_loss: 40.2102 - val_mae: 4.8582\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 41.9938 - mae: 4.9661 - val_loss: 33.1443 - val_mae: 4.3354\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 33.5407 - mae: 4.2982 - val_loss: 30.8938 - val_mae: 4.0534\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 29.8857 - mae: 3.9448 - val_loss: 29.5851 - val_mae: 3.8641\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.0329 - mae: 3.6381 - val_loss: 27.1057 - val_mae: 3.6500\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.1175 - mae: 3.4848 - val_loss: 25.2619 - val_mae: 3.5403\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.2315 - mae: 3.3919 - val_loss: 24.5537 - val_mae: 3.4432\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.1634 - mae: 3.2765 - val_loss: 23.8325 - val_mae: 3.3541\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.3251 - mae: 3.1899 - val_loss: 23.2759 - val_mae: 3.2680\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 20.5161 - mae: 3.0955 - val_loss: 22.7874 - val_mae: 3.2061\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.8647 - mae: 3.0263 - val_loss: 22.2352 - val_mae: 3.1461\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.2199 - mae: 2.9783 - val_loss: 21.6261 - val_mae: 3.0946\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 18.6732 - mae: 2.9286 - val_loss: 21.1215 - val_mae: 3.0498\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 18.1515 - mae: 2.8794 - val_loss: 20.5662 - val_mae: 3.0150\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 17.6183 - mae: 2.8346 - val_loss: 20.3180 - val_mae: 2.9740\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 17.3676 - mae: 2.7954 - val_loss: 19.8012 - val_mae: 2.9572\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 16.7988 - mae: 2.7510 - val_loss: 19.5635 - val_mae: 2.9093\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 16.4514 - mae: 2.7057 - val_loss: 19.2155 - val_mae: 2.8747\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.9736 - mae: 2.6728 - val_loss: 18.8805 - val_mae: 2.8714\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.6041 - mae: 2.6447 - val_loss: 18.5693 - val_mae: 2.8520\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 15.3262 - mae: 2.6138 - val_loss: 18.3768 - val_mae: 2.8290\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.8988 - mae: 2.5548 - val_loss: 18.1272 - val_mae: 2.7775\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.5355 - mae: 2.5261 - val_loss: 17.8370 - val_mae: 2.7736\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.2965 - mae: 2.5062 - val_loss: 17.6129 - val_mae: 2.7639\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.9981 - mae: 2.4906 - val_loss: 17.3431 - val_mae: 2.7839\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 13.6431 - mae: 2.4647 - val_loss: 17.2271 - val_mae: 2.7682\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.3250 - mae: 2.4191 - val_loss: 17.0476 - val_mae: 2.7444\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.1512 - mae: 2.3835 - val_loss: 16.9128 - val_mae: 2.7006\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 12.8116 - mae: 2.3718 - val_loss: 16.7271 - val_mae: 2.7226\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.6081 - mae: 2.3574 - val_loss: 16.5620 - val_mae: 2.7463\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.3723 - mae: 2.3533 - val_loss: 16.4424 - val_mae: 2.7569\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.2307 - mae: 2.3494 - val_loss: 16.3310 - val_mae: 2.7559\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.8479 - mae: 2.2989 - val_loss: 16.1951 - val_mae: 2.7168\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.8955 - mae: 2.2744 - val_loss: 16.1162 - val_mae: 2.6679\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.6098 - mae: 2.2650 - val_loss: 15.8864 - val_mae: 2.6961\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.4228 - mae: 2.2639 - val_loss: 15.9997 - val_mae: 2.7612\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.1885 - mae: 2.2573 - val_loss: 15.9624 - val_mae: 2.7628\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.9485 - mae: 2.2121 - val_loss: 15.7329 - val_mae: 2.6946\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.7282 - mae: 2.1875 - val_loss: 15.6431 - val_mae: 2.6684\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.6492 - mae: 2.1878 - val_loss: 15.5980 - val_mae: 2.7069\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.3920 - mae: 2.1767 - val_loss: 15.4968 - val_mae: 2.7067\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.2183 - mae: 2.1651 - val_loss: 15.4591 - val_mae: 2.7020\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.0581 - mae: 2.1502 - val_loss: 15.3779 - val_mae: 2.6923\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.9042 - mae: 2.1256 - val_loss: 15.3929 - val_mae: 2.6904\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.8046 - mae: 2.1184 - val_loss: 15.4401 - val_mae: 2.7115\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.6518 - mae: 2.1186 - val_loss: 15.3440 - val_mae: 2.7010\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.5569 - mae: 2.1074 - val_loss: 15.3860 - val_mae: 2.7044\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.3861 - mae: 2.0821 - val_loss: 15.2410 - val_mae: 2.6872\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.2128 - mae: 2.0678 - val_loss: 15.2901 - val_mae: 2.6927\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.1026 - mae: 2.0726 - val_loss: 15.3329 - val_mae: 2.7121\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.0350 - mae: 2.0754 - val_loss: 15.4234 - val_mae: 2.7379\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.9667 - mae: 2.0609 - val_loss: 15.2758 - val_mae: 2.7067\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.7223 - mae: 2.0219 - val_loss: 15.1245 - val_mae: 2.6829\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.6606 - mae: 2.0341 - val_loss: 15.1932 - val_mae: 2.7022\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.5669 - mae: 2.0231 - val_loss: 15.0272 - val_mae: 2.6728\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.3903 - mae: 1.9935 - val_loss: 15.0682 - val_mae: 2.6896\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.3176 - mae: 1.9820 - val_loss: 15.1692 - val_mae: 2.7125\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.2246 - mae: 1.9962 - val_loss: 15.1802 - val_mae: 2.7116\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.1815 - mae: 1.9998 - val_loss: 15.2439 - val_mae: 2.7291\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 8.1152 - mae: 1.9601 - val_loss: 15.0528 - val_mae: 2.6782\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.9527 - mae: 1.9554 - val_loss: 15.1097 - val_mae: 2.6960\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.8356 - mae: 1.9485 - val_loss: 15.1102 - val_mae: 2.7096\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.7685 - mae: 1.9520 - val_loss: 15.0523 - val_mae: 2.7087\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.7494 - mae: 1.9564 - val_loss: 15.1558 - val_mae: 2.7246\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.7763 - mae: 1.9391 - val_loss: 15.0460 - val_mae: 2.7006\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.5849 - mae: 1.9347 - val_loss: 15.2856 - val_mae: 2.7513\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 7.4209 - mae: 1.9191 - val_loss: 15.1278 - val_mae: 2.7260\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.4429 - mae: 1.9010 - val_loss: 15.0940 - val_mae: 2.7183\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.2822 - mae: 1.8854 - val_loss: 15.0099 - val_mae: 2.7088\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.2351 - mae: 1.8948 - val_loss: 15.1552 - val_mae: 2.7336\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.0803 - mae: 1.8812 - val_loss: 15.1738 - val_mae: 2.7349\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.0933 - mae: 1.8741 - val_loss: 15.2681 - val_mae: 2.7532\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9678 - mae: 1.8584 - val_loss: 14.9997 - val_mae: 2.7168\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9691 - mae: 1.8666 - val_loss: 15.1236 - val_mae: 2.7344\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8709 - mae: 1.8620 - val_loss: 14.9796 - val_mae: 2.7220\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.7644 - mae: 1.8361 - val_loss: 15.1270 - val_mae: 2.7372\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.6411 - mae: 1.8249 - val_loss: 15.0253 - val_mae: 2.7243\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.6028 - mae: 1.8230 - val_loss: 15.0523 - val_mae: 2.7264\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.5338 - mae: 1.8035 - val_loss: 14.9860 - val_mae: 2.7192\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.5172 - mae: 1.8006 - val_loss: 15.2347 - val_mae: 2.7551\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.4054 - mae: 1.7925 - val_loss: 14.9791 - val_mae: 2.7254\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.3408 - mae: 1.7838 - val_loss: 15.0784 - val_mae: 2.7331\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3099 - mae: 1.7821 - val_loss: 15.1929 - val_mae: 2.7511\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2111 - mae: 1.7704 - val_loss: 15.2271 - val_mae: 2.7648\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1976 - mae: 1.7667 - val_loss: 15.0698 - val_mae: 2.7366\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.1759 - mae: 1.7610 - val_loss: 14.9822 - val_mae: 2.7301\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3340 - mae: 1.8002 - val_loss: 15.6998 - val_mae: 2.8360\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1170 - mae: 1.7612 - val_loss: 14.8066 - val_mae: 2.7174\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.9995 - mae: 1.7442 - val_loss: 15.0968 - val_mae: 2.7448\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.9162 - mae: 1.7538 - val_loss: 15.5087 - val_mae: 2.8012\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8872 - mae: 1.7412 - val_loss: 15.1117 - val_mae: 2.7571\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.8753 - mae: 1.7132 - val_loss: 14.8775 - val_mae: 2.7197\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7551 - mae: 1.7151 - val_loss: 15.5055 - val_mae: 2.8047\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8255 - mae: 1.7292 - val_loss: 15.0496 - val_mae: 2.7534\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.5653 - mae: 1.6894 - val_loss: 15.1538 - val_mae: 2.7624\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5800 - mae: 1.6969 - val_loss: 15.1050 - val_mae: 2.7559\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4679 - mae: 1.6935 - val_loss: 15.4476 - val_mae: 2.8049\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.4776 - mae: 1.6802 - val_loss: 15.2541 - val_mae: 2.7896\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.4258 - mae: 1.6648 - val_loss: 15.1753 - val_mae: 2.7725\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3047 - mae: 1.6534 - val_loss: 15.5642 - val_mae: 2.8148\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2917 - mae: 1.6612 - val_loss: 15.2787 - val_mae: 2.7840\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2266 - mae: 1.6393 - val_loss: 15.3724 - val_mae: 2.8101\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.2213 - mae: 1.6349 - val_loss: 15.2948 - val_mae: 2.7983\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.2299 - mae: 1.6599 - val_loss: 15.5900 - val_mae: 2.8213\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.0893 - mae: 1.6284 - val_loss: 15.0965 - val_mae: 2.7716\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1125 - mae: 1.6274 - val_loss: 15.4379 - val_mae: 2.8245\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 5.0073 - mae: 1.6112 - val_loss: 15.3292 - val_mae: 2.8025\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.0061 - mae: 1.6141 - val_loss: 15.2489 - val_mae: 2.7861\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9080 - mae: 1.6025 - val_loss: 15.3788 - val_mae: 2.8158\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.9494 - mae: 1.5956 - val_loss: 15.2063 - val_mae: 2.8083\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.9504 - mae: 1.6099 - val_loss: 15.7441 - val_mae: 2.8492\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.8817 - mae: 1.5946 - val_loss: 15.4012 - val_mae: 2.8219\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.8997 - mae: 1.5915 - val_loss: 15.0285 - val_mae: 2.7733\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.7299 - mae: 1.5626 - val_loss: 15.6238 - val_mae: 2.8299\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7521 - mae: 1.5728 - val_loss: 15.5046 - val_mae: 2.8297\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7724 - mae: 1.5756 - val_loss: 15.4516 - val_mae: 2.8315\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.6800 - mae: 1.5566 - val_loss: 15.4331 - val_mae: 2.8128\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.6125 - mae: 1.5481 - val_loss: 15.6196 - val_mae: 2.8490\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.5049 - mae: 1.5351 - val_loss: 15.2273 - val_mae: 2.7964\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.5148 - mae: 1.5305 - val_loss: 15.3162 - val_mae: 2.7947\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.5288 - mae: 1.5398 - val_loss: 15.4921 - val_mae: 2.8270\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.4640 - mae: 1.5375 - val_loss: 15.2179 - val_mae: 2.7961\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5492 - mae: 1.5364 - val_loss: 15.9287 - val_mae: 2.8688\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3045 - mae: 1.4918 - val_loss: 15.0868 - val_mae: 2.7808\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.3281 - mae: 1.4943 - val_loss: 15.2120 - val_mae: 2.7945\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.3000 - mae: 1.5000 - val_loss: 15.5468 - val_mae: 2.8268\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.2244 - mae: 1.4835 - val_loss: 15.4041 - val_mae: 2.8196\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.2447 - mae: 1.4871 - val_loss: 15.0194 - val_mae: 2.7587\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1583 - mae: 1.4736 - val_loss: 15.8079 - val_mae: 2.8503\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1300 - mae: 1.4664 - val_loss: 15.3552 - val_mae: 2.8034\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.0995 - mae: 1.4599 - val_loss: 15.1213 - val_mae: 2.7769\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.0456 - mae: 1.4486 - val_loss: 15.4607 - val_mae: 2.8174\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.0682 - mae: 1.4470 - val_loss: 15.3424 - val_mae: 2.8147\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9505 - mae: 1.4278 - val_loss: 15.5029 - val_mae: 2.8154\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9546 - mae: 1.4303 - val_loss: 15.2558 - val_mae: 2.7871\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9241 - mae: 1.4269 - val_loss: 15.5251 - val_mae: 2.8222\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.9470 - mae: 1.4246 - val_loss: 15.5297 - val_mae: 2.8284\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9793 - mae: 1.4357 - val_loss: 15.2299 - val_mae: 2.7765\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.0227 - mae: 1.4393 - val_loss: 15.1476 - val_mae: 2.7931\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.8498 - mae: 1.4354 - val_loss: 15.9812 - val_mae: 2.8728\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8068 - mae: 1.4040 - val_loss: 14.9517 - val_mae: 2.7510\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.7870 - mae: 1.4014 - val_loss: 15.4295 - val_mae: 2.8031\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.8055 - mae: 1.4187 - val_loss: 15.5959 - val_mae: 2.8258\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7202 - mae: 1.3959 - val_loss: 14.9179 - val_mae: 2.7461\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.7948 - mae: 1.3973 - val_loss: 15.4784 - val_mae: 2.8075\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.7684 - mae: 1.4016 - val_loss: 15.2574 - val_mae: 2.8092\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6669 - mae: 1.3766 - val_loss: 15.2476 - val_mae: 2.7734\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6369 - mae: 1.3665 - val_loss: 15.2048 - val_mae: 2.7739\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6994 - mae: 1.3943 - val_loss: 15.4607 - val_mae: 2.8111\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.4914 - mae: 1.3377 - val_loss: 14.9981 - val_mae: 2.7535\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5306 - mae: 1.3606 - val_loss: 15.5839 - val_mae: 2.8211\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.4272 - mae: 1.3329 - val_loss: 15.1379 - val_mae: 2.7865\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5216 - mae: 1.3459 - val_loss: 15.4330 - val_mae: 2.8096\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.4598 - mae: 1.3347 - val_loss: 15.0221 - val_mae: 2.7479\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4114 - mae: 1.3326 - val_loss: 15.5760 - val_mae: 2.8192\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3650 - mae: 1.3194 - val_loss: 14.8690 - val_mae: 2.7273\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3716 - mae: 1.3185 - val_loss: 15.2800 - val_mae: 2.7845\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3131 - mae: 1.3073 - val_loss: 15.3883 - val_mae: 2.7965\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3042 - mae: 1.3061 - val_loss: 15.3437 - val_mae: 2.7899\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.2808 - mae: 1.2863 - val_loss: 15.4040 - val_mae: 2.7871\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.2557 - mae: 1.2854 - val_loss: 15.2034 - val_mae: 2.7775\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.2006 - mae: 1.2823 - val_loss: 15.3041 - val_mae: 2.7753\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.2222 - mae: 1.2946 - val_loss: 15.2046 - val_mae: 2.7617\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.2140 - mae: 1.2717 - val_loss: 15.3495 - val_mae: 2.7892\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1867 - mae: 1.2942 - val_loss: 15.3367 - val_mae: 2.7770\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1455 - mae: 1.2675 - val_loss: 15.0405 - val_mae: 2.7490\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1691 - mae: 1.2773 - val_loss: 15.3384 - val_mae: 2.7874\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1610 - mae: 1.2924 - val_loss: 15.2446 - val_mae: 2.7998\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0956 - mae: 1.2545 - val_loss: 14.9699 - val_mae: 2.7490\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0479 - mae: 1.2479 - val_loss: 15.6888 - val_mae: 2.8149\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0343 - mae: 1.2568 - val_loss: 15.1500 - val_mae: 2.7433\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9991 - mae: 1.2410 - val_loss: 15.3138 - val_mae: 2.7738\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.0162 - mae: 1.2450 - val_loss: 15.4603 - val_mae: 2.7795\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9565 - mae: 1.2271 - val_loss: 14.8774 - val_mae: 2.7295\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9655 - mae: 1.2323 - val_loss: 15.5790 - val_mae: 2.8091\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.9569 - mae: 1.2637 - val_loss: 15.1797 - val_mae: 2.7546\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.9411 - mae: 1.2273 - val_loss: 15.0516 - val_mae: 2.7375\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8637 - mae: 1.2112 - val_loss: 15.6930 - val_mae: 2.8252\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9005 - mae: 1.2275 - val_loss: 15.1091 - val_mae: 2.7589\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.8541 - mae: 1.2047 - val_loss: 15.1910 - val_mae: 2.7569\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.9002 - mae: 1.2357 - val_loss: 15.4853 - val_mae: 2.7906\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.8036 - mae: 1.1995 - val_loss: 15.0224 - val_mae: 2.7325\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8209 - mae: 1.2011 - val_loss: 15.4023 - val_mae: 2.7745\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.7658 - mae: 1.1983 - val_loss: 15.0893 - val_mae: 2.7510\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.7643 - mae: 1.1855 - val_loss: 15.1265 - val_mae: 2.7634\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.7903 - mae: 1.2035 - val_loss: 15.3285 - val_mae: 2.7548\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.7580 - mae: 1.2044 - val_loss: 15.1330 - val_mae: 2.7456\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9046 - mae: 1.2398 - val_loss: 15.3955 - val_mae: 2.7633\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.8872 - mae: 1.2180 - val_loss: 14.7918 - val_mae: 2.7239\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7946 - mae: 1.2212 - val_loss: 15.9345 - val_mae: 2.8391\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6196 - mae: 1.1762 - val_loss: 14.7624 - val_mae: 2.7149\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6615 - mae: 1.1737 - val_loss: 15.7991 - val_mae: 2.8038\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.6868 - mae: 1.1914 - val_loss: 14.9450 - val_mae: 2.7173\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.6423 - mae: 1.1751 - val_loss: 15.2651 - val_mae: 2.7715\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6416 - mae: 1.1900 - val_loss: 15.2938 - val_mae: 2.7667\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5602 - mae: 1.1614 - val_loss: 15.0940 - val_mae: 2.7363\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.5430 - mae: 1.1566 - val_loss: 15.2786 - val_mae: 2.7523\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.5117 - mae: 1.1455 - val_loss: 15.0206 - val_mae: 2.7260\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.4933 - mae: 1.1495 - val_loss: 14.9673 - val_mae: 2.7316\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.4256 - mae: 1.1229 - val_loss: 15.2292 - val_mae: 2.7427\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.4777 - mae: 1.1340 - val_loss: 14.6698 - val_mae: 2.6882\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.4893 - mae: 1.1487 - val_loss: 15.9525 - val_mae: 2.8162\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.4863 - mae: 1.1502 - val_loss: 14.9317 - val_mae: 2.6978\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3818 - mae: 1.1101 - val_loss: 15.1560 - val_mae: 2.7357\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3399 - mae: 1.0995 - val_loss: 15.1967 - val_mae: 2.7405\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.4720 - mae: 1.1220 - val_loss: 14.9190 - val_mae: 2.7212\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.4337 - mae: 1.1578 - val_loss: 15.0467 - val_mae: 2.7245\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.4053 - mae: 1.1136 - val_loss: 14.9949 - val_mae: 2.7181\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.3641 - mae: 1.1216 - val_loss: 15.2898 - val_mae: 2.7567\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3456 - mae: 1.1057 - val_loss: 14.9783 - val_mae: 2.7131\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.2200 - mae: 1.0850 - val_loss: 15.2188 - val_mae: 2.7355\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2776 - mae: 1.1059 - val_loss: 14.8857 - val_mae: 2.7063\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2521 - mae: 1.0779 - val_loss: 15.1712 - val_mae: 2.7358\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.2183 - mae: 1.0883 - val_loss: 14.9642 - val_mae: 2.7062\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.1808 - mae: 1.0747 - val_loss: 15.1058 - val_mae: 2.7335\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.3598 - mae: 1.1413 - val_loss: 15.1991 - val_mae: 2.7244\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.2612 - mae: 1.0844 - val_loss: 14.5335 - val_mae: 2.6630\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.2283 - mae: 1.1052 - val_loss: 15.7606 - val_mae: 2.8123\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.3027 - mae: 1.1226 - val_loss: 14.8018 - val_mae: 2.6961\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1772 - mae: 1.0813 - val_loss: 15.2555 - val_mae: 2.7259\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1638 - mae: 1.0924 - val_loss: 15.2335 - val_mae: 2.7228\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1904 - mae: 1.0785 - val_loss: 14.6636 - val_mae: 2.6828\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.0544 - mae: 1.0741 - val_loss: 15.7713 - val_mae: 2.8117\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1058 - mae: 1.0659 - val_loss: 14.5346 - val_mae: 2.6556\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.1261 - mae: 1.0597 - val_loss: 15.5464 - val_mae: 2.7686\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.0820 - mae: 1.0788 - val_loss: 15.2237 - val_mae: 2.7501\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1525 - mae: 1.0650 - val_loss: 15.1277 - val_mae: 2.7310\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0293 - mae: 1.0316 - val_loss: 15.3755 - val_mae: 2.7646\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9791 - mae: 1.0103 - val_loss: 14.9813 - val_mae: 2.7207\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9121 - mae: 1.0029 - val_loss: 15.3748 - val_mae: 2.7588\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9516 - mae: 1.0157 - val_loss: 15.0019 - val_mae: 2.7093\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8830 - mae: 0.9830 - val_loss: 15.0364 - val_mae: 2.7109\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9114 - mae: 1.0099 - val_loss: 14.8516 - val_mae: 2.7058\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9663 - mae: 1.0094 - val_loss: 15.0512 - val_mae: 2.7242\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1648 - mae: 1.1138 - val_loss: 15.4824 - val_mae: 2.7552\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1703 - mae: 1.1279 - val_loss: 14.4265 - val_mae: 2.6445\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.9335 - mae: 1.0323 - val_loss: 15.5816 - val_mae: 2.7757\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8472 - mae: 1.0115 - val_loss: 14.6087 - val_mae: 2.6795\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8089 - mae: 0.9753 - val_loss: 15.3127 - val_mae: 2.7334\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7420 - mae: 0.9594 - val_loss: 15.0228 - val_mae: 2.7312\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.7685 - mae: 0.9750 - val_loss: 15.1990 - val_mae: 2.7312\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7699 - mae: 0.9505 - val_loss: 15.0531 - val_mae: 2.7253\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6902 - mae: 0.9414 - val_loss: 15.1937 - val_mae: 2.7223\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7240 - mae: 0.9384 - val_loss: 14.9605 - val_mae: 2.7163\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.8504 - mae: 1.0067 - val_loss: 15.2655 - val_mae: 2.7288\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8255 - mae: 0.9833 - val_loss: 14.7387 - val_mae: 2.6960\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6591 - mae: 0.9452 - val_loss: 15.4095 - val_mae: 2.7545\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6540 - mae: 0.9312 - val_loss: 14.6015 - val_mae: 2.6782\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.6711 - mae: 0.9318 - val_loss: 15.2277 - val_mae: 2.7306\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.6261 - mae: 0.9170 - val_loss: 14.8177 - val_mae: 2.7159\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6665 - mae: 0.9432 - val_loss: 14.7749 - val_mae: 2.6841\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.6274 - mae: 0.9248 - val_loss: 15.2238 - val_mae: 2.7658\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6861 - mae: 0.9742 - val_loss: 15.1232 - val_mae: 2.7280\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.7102 - mae: 0.9686 - val_loss: 14.8844 - val_mae: 2.7004\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6830 - mae: 0.9770 - val_loss: 15.1777 - val_mae: 2.7630\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6895 - mae: 0.9384 - val_loss: 14.9195 - val_mae: 2.7186\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6401 - mae: 0.9762 - val_loss: 15.2011 - val_mae: 2.7396\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6280 - mae: 0.9408 - val_loss: 14.9792 - val_mae: 2.7129\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5418 - mae: 0.9236 - val_loss: 15.0949 - val_mae: 2.7137\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4878 - mae: 0.8878 - val_loss: 14.7118 - val_mae: 2.7214\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5255 - mae: 0.8971 - val_loss: 15.1652 - val_mae: 2.7365\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5192 - mae: 0.9186 - val_loss: 14.6554 - val_mae: 2.6694\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4561 - mae: 0.8756 - val_loss: 15.2345 - val_mae: 2.7511\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5119 - mae: 0.9118 - val_loss: 14.8563 - val_mae: 2.7090\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5158 - mae: 0.8891 - val_loss: 15.1633 - val_mae: 2.7246\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4481 - mae: 0.8851 - val_loss: 14.9544 - val_mae: 2.7334\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4464 - mae: 0.8738 - val_loss: 15.2057 - val_mae: 2.7314\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4305 - mae: 0.8713 - val_loss: 15.0680 - val_mae: 2.7502\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4155 - mae: 0.8608 - val_loss: 14.8721 - val_mae: 2.6931\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3318 - mae: 0.8333 - val_loss: 14.9768 - val_mae: 2.7339\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3379 - mae: 0.8386 - val_loss: 15.1159 - val_mae: 2.7201\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3490 - mae: 0.8520 - val_loss: 14.6097 - val_mae: 2.7092\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3427 - mae: 0.8318 - val_loss: 14.9659 - val_mae: 2.7313\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3080 - mae: 0.8283 - val_loss: 14.8461 - val_mae: 2.7009\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3513 - mae: 0.8445 - val_loss: 14.8840 - val_mae: 2.7288\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2784 - mae: 0.8039 - val_loss: 15.0684 - val_mae: 2.7249\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2886 - mae: 0.8099 - val_loss: 14.8125 - val_mae: 2.7431\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2729 - mae: 0.8126 - val_loss: 14.9656 - val_mae: 2.6968\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2671 - mae: 0.8165 - val_loss: 15.1665 - val_mae: 2.7586\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2403 - mae: 0.8218 - val_loss: 14.7214 - val_mae: 2.6942\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2817 - mae: 0.8228 - val_loss: 14.9437 - val_mae: 2.7379\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1732 - mae: 0.7805 - val_loss: 14.8810 - val_mae: 2.7301\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1810 - mae: 0.7768 - val_loss: 14.7490 - val_mae: 2.6957\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1502 - mae: 0.7693 - val_loss: 14.9194 - val_mae: 2.7520\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.2278 - mae: 0.8109 - val_loss: 15.1090 - val_mae: 2.7470\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3380 - mae: 0.8709 - val_loss: 14.5406 - val_mae: 2.6732\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2605 - mae: 0.8319 - val_loss: 15.1867 - val_mae: 2.7448\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2393 - mae: 0.8074 - val_loss: 14.5190 - val_mae: 2.7072\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.1703 - mae: 0.7729 - val_loss: 15.0190 - val_mae: 2.7547\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 25.1411 - mae: 3.2168\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 34ms/step - loss: 558.8118 - mae: 21.9859 - val_loss: 533.2831 - val_mae: 21.0758\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 531.8316 - mae: 21.3802 - val_loss: 508.6438 - val_mae: 20.4861\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 504.2003 - mae: 20.7402 - val_loss: 478.1883 - val_mae: 19.7391\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 467.0598 - mae: 19.8325 - val_loss: 435.0368 - val_mae: 18.6334\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 417.1582 - mae: 18.5161 - val_loss: 375.9866 - val_mae: 17.0006\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 348.6140 - mae: 16.6224 - val_loss: 300.9771 - val_mae: 14.9762\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 264.4768 - mae: 14.1001 - val_loss: 216.2209 - val_mae: 12.5965\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 176.4406 - mae: 11.1172 - val_loss: 139.1626 - val_mae: 9.8349\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 104.2804 - mae: 8.2932 - val_loss: 93.5048 - val_mae: 7.8766\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 75.7230 - mae: 7.1020 - val_loss: 79.0831 - val_mae: 6.9137\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 67.8966 - mae: 6.6726 - val_loss: 66.3616 - val_mae: 6.1678\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 52.9700 - mae: 5.8219 - val_loss: 50.5016 - val_mae: 5.2348\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 39.1691 - mae: 4.9641 - val_loss: 42.4908 - val_mae: 4.6820\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 32.1441 - mae: 4.3710 - val_loss: 38.0086 - val_mae: 4.3034\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 27.6944 - mae: 4.0002 - val_loss: 34.7063 - val_mae: 4.0092\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.9682 - mae: 3.7244 - val_loss: 32.9295 - val_mae: 3.8463\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 21.8561 - mae: 3.5350 - val_loss: 32.0642 - val_mae: 3.8141\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 20.6289 - mae: 3.4722 - val_loss: 31.0590 - val_mae: 3.7363\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.4193 - mae: 3.3676 - val_loss: 30.1413 - val_mae: 3.6317\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 18.6442 - mae: 3.2762 - val_loss: 29.4221 - val_mae: 3.5681\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.9780 - mae: 3.1954 - val_loss: 28.5877 - val_mae: 3.4996\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.3803 - mae: 3.1539 - val_loss: 27.9313 - val_mae: 3.4944\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 16.6962 - mae: 3.0948 - val_loss: 27.3170 - val_mae: 3.4508\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 16.2379 - mae: 3.0377 - val_loss: 26.5852 - val_mae: 3.4120\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.8046 - mae: 2.9890 - val_loss: 26.0404 - val_mae: 3.3543\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 15.3459 - mae: 2.9317 - val_loss: 25.4706 - val_mae: 3.3205\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.0917 - mae: 2.9064 - val_loss: 24.9514 - val_mae: 3.3228\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.7312 - mae: 2.8676 - val_loss: 24.2219 - val_mae: 3.2084\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 14.3038 - mae: 2.8068 - val_loss: 23.7863 - val_mae: 3.1544\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 13.9786 - mae: 2.7699 - val_loss: 23.3369 - val_mae: 3.1490\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 13.6151 - mae: 2.7329 - val_loss: 22.8702 - val_mae: 3.0905\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 13.3622 - mae: 2.6928 - val_loss: 22.6993 - val_mae: 3.0497\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 13.0880 - mae: 2.6527 - val_loss: 22.2365 - val_mae: 3.0251\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.8051 - mae: 2.6292 - val_loss: 21.9305 - val_mae: 3.0013\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.5722 - mae: 2.6005 - val_loss: 21.7139 - val_mae: 2.9804\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.3821 - mae: 2.5888 - val_loss: 21.2910 - val_mae: 2.9554\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.0891 - mae: 2.5531 - val_loss: 21.0601 - val_mae: 2.9279\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.8683 - mae: 2.5285 - val_loss: 20.8477 - val_mae: 2.9046\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.6390 - mae: 2.4983 - val_loss: 20.7775 - val_mae: 2.8792\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.5117 - mae: 2.4760 - val_loss: 20.6637 - val_mae: 2.8634\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.3336 - mae: 2.4657 - val_loss: 20.3201 - val_mae: 2.8518\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.1977 - mae: 2.4638 - val_loss: 19.9237 - val_mae: 2.8320\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.9773 - mae: 2.4526 - val_loss: 19.8454 - val_mae: 2.8087\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.8060 - mae: 2.4333 - val_loss: 19.6919 - val_mae: 2.7755\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 10.6510 - mae: 2.4004 - val_loss: 19.5968 - val_mae: 2.7484\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.4917 - mae: 2.3779 - val_loss: 19.3691 - val_mae: 2.7347\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.5802 - mae: 2.4139 - val_loss: 19.0291 - val_mae: 2.7494\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.2087 - mae: 2.3737 - val_loss: 19.0991 - val_mae: 2.7258\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0787 - mae: 2.3398 - val_loss: 18.9483 - val_mae: 2.6871\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.9602 - mae: 2.3183 - val_loss: 18.7865 - val_mae: 2.6731\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.8611 - mae: 2.3240 - val_loss: 18.6045 - val_mae: 2.6731\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.7813 - mae: 2.3015 - val_loss: 18.5856 - val_mae: 2.6469\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.5609 - mae: 2.2729 - val_loss: 18.3898 - val_mae: 2.6397\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.4285 - mae: 2.2728 - val_loss: 18.3093 - val_mae: 2.6374\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.4027 - mae: 2.2824 - val_loss: 18.0088 - val_mae: 2.6388\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.2488 - mae: 2.2463 - val_loss: 18.0836 - val_mae: 2.6021\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.0790 - mae: 2.2206 - val_loss: 17.8789 - val_mae: 2.5839\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.9909 - mae: 2.2105 - val_loss: 17.8171 - val_mae: 2.5721\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.8807 - mae: 2.2090 - val_loss: 17.5288 - val_mae: 2.5702\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 8.8629 - mae: 2.2085 - val_loss: 17.6221 - val_mae: 2.5583\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.6315 - mae: 2.1745 - val_loss: 17.4080 - val_mae: 2.5611\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.5830 - mae: 2.1756 - val_loss: 17.1315 - val_mae: 2.5622\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.5451 - mae: 2.1815 - val_loss: 17.2032 - val_mae: 2.5371\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.4275 - mae: 2.1466 - val_loss: 17.1855 - val_mae: 2.5340\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.2746 - mae: 2.1354 - val_loss: 17.0011 - val_mae: 2.5432\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.2610 - mae: 2.1478 - val_loss: 16.8164 - val_mae: 2.5362\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.1298 - mae: 2.1315 - val_loss: 16.7293 - val_mae: 2.5143\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.0003 - mae: 2.1048 - val_loss: 16.8935 - val_mae: 2.4960\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.9941 - mae: 2.0832 - val_loss: 16.8511 - val_mae: 2.4989\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.8328 - mae: 2.0719 - val_loss: 16.6355 - val_mae: 2.5324\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.8032 - mae: 2.0739 - val_loss: 16.6846 - val_mae: 2.5293\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.6784 - mae: 2.0519 - val_loss: 16.4557 - val_mae: 2.5041\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.6514 - mae: 2.0448 - val_loss: 16.3053 - val_mae: 2.4982\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.4962 - mae: 2.0374 - val_loss: 16.2571 - val_mae: 2.5146\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 7.5283 - mae: 2.0440 - val_loss: 16.2773 - val_mae: 2.4950\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.4799 - mae: 2.0253 - val_loss: 16.2840 - val_mae: 2.4842\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.3558 - mae: 2.0072 - val_loss: 16.1265 - val_mae: 2.5249\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.1909 - mae: 1.9901 - val_loss: 16.1052 - val_mae: 2.4963\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.1201 - mae: 1.9786 - val_loss: 16.0750 - val_mae: 2.4868\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.0722 - mae: 1.9629 - val_loss: 16.1151 - val_mae: 2.4797\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.9917 - mae: 1.9549 - val_loss: 16.0325 - val_mae: 2.4896\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.9323 - mae: 1.9426 - val_loss: 16.0425 - val_mae: 2.4931\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.8470 - mae: 1.9251 - val_loss: 15.7649 - val_mae: 2.4911\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.8668 - mae: 1.9307 - val_loss: 15.6641 - val_mae: 2.4688\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.7443 - mae: 1.9169 - val_loss: 15.6878 - val_mae: 2.4751\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.6543 - mae: 1.9031 - val_loss: 15.6021 - val_mae: 2.4764\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.5973 - mae: 1.8903 - val_loss: 15.4941 - val_mae: 2.4845\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4986 - mae: 1.8801 - val_loss: 15.5076 - val_mae: 2.4684\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.4555 - mae: 1.8681 - val_loss: 15.3418 - val_mae: 2.4653\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3902 - mae: 1.8546 - val_loss: 15.2981 - val_mae: 2.4578\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3508 - mae: 1.8573 - val_loss: 15.4386 - val_mae: 2.4480\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.2881 - mae: 1.8394 - val_loss: 15.4591 - val_mae: 2.4815\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.2431 - mae: 1.8283 - val_loss: 15.3272 - val_mae: 2.4882\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.1815 - mae: 1.8074 - val_loss: 15.0879 - val_mae: 2.4667\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0646 - mae: 1.7929 - val_loss: 15.2204 - val_mae: 2.4717\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.0318 - mae: 1.7954 - val_loss: 15.1156 - val_mae: 2.4699\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.9417 - mae: 1.7841 - val_loss: 14.8908 - val_mae: 2.4422\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8761 - mae: 1.7734 - val_loss: 14.9231 - val_mae: 2.4375\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.7751 - mae: 1.7527 - val_loss: 14.9602 - val_mae: 2.4582\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.7398 - mae: 1.7389 - val_loss: 15.0514 - val_mae: 2.4761\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6660 - mae: 1.7237 - val_loss: 14.9195 - val_mae: 2.4668\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7529 - mae: 1.7412 - val_loss: 14.8198 - val_mae: 2.4639\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5594 - mae: 1.6925 - val_loss: 14.8569 - val_mae: 2.4927\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.5085 - mae: 1.6967 - val_loss: 14.7532 - val_mae: 2.4597\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.3991 - mae: 1.6820 - val_loss: 14.7429 - val_mae: 2.4731\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.2840 - mae: 1.6671 - val_loss: 14.7772 - val_mae: 2.4837\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3239 - mae: 1.6611 - val_loss: 14.8083 - val_mae: 2.4822\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.3203 - mae: 1.6725 - val_loss: 14.7200 - val_mae: 2.5103\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.1499 - mae: 1.6389 - val_loss: 14.7676 - val_mae: 2.4596\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.1106 - mae: 1.6432 - val_loss: 14.5619 - val_mae: 2.4606\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.0136 - mae: 1.6156 - val_loss: 14.4332 - val_mae: 2.4637\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9992 - mae: 1.6176 - val_loss: 14.4622 - val_mae: 2.4764\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9008 - mae: 1.5860 - val_loss: 14.3993 - val_mae: 2.4572\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8849 - mae: 1.6001 - val_loss: 14.3808 - val_mae: 2.4503\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.9594 - mae: 1.6127 - val_loss: 14.3701 - val_mae: 2.4767\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.8189 - mae: 1.5805 - val_loss: 14.4409 - val_mae: 2.4689\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.7629 - mae: 1.5937 - val_loss: 14.5216 - val_mae: 2.4857\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.6112 - mae: 1.5457 - val_loss: 14.2124 - val_mae: 2.4632\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6066 - mae: 1.5571 - val_loss: 14.3524 - val_mae: 2.4550\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4817 - mae: 1.5335 - val_loss: 14.2730 - val_mae: 2.4642\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 4.4781 - mae: 1.5206 - val_loss: 14.0599 - val_mae: 2.4606\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3593 - mae: 1.5102 - val_loss: 14.1837 - val_mae: 2.4574\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3696 - mae: 1.5238 - val_loss: 14.2839 - val_mae: 2.4582\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.2679 - mae: 1.4975 - val_loss: 14.1580 - val_mae: 2.4794\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.1989 - mae: 1.4791 - val_loss: 14.0806 - val_mae: 2.4448\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1449 - mae: 1.4775 - val_loss: 14.0726 - val_mae: 2.4440\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1113 - mae: 1.4763 - val_loss: 14.0920 - val_mae: 2.4600\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.0714 - mae: 1.4659 - val_loss: 14.0076 - val_mae: 2.4694\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.0083 - mae: 1.4439 - val_loss: 14.0738 - val_mae: 2.4632\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9767 - mae: 1.4431 - val_loss: 13.9674 - val_mae: 2.4628\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.9255 - mae: 1.4199 - val_loss: 14.0173 - val_mae: 2.4530\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8208 - mae: 1.4199 - val_loss: 13.9781 - val_mae: 2.4606\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8152 - mae: 1.4114 - val_loss: 13.7580 - val_mae: 2.4310\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.7894 - mae: 1.4022 - val_loss: 13.6861 - val_mae: 2.4308\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6085 - mae: 1.3856 - val_loss: 13.8292 - val_mae: 2.4225\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.7007 - mae: 1.3874 - val_loss: 13.9980 - val_mae: 2.4583\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5970 - mae: 1.3777 - val_loss: 13.8931 - val_mae: 2.4740\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6144 - mae: 1.3711 - val_loss: 13.7905 - val_mae: 2.4582\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.4695 - mae: 1.3516 - val_loss: 13.8978 - val_mae: 2.4363\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.4448 - mae: 1.3391 - val_loss: 13.7160 - val_mae: 2.4443\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.4452 - mae: 1.3557 - val_loss: 13.7533 - val_mae: 2.4618\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.5043 - mae: 1.3657 - val_loss: 13.9433 - val_mae: 2.4376\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.4120 - mae: 1.3369 - val_loss: 13.8685 - val_mae: 2.4923\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.3171 - mae: 1.3387 - val_loss: 13.6815 - val_mae: 2.4216\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2512 - mae: 1.3137 - val_loss: 13.8608 - val_mae: 2.4655\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.1261 - mae: 1.2957 - val_loss: 13.7108 - val_mae: 2.4688\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.0772 - mae: 1.2735 - val_loss: 13.5776 - val_mae: 2.4254\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0535 - mae: 1.2756 - val_loss: 13.6189 - val_mae: 2.4411\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.0463 - mae: 1.2798 - val_loss: 13.7404 - val_mae: 2.4669\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1161 - mae: 1.2788 - val_loss: 13.6260 - val_mae: 2.4671\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8916 - mae: 1.2440 - val_loss: 13.6306 - val_mae: 2.4634\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8849 - mae: 1.2552 - val_loss: 13.6134 - val_mae: 2.4407\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9083 - mae: 1.2439 - val_loss: 13.6801 - val_mae: 2.4702\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7791 - mae: 1.2278 - val_loss: 13.6579 - val_mae: 2.4870\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.7052 - mae: 1.2036 - val_loss: 13.5738 - val_mae: 2.4599\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.7083 - mae: 1.1983 - val_loss: 13.4730 - val_mae: 2.4447\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.6281 - mae: 1.1779 - val_loss: 13.5172 - val_mae: 2.4742\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6546 - mae: 1.1834 - val_loss: 13.6398 - val_mae: 2.4602\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.5061 - mae: 1.1674 - val_loss: 13.5571 - val_mae: 2.4738\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.5891 - mae: 1.1680 - val_loss: 13.4147 - val_mae: 2.4659\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.5451 - mae: 1.1630 - val_loss: 13.4344 - val_mae: 2.4605\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.3951 - mae: 1.1473 - val_loss: 13.4228 - val_mae: 2.4769\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.5483 - mae: 1.1685 - val_loss: 13.4984 - val_mae: 2.4544\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.3637 - mae: 1.1331 - val_loss: 13.5468 - val_mae: 2.4906\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.3479 - mae: 1.1158 - val_loss: 13.4691 - val_mae: 2.4715\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3765 - mae: 1.1189 - val_loss: 13.4044 - val_mae: 2.4851\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.2293 - mae: 1.0968 - val_loss: 13.4866 - val_mae: 2.4810\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.1853 - mae: 1.0839 - val_loss: 13.5769 - val_mae: 2.4975\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.1612 - mae: 1.0748 - val_loss: 13.5804 - val_mae: 2.5150\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.1346 - mae: 1.0771 - val_loss: 13.5625 - val_mae: 2.5025\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0686 - mae: 1.0826 - val_loss: 13.5344 - val_mae: 2.5031\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.0865 - mae: 1.0639 - val_loss: 13.4623 - val_mae: 2.4945\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.0061 - mae: 1.0386 - val_loss: 13.6238 - val_mae: 2.5202\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.0026 - mae: 1.0397 - val_loss: 13.6342 - val_mae: 2.5249\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9296 - mae: 1.0097 - val_loss: 13.5767 - val_mae: 2.5193\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.9214 - mae: 1.0208 - val_loss: 13.5717 - val_mae: 2.5167\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.9451 - mae: 1.0214 - val_loss: 13.7328 - val_mae: 2.5272\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8951 - mae: 1.0156 - val_loss: 13.8276 - val_mae: 2.5699\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8973 - mae: 0.9988 - val_loss: 13.6060 - val_mae: 2.5264\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7527 - mae: 0.9697 - val_loss: 13.6818 - val_mae: 2.5527\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7862 - mae: 0.9992 - val_loss: 13.6453 - val_mae: 2.5421\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.7459 - mae: 0.9679 - val_loss: 13.7355 - val_mae: 2.5548\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6831 - mae: 0.9625 - val_loss: 13.8194 - val_mae: 2.5540\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6337 - mae: 0.9429 - val_loss: 13.7885 - val_mae: 2.5609\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6510 - mae: 0.9304 - val_loss: 13.6404 - val_mae: 2.5559\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6018 - mae: 0.9217 - val_loss: 13.7533 - val_mae: 2.5601\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6127 - mae: 0.9407 - val_loss: 13.8117 - val_mae: 2.5689\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5781 - mae: 0.9266 - val_loss: 13.8434 - val_mae: 2.5785\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5353 - mae: 0.9132 - val_loss: 13.8912 - val_mae: 2.5894\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.5451 - mae: 0.9189 - val_loss: 13.7454 - val_mae: 2.5626\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5165 - mae: 0.8925 - val_loss: 13.7259 - val_mae: 2.5682\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4662 - mae: 0.8884 - val_loss: 13.8670 - val_mae: 2.5845\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4464 - mae: 0.8965 - val_loss: 13.9141 - val_mae: 2.5857\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4223 - mae: 0.8842 - val_loss: 13.8676 - val_mae: 2.5821\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4752 - mae: 0.8924 - val_loss: 13.8646 - val_mae: 2.5904\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3902 - mae: 0.8615 - val_loss: 13.9117 - val_mae: 2.5820\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3785 - mae: 0.8687 - val_loss: 13.9665 - val_mae: 2.5942\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4177 - mae: 0.8581 - val_loss: 13.9670 - val_mae: 2.5958\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3653 - mae: 0.8640 - val_loss: 14.0015 - val_mae: 2.6085\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3936 - mae: 0.8443 - val_loss: 14.0376 - val_mae: 2.6105\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3051 - mae: 0.8508 - val_loss: 14.0974 - val_mae: 2.6084\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3082 - mae: 0.8346 - val_loss: 13.9852 - val_mae: 2.6041\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2723 - mae: 0.8228 - val_loss: 14.0644 - val_mae: 2.6149\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2160 - mae: 0.7990 - val_loss: 14.1457 - val_mae: 2.6174\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2089 - mae: 0.8065 - val_loss: 14.2222 - val_mae: 2.6254\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2167 - mae: 0.8125 - val_loss: 14.1607 - val_mae: 2.6218\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2786 - mae: 0.8123 - val_loss: 14.1164 - val_mae: 2.6175\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2837 - mae: 0.8348 - val_loss: 14.1187 - val_mae: 2.6087\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1944 - mae: 0.7943 - val_loss: 14.2119 - val_mae: 2.6266\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.1475 - mae: 0.7672 - val_loss: 14.2941 - val_mae: 2.6340\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1865 - mae: 0.8001 - val_loss: 14.3302 - val_mae: 2.6384\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1243 - mae: 0.7661 - val_loss: 14.2306 - val_mae: 2.6368\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1004 - mae: 0.7623 - val_loss: 14.2011 - val_mae: 2.6193\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.0836 - mae: 0.7527 - val_loss: 14.2919 - val_mae: 2.6333\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1039 - mae: 0.7634 - val_loss: 14.4213 - val_mae: 2.6605\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.0618 - mae: 0.7424 - val_loss: 14.3944 - val_mae: 2.6481\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0817 - mae: 0.7553 - val_loss: 14.3479 - val_mae: 2.6386\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.0474 - mae: 0.7287 - val_loss: 14.3622 - val_mae: 2.6451\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0297 - mae: 0.7388 - val_loss: 14.4218 - val_mae: 2.6550\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0131 - mae: 0.7207 - val_loss: 14.4085 - val_mae: 2.6620\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0022 - mae: 0.7157 - val_loss: 14.5587 - val_mae: 2.6773\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0673 - mae: 0.7486 - val_loss: 14.6013 - val_mae: 2.6631\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.9971 - mae: 0.7283 - val_loss: 14.5532 - val_mae: 2.6662\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.0136 - mae: 0.7039 - val_loss: 14.5348 - val_mae: 2.6586\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0105 - mae: 0.7339 - val_loss: 14.6681 - val_mae: 2.6805\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.0164 - mae: 0.7291 - val_loss: 14.6213 - val_mae: 2.6786\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.9380 - mae: 0.7053 - val_loss: 14.5948 - val_mae: 2.6756\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.9553 - mae: 0.7191 - val_loss: 14.5390 - val_mae: 2.6555\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.9694 - mae: 0.7006 - val_loss: 14.7415 - val_mae: 2.6899\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8964 - mae: 0.6825 - val_loss: 14.5433 - val_mae: 2.6568\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.9714 - mae: 0.7172 - val_loss: 14.6291 - val_mae: 2.6607\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.9672 - mae: 0.7079 - val_loss: 14.6152 - val_mae: 2.6791\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.9123 - mae: 0.6915 - val_loss: 14.6941 - val_mae: 2.6968\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8996 - mae: 0.6726 - val_loss: 14.6409 - val_mae: 2.6643\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8601 - mae: 0.6590 - val_loss: 14.6723 - val_mae: 2.6758\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.9112 - mae: 0.6860 - val_loss: 14.6624 - val_mae: 2.6851\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.8705 - mae: 0.6604 - val_loss: 14.7648 - val_mae: 2.6920\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8477 - mae: 0.6543 - val_loss: 14.8993 - val_mae: 2.7055\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8689 - mae: 0.6559 - val_loss: 14.7342 - val_mae: 2.6727\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8741 - mae: 0.6586 - val_loss: 14.7720 - val_mae: 2.6864\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8342 - mae: 0.6448 - val_loss: 14.8982 - val_mae: 2.6923\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8195 - mae: 0.6424 - val_loss: 14.7860 - val_mae: 2.6890\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8163 - mae: 0.6282 - val_loss: 14.8748 - val_mae: 2.6993\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8632 - mae: 0.6718 - val_loss: 14.7875 - val_mae: 2.6787\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8600 - mae: 0.6753 - val_loss: 14.8768 - val_mae: 2.6882\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.8355 - mae: 0.6662 - val_loss: 14.7934 - val_mae: 2.6933\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.9544 - mae: 0.6991 - val_loss: 14.9272 - val_mae: 2.7150\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.9216 - mae: 0.7236 - val_loss: 14.9929 - val_mae: 2.6864\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.8321 - mae: 0.6549 - val_loss: 15.0225 - val_mae: 2.7203\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8162 - mae: 0.6502 - val_loss: 14.8797 - val_mae: 2.6949\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7731 - mae: 0.6138 - val_loss: 14.8586 - val_mae: 2.6821\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7350 - mae: 0.6006 - val_loss: 14.9538 - val_mae: 2.6967\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7503 - mae: 0.6003 - val_loss: 15.0894 - val_mae: 2.7139\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.7094 - mae: 0.5855 - val_loss: 15.0183 - val_mae: 2.7077\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7295 - mae: 0.5932 - val_loss: 14.9737 - val_mae: 2.6987\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.7533 - mae: 0.6293 - val_loss: 15.0244 - val_mae: 2.7053\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7582 - mae: 0.6124 - val_loss: 14.9961 - val_mae: 2.6882\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.8170 - mae: 0.6483 - val_loss: 15.0778 - val_mae: 2.7250\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.7533 - mae: 0.6155 - val_loss: 15.0473 - val_mae: 2.7146\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7076 - mae: 0.5848 - val_loss: 15.0025 - val_mae: 2.6951\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7116 - mae: 0.5867 - val_loss: 15.1408 - val_mae: 2.7192\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.7382 - mae: 0.6166 - val_loss: 15.0400 - val_mae: 2.7146\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7377 - mae: 0.6285 - val_loss: 15.2036 - val_mae: 2.7395\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7842 - mae: 0.6691 - val_loss: 15.1312 - val_mae: 2.7081\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7803 - mae: 0.6388 - val_loss: 15.2378 - val_mae: 2.7445\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.7892 - mae: 0.6529 - val_loss: 15.1889 - val_mae: 2.7239\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6975 - mae: 0.5797 - val_loss: 15.1799 - val_mae: 2.7225\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6974 - mae: 0.5935 - val_loss: 15.1147 - val_mae: 2.7109\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7164 - mae: 0.5798 - val_loss: 15.3366 - val_mae: 2.7286\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7149 - mae: 0.6022 - val_loss: 15.1926 - val_mae: 2.7220\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6909 - mae: 0.5900 - val_loss: 15.2804 - val_mae: 2.7455\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.7316 - mae: 0.6285 - val_loss: 15.1251 - val_mae: 2.7094\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6924 - mae: 0.5760 - val_loss: 15.1928 - val_mae: 2.7134\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.6939 - mae: 0.5942 - val_loss: 15.2205 - val_mae: 2.7217\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6312 - mae: 0.5507 - val_loss: 15.3436 - val_mae: 2.7327\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6156 - mae: 0.5423 - val_loss: 15.1930 - val_mae: 2.7160\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6031 - mae: 0.5277 - val_loss: 15.2925 - val_mae: 2.7330\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.6143 - mae: 0.5456 - val_loss: 15.4563 - val_mae: 2.7674\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5955 - mae: 0.5289 - val_loss: 15.2485 - val_mae: 2.7132\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6141 - mae: 0.5445 - val_loss: 15.3094 - val_mae: 2.7275\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6224 - mae: 0.5455 - val_loss: 15.4650 - val_mae: 2.7554\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5877 - mae: 0.5438 - val_loss: 15.4095 - val_mae: 2.7562\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5648 - mae: 0.5161 - val_loss: 15.2044 - val_mae: 2.7198\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5705 - mae: 0.5103 - val_loss: 15.3907 - val_mae: 2.7399\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5649 - mae: 0.5121 - val_loss: 15.4164 - val_mae: 2.7558\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5579 - mae: 0.5199 - val_loss: 15.3943 - val_mae: 2.7462\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5556 - mae: 0.5142 - val_loss: 15.4845 - val_mae: 2.7522\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5518 - mae: 0.5020 - val_loss: 15.4905 - val_mae: 2.7585\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5572 - mae: 0.5114 - val_loss: 15.4393 - val_mae: 2.7534\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5313 - mae: 0.4918 - val_loss: 15.6098 - val_mae: 2.7678\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5912 - mae: 0.5243 - val_loss: 15.4403 - val_mae: 2.7466\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.5619 - mae: 0.5130 - val_loss: 15.5015 - val_mae: 2.7606\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5529 - mae: 0.5241 - val_loss: 15.5862 - val_mae: 2.7718\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5508 - mae: 0.5013 - val_loss: 15.5585 - val_mae: 2.7608\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5399 - mae: 0.5081 - val_loss: 15.5296 - val_mae: 2.7607\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5139 - mae: 0.4767 - val_loss: 15.5275 - val_mae: 2.7659\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5412 - mae: 0.5134 - val_loss: 15.5477 - val_mae: 2.7687\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5304 - mae: 0.4897 - val_loss: 15.5857 - val_mae: 2.7670\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5070 - mae: 0.4780 - val_loss: 15.5309 - val_mae: 2.7533\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5011 - mae: 0.4750 - val_loss: 15.5782 - val_mae: 2.7721\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 21.9976 - mae: 3.0090\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 1s 37ms/step - loss: 531.3131 - mae: 21.2253 - val_loss: 567.9335 - val_mae: 21.8701\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 494.7646 - mae: 20.3550 - val_loss: 526.7747 - val_mae: 20.9128\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 452.8961 - mae: 19.3007 - val_loss: 476.5811 - val_mae: 19.7100\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 401.6833 - mae: 17.8942 - val_loss: 414.0204 - val_mae: 18.0987\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 340.5271 - mae: 16.1858 - val_loss: 336.7602 - val_mae: 15.9413\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 265.5007 - mae: 14.0859 - val_loss: 249.7851 - val_mae: 13.3420\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 188.5709 - mae: 11.6919 - val_loss: 164.0129 - val_mae: 10.3213\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 122.2908 - mae: 9.1705 - val_loss: 100.9075 - val_mae: 7.9064\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.5898 - mae: 7.0898 - val_loss: 75.6522 - val_mae: 6.9389\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 63.3211 - mae: 6.3265 - val_loss: 66.7941 - val_mae: 6.5984\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 52.5045 - mae: 5.6015 - val_loss: 53.3345 - val_mae: 5.8633\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 40.9532 - mae: 4.8335 - val_loss: 43.0059 - val_mae: 5.1318\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 34.0059 - mae: 4.3500 - val_loss: 38.3119 - val_mae: 4.7568\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 29.3933 - mae: 3.9067 - val_loss: 35.4198 - val_mae: 4.4820\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.5838 - mae: 3.6925 - val_loss: 34.1971 - val_mae: 4.3394\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 24.2377 - mae: 3.5301 - val_loss: 32.6135 - val_mae: 4.2104\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 22.8673 - mae: 3.4229 - val_loss: 31.3887 - val_mae: 4.0975\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 21.9275 - mae: 3.3369 - val_loss: 30.6631 - val_mae: 3.9931\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 20.5351 - mae: 3.2108 - val_loss: 29.4415 - val_mae: 3.8887\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 19.6587 - mae: 3.1026 - val_loss: 28.6606 - val_mae: 3.8440\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 18.6986 - mae: 3.0228 - val_loss: 28.4666 - val_mae: 3.7990\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 18.2275 - mae: 3.0047 - val_loss: 28.2636 - val_mae: 3.7406\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 17.3591 - mae: 2.9248 - val_loss: 27.3547 - val_mae: 3.6983\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 16.6237 - mae: 2.8354 - val_loss: 27.1691 - val_mae: 3.6843\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 16.0926 - mae: 2.7879 - val_loss: 26.4042 - val_mae: 3.6413\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 15.6786 - mae: 2.7491 - val_loss: 26.0309 - val_mae: 3.5890\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 15.0866 - mae: 2.6915 - val_loss: 25.6314 - val_mae: 3.5602\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.7615 - mae: 2.6527 - val_loss: 25.6373 - val_mae: 3.5501\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 14.4166 - mae: 2.6047 - val_loss: 25.1135 - val_mae: 3.5103\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 13.9695 - mae: 2.5583 - val_loss: 24.9074 - val_mae: 3.4817\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 13.5960 - mae: 2.5253 - val_loss: 24.9757 - val_mae: 3.4829\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 13.5332 - mae: 2.5012 - val_loss: 24.1978 - val_mae: 3.4497\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 13.0519 - mae: 2.4618 - val_loss: 24.5750 - val_mae: 3.4492\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 12.8982 - mae: 2.4799 - val_loss: 24.2705 - val_mae: 3.4241\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.4785 - mae: 2.4257 - val_loss: 23.6801 - val_mae: 3.3974\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.2393 - mae: 2.3803 - val_loss: 23.4855 - val_mae: 3.3832\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.0069 - mae: 2.3480 - val_loss: 23.1308 - val_mae: 3.3640\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.7554 - mae: 2.3142 - val_loss: 22.9625 - val_mae: 3.3566\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.5571 - mae: 2.2900 - val_loss: 22.6795 - val_mae: 3.3282\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.3951 - mae: 2.2731 - val_loss: 22.4585 - val_mae: 3.3210\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.2110 - mae: 2.2603 - val_loss: 22.4026 - val_mae: 3.3110\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.9799 - mae: 2.2422 - val_loss: 22.5016 - val_mae: 3.2924\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.8864 - mae: 2.2542 - val_loss: 22.4332 - val_mae: 3.2885\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.6734 - mae: 2.2300 - val_loss: 21.8280 - val_mae: 3.2691\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.5860 - mae: 2.2028 - val_loss: 21.5794 - val_mae: 3.2716\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.3129 - mae: 2.1696 - val_loss: 21.6205 - val_mae: 3.2422\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.3048 - mae: 2.1938 - val_loss: 21.8587 - val_mae: 3.2434\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.1028 - mae: 2.1738 - val_loss: 21.1999 - val_mae: 3.1924\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.0009 - mae: 2.1402 - val_loss: 20.7951 - val_mae: 3.2004\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.8496 - mae: 2.1105 - val_loss: 21.0672 - val_mae: 3.2048\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.6966 - mae: 2.1081 - val_loss: 21.0315 - val_mae: 3.1806\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.5266 - mae: 2.1027 - val_loss: 20.7522 - val_mae: 3.1504\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.5161 - mae: 2.0762 - val_loss: 20.2919 - val_mae: 3.1600\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.2726 - mae: 2.0408 - val_loss: 20.3607 - val_mae: 3.1695\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.2779 - mae: 2.0623 - val_loss: 20.7866 - val_mae: 3.1237\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.1683 - mae: 2.0617 - val_loss: 20.4810 - val_mae: 3.1268\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 8.8736 - mae: 2.0194 - val_loss: 20.1967 - val_mae: 3.1466\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.8859 - mae: 2.0111 - val_loss: 20.0001 - val_mae: 3.1274\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.6346 - mae: 1.9823 - val_loss: 20.2062 - val_mae: 3.1036\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 8.6405 - mae: 1.9842 - val_loss: 20.0662 - val_mae: 3.0856\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.4656 - mae: 1.9695 - val_loss: 20.2350 - val_mae: 3.0789\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.3354 - mae: 1.9600 - val_loss: 20.3313 - val_mae: 3.1115\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 8.2674 - mae: 1.9554 - val_loss: 19.9942 - val_mae: 3.0803\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.4410 - mae: 1.9720 - val_loss: 19.6677 - val_mae: 3.0872\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.0671 - mae: 1.9156 - val_loss: 20.0462 - val_mae: 3.0690\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 8.1241 - mae: 1.9317 - val_loss: 19.7270 - val_mae: 3.0705\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.9505 - mae: 1.9189 - val_loss: 20.0986 - val_mae: 3.0456\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.8017 - mae: 1.9079 - val_loss: 19.7003 - val_mae: 3.0678\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.7477 - mae: 1.8927 - val_loss: 19.3463 - val_mae: 3.0293\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.6547 - mae: 1.8624 - val_loss: 19.3415 - val_mae: 3.0323\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.5304 - mae: 1.8585 - val_loss: 19.4810 - val_mae: 2.9936\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.4441 - mae: 1.8322 - val_loss: 19.4928 - val_mae: 3.0478\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.3997 - mae: 1.8431 - val_loss: 19.8185 - val_mae: 3.0187\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.2693 - mae: 1.8318 - val_loss: 19.4747 - val_mae: 3.0382\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 7.2413 - mae: 1.8232 - val_loss: 19.6479 - val_mae: 3.0151\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.0367 - mae: 1.8096 - val_loss: 19.5590 - val_mae: 3.0273\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.9534 - mae: 1.7941 - val_loss: 19.4101 - val_mae: 3.0187\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.9355 - mae: 1.7945 - val_loss: 19.5214 - val_mae: 2.9865\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.9665 - mae: 1.8178 - val_loss: 19.3298 - val_mae: 2.9884\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.7674 - mae: 1.7625 - val_loss: 19.1633 - val_mae: 3.0438\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.7765 - mae: 1.7613 - val_loss: 19.3590 - val_mae: 2.9630\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.6310 - mae: 1.7599 - val_loss: 19.4173 - val_mae: 2.9637\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 6.5740 - mae: 1.7222 - val_loss: 19.3626 - val_mae: 3.0363\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.4708 - mae: 1.7292 - val_loss: 19.4073 - val_mae: 2.9778\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3559 - mae: 1.7235 - val_loss: 19.5110 - val_mae: 2.9920\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.3012 - mae: 1.7195 - val_loss: 19.3384 - val_mae: 2.9681\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2520 - mae: 1.7118 - val_loss: 19.3371 - val_mae: 2.9806\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1928 - mae: 1.6832 - val_loss: 19.3717 - val_mae: 2.9758\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 6.0490 - mae: 1.6961 - val_loss: 19.4300 - val_mae: 2.9434\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.2128 - mae: 1.7318 - val_loss: 19.2704 - val_mae: 2.9711\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1448 - mae: 1.6815 - val_loss: 18.8069 - val_mae: 3.0089\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.0670 - mae: 1.6801 - val_loss: 19.1411 - val_mae: 2.9286\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8705 - mae: 1.6872 - val_loss: 19.0797 - val_mae: 2.9729\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.8054 - mae: 1.6386 - val_loss: 18.9048 - val_mae: 2.9858\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.7574 - mae: 1.6187 - val_loss: 19.3138 - val_mae: 2.9396\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.6922 - mae: 1.6399 - val_loss: 18.8610 - val_mae: 2.9618\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.6415 - mae: 1.6117 - val_loss: 18.8513 - val_mae: 2.9910\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.8709 - mae: 1.6592 - val_loss: 19.1202 - val_mae: 2.9553\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.5095 - mae: 1.6359 - val_loss: 18.5500 - val_mae: 2.9918\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4897 - mae: 1.6080 - val_loss: 18.7289 - val_mae: 2.9609\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 5.3869 - mae: 1.5961 - val_loss: 18.5649 - val_mae: 2.9332\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2956 - mae: 1.5731 - val_loss: 18.5629 - val_mae: 2.9348\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 5.2073 - mae: 1.5741 - val_loss: 18.6582 - val_mae: 2.9616\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1902 - mae: 1.5526 - val_loss: 18.5541 - val_mae: 2.9610\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1644 - mae: 1.5541 - val_loss: 18.8207 - val_mae: 2.9296\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 5.0950 - mae: 1.5737 - val_loss: 18.5210 - val_mae: 3.0003\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9984 - mae: 1.5297 - val_loss: 18.4455 - val_mae: 2.9688\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9968 - mae: 1.5529 - val_loss: 18.6131 - val_mae: 2.9358\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.8648 - mae: 1.5169 - val_loss: 18.4265 - val_mae: 3.0114\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9089 - mae: 1.5158 - val_loss: 18.3177 - val_mae: 2.9697\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.6979 - mae: 1.5036 - val_loss: 18.5514 - val_mae: 2.9162\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.7392 - mae: 1.5029 - val_loss: 18.1507 - val_mae: 2.9827\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.6361 - mae: 1.4837 - val_loss: 18.4386 - val_mae: 2.9721\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.5999 - mae: 1.4759 - val_loss: 18.4483 - val_mae: 2.9860\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.5444 - mae: 1.4872 - val_loss: 18.4930 - val_mae: 2.9626\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4108 - mae: 1.4531 - val_loss: 18.2808 - val_mae: 3.0041\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4449 - mae: 1.4576 - val_loss: 18.2027 - val_mae: 2.9716\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.2795 - mae: 1.4344 - val_loss: 18.1423 - val_mae: 2.9486\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.3690 - mae: 1.4506 - val_loss: 18.0464 - val_mae: 2.9866\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.2269 - mae: 1.4269 - val_loss: 18.3084 - val_mae: 2.9862\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.1636 - mae: 1.4115 - val_loss: 18.3754 - val_mae: 2.9938\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 4.1450 - mae: 1.4120 - val_loss: 18.2796 - val_mae: 3.0017\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 4.2129 - mae: 1.4249 - val_loss: 18.1063 - val_mae: 2.9874\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.2419 - mae: 1.4263 - val_loss: 18.2093 - val_mae: 2.9837\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1108 - mae: 1.4163 - val_loss: 17.9448 - val_mae: 2.9946\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9856 - mae: 1.4062 - val_loss: 18.0965 - val_mae: 2.9518\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.0444 - mae: 1.3824 - val_loss: 17.8693 - val_mae: 3.0142\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8990 - mae: 1.3595 - val_loss: 17.8989 - val_mae: 2.9798\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8469 - mae: 1.3655 - val_loss: 17.9215 - val_mae: 3.0063\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8273 - mae: 1.3836 - val_loss: 18.0424 - val_mae: 2.9803\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8191 - mae: 1.3540 - val_loss: 17.6731 - val_mae: 3.0253\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6846 - mae: 1.3481 - val_loss: 18.2323 - val_mae: 2.9981\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7064 - mae: 1.3566 - val_loss: 17.7852 - val_mae: 3.0125\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.7089 - mae: 1.3660 - val_loss: 17.7776 - val_mae: 3.0148\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.5245 - mae: 1.3291 - val_loss: 18.1453 - val_mae: 2.9511\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5792 - mae: 1.3409 - val_loss: 17.5885 - val_mae: 3.0275\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6478 - mae: 1.3503 - val_loss: 17.8156 - val_mae: 2.9930\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6693 - mae: 1.3625 - val_loss: 18.0420 - val_mae: 3.0087\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6444 - mae: 1.3469 - val_loss: 17.8001 - val_mae: 3.0310\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3229 - mae: 1.2892 - val_loss: 18.1406 - val_mae: 2.9902\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.3295 - mae: 1.2872 - val_loss: 17.7983 - val_mae: 3.0442\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.3434 - mae: 1.2920 - val_loss: 17.7763 - val_mae: 3.0133\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.3592 - mae: 1.2974 - val_loss: 17.7657 - val_mae: 3.0253\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.2394 - mae: 1.2703 - val_loss: 17.7921 - val_mae: 3.0466\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 3.1877 - mae: 1.2555 - val_loss: 17.9372 - val_mae: 2.9641\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2507 - mae: 1.2859 - val_loss: 17.6899 - val_mae: 3.0379\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2276 - mae: 1.2694 - val_loss: 18.0331 - val_mae: 3.0821\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.0985 - mae: 1.2551 - val_loss: 17.7395 - val_mae: 3.0483\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.1593 - mae: 1.2538 - val_loss: 17.8826 - val_mae: 3.0402\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0507 - mae: 1.2237 - val_loss: 17.9120 - val_mae: 3.0117\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.9042 - mae: 1.1980 - val_loss: 17.8591 - val_mae: 3.0695\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0039 - mae: 1.2238 - val_loss: 17.7988 - val_mae: 3.0280\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.8928 - mae: 1.2024 - val_loss: 17.8156 - val_mae: 3.0201\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.8017 - mae: 1.1786 - val_loss: 17.7751 - val_mae: 3.0662\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8901 - mae: 1.2012 - val_loss: 18.0564 - val_mae: 3.0267\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.7968 - mae: 1.1835 - val_loss: 18.0211 - val_mae: 3.0999\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.7492 - mae: 1.1624 - val_loss: 17.8174 - val_mae: 3.0476\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.7790 - mae: 1.1640 - val_loss: 17.7968 - val_mae: 3.0396\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.7293 - mae: 1.1598 - val_loss: 17.8086 - val_mae: 3.0535\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.7743 - mae: 1.1727 - val_loss: 17.8256 - val_mae: 3.0634\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.6489 - mae: 1.1464 - val_loss: 17.8263 - val_mae: 3.0537\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5752 - mae: 1.1297 - val_loss: 17.8574 - val_mae: 3.0498\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.7021 - mae: 1.1659 - val_loss: 17.8086 - val_mae: 3.0554\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5613 - mae: 1.1310 - val_loss: 18.2353 - val_mae: 3.0860\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.5678 - mae: 1.1261 - val_loss: 17.9759 - val_mae: 3.0963\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.4777 - mae: 1.1038 - val_loss: 18.1515 - val_mae: 3.0731\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.5428 - mae: 1.1266 - val_loss: 17.8945 - val_mae: 3.0908\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5283 - mae: 1.1214 - val_loss: 17.8749 - val_mae: 3.0718\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.5014 - mae: 1.1179 - val_loss: 18.1496 - val_mae: 3.0565\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.3804 - mae: 1.0732 - val_loss: 17.9876 - val_mae: 3.1083\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.3699 - mae: 1.0844 - val_loss: 18.1331 - val_mae: 3.0796\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5063 - mae: 1.1049 - val_loss: 18.0193 - val_mae: 3.0939\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.4186 - mae: 1.0966 - val_loss: 17.9948 - val_mae: 3.0882\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.3677 - mae: 1.0872 - val_loss: 17.9302 - val_mae: 3.1093\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.3373 - mae: 1.0608 - val_loss: 18.1881 - val_mae: 3.0751\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.2277 - mae: 1.0420 - val_loss: 17.9421 - val_mae: 3.1050\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.2097 - mae: 1.0291 - val_loss: 17.9254 - val_mae: 3.0936\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.1981 - mae: 1.0456 - val_loss: 17.9155 - val_mae: 3.0899\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.2276 - mae: 1.0368 - val_loss: 17.9486 - val_mae: 3.1020\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1342 - mae: 1.0125 - val_loss: 17.9376 - val_mae: 3.0734\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.1043 - mae: 1.0034 - val_loss: 17.7925 - val_mae: 3.1158\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.1449 - mae: 1.0196 - val_loss: 17.9341 - val_mae: 3.1162\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 2.2282 - mae: 1.0559 - val_loss: 18.1925 - val_mae: 3.0970\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1803 - mae: 1.0607 - val_loss: 18.0920 - val_mae: 3.0839\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0837 - mae: 1.0208 - val_loss: 18.0101 - val_mae: 3.1349\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0805 - mae: 0.9946 - val_loss: 18.0076 - val_mae: 3.1283\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9909 - mae: 0.9694 - val_loss: 17.9369 - val_mae: 3.0934\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.9526 - mae: 0.9712 - val_loss: 18.2997 - val_mae: 3.1376\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9434 - mae: 0.9610 - val_loss: 18.1783 - val_mae: 3.1132\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9397 - mae: 0.9579 - val_loss: 18.1720 - val_mae: 3.1214\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.9155 - mae: 0.9664 - val_loss: 18.0341 - val_mae: 3.0950\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0121 - mae: 0.9812 - val_loss: 18.0349 - val_mae: 3.1108\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.8797 - mae: 0.9879 - val_loss: 17.8847 - val_mae: 3.1389\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.9096 - mae: 0.9622 - val_loss: 17.9715 - val_mae: 3.0962\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8910 - mae: 0.9480 - val_loss: 18.1951 - val_mae: 3.1294\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.8300 - mae: 0.9411 - val_loss: 18.2908 - val_mae: 3.1242\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.7860 - mae: 0.9238 - val_loss: 18.0614 - val_mae: 3.1408\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.9559 - mae: 0.9787 - val_loss: 18.1233 - val_mae: 3.1096\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8444 - mae: 0.9624 - val_loss: 18.3371 - val_mae: 3.1278\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8854 - mae: 0.9508 - val_loss: 18.4339 - val_mae: 3.1507\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8129 - mae: 0.9425 - val_loss: 18.2669 - val_mae: 3.1238\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8348 - mae: 0.9363 - val_loss: 18.1308 - val_mae: 3.1494\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7477 - mae: 0.9206 - val_loss: 18.3429 - val_mae: 3.1276\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.7354 - mae: 0.9260 - val_loss: 18.1846 - val_mae: 3.1656\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6612 - mae: 0.8808 - val_loss: 18.6780 - val_mae: 3.1362\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6633 - mae: 0.8835 - val_loss: 18.3407 - val_mae: 3.1769\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.6366 - mae: 0.8743 - val_loss: 18.6872 - val_mae: 3.1524\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.7073 - mae: 0.9083 - val_loss: 18.4242 - val_mae: 3.1727\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.7321 - mae: 0.9200 - val_loss: 18.5556 - val_mae: 3.1468\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.6908 - mae: 0.9348 - val_loss: 18.4173 - val_mae: 3.1720\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7054 - mae: 0.9116 - val_loss: 18.3534 - val_mae: 3.1562\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6026 - mae: 0.8837 - val_loss: 18.6576 - val_mae: 3.1726\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6136 - mae: 0.8780 - val_loss: 18.3399 - val_mae: 3.1713\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5780 - mae: 0.8486 - val_loss: 18.6079 - val_mae: 3.1835\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5330 - mae: 0.8421 - val_loss: 18.4181 - val_mae: 3.1556\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.5483 - mae: 0.8482 - val_loss: 18.4479 - val_mae: 3.1456\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5756 - mae: 0.8761 - val_loss: 18.3847 - val_mae: 3.1671\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4652 - mae: 0.8187 - val_loss: 18.7381 - val_mae: 3.1928\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4930 - mae: 0.8226 - val_loss: 18.5613 - val_mae: 3.1853\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.5130 - mae: 0.8351 - val_loss: 18.4769 - val_mae: 3.1961\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5538 - mae: 0.8538 - val_loss: 18.6079 - val_mae: 3.1873\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4649 - mae: 0.8329 - val_loss: 18.5576 - val_mae: 3.1708\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4789 - mae: 0.8247 - val_loss: 18.7675 - val_mae: 3.1908\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4438 - mae: 0.8140 - val_loss: 18.5453 - val_mae: 3.2029\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3966 - mae: 0.8132 - val_loss: 18.7138 - val_mae: 3.1857\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.4401 - mae: 0.8225 - val_loss: 18.8102 - val_mae: 3.2276\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3771 - mae: 0.7942 - val_loss: 18.9003 - val_mae: 3.1917\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3952 - mae: 0.7960 - val_loss: 18.7506 - val_mae: 3.1845\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3732 - mae: 0.7881 - val_loss: 18.9067 - val_mae: 3.2025\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3424 - mae: 0.7866 - val_loss: 18.7265 - val_mae: 3.2188\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4207 - mae: 0.8242 - val_loss: 18.7954 - val_mae: 3.2077\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3569 - mae: 0.7946 - val_loss: 18.9304 - val_mae: 3.2292\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3308 - mae: 0.7895 - val_loss: 19.2570 - val_mae: 3.2232\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3573 - mae: 0.7919 - val_loss: 18.7654 - val_mae: 3.2205\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3488 - mae: 0.7863 - val_loss: 19.0029 - val_mae: 3.2121\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3917 - mae: 0.7928 - val_loss: 19.0323 - val_mae: 3.2385\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2689 - mae: 0.7662 - val_loss: 19.3842 - val_mae: 3.1934\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4144 - mae: 0.8193 - val_loss: 19.1579 - val_mae: 3.2635\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3999 - mae: 0.8184 - val_loss: 19.1532 - val_mae: 3.2169\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.3778 - mae: 0.8032 - val_loss: 18.9541 - val_mae: 3.2320\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2845 - mae: 0.7685 - val_loss: 19.1950 - val_mae: 3.2109\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3383 - mae: 0.7829 - val_loss: 18.9375 - val_mae: 3.2406\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3922 - mae: 0.8068 - val_loss: 19.1296 - val_mae: 3.1998\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4285 - mae: 0.8793 - val_loss: 18.9967 - val_mae: 3.2319\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4713 - mae: 0.8574 - val_loss: 19.2598 - val_mae: 3.2237\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4034 - mae: 0.8466 - val_loss: 18.7210 - val_mae: 3.2139\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4096 - mae: 0.8062 - val_loss: 19.0536 - val_mae: 3.2000\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2703 - mae: 0.7495 - val_loss: 18.9460 - val_mae: 3.2071\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1988 - mae: 0.7281 - val_loss: 18.9156 - val_mae: 3.1909\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1649 - mae: 0.7206 - val_loss: 18.9797 - val_mae: 3.2233\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1765 - mae: 0.7259 - val_loss: 18.9918 - val_mae: 3.2163\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1800 - mae: 0.7133 - val_loss: 19.0448 - val_mae: 3.2126\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1427 - mae: 0.7236 - val_loss: 19.1433 - val_mae: 3.2355\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1699 - mae: 0.7176 - val_loss: 19.0312 - val_mae: 3.2284\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1240 - mae: 0.6981 - val_loss: 19.2323 - val_mae: 3.2211\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.1578 - mae: 0.7139 - val_loss: 19.2582 - val_mae: 3.2103\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1307 - mae: 0.6979 - val_loss: 18.9151 - val_mae: 3.2121\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.1268 - mae: 0.7101 - val_loss: 19.0048 - val_mae: 3.2223\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.1104 - mae: 0.6953 - val_loss: 19.2970 - val_mae: 3.2302\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.0703 - mae: 0.6799 - val_loss: 19.1544 - val_mae: 3.2364\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.0459 - mae: 0.6675 - val_loss: 19.2676 - val_mae: 3.2333\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.0789 - mae: 0.6980 - val_loss: 19.1148 - val_mae: 3.2403\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1161 - mae: 0.7167 - val_loss: 19.3046 - val_mae: 3.2112\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.0827 - mae: 0.6966 - val_loss: 19.2082 - val_mae: 3.2442\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1055 - mae: 0.6997 - val_loss: 19.4982 - val_mae: 3.2324\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1603 - mae: 0.7094 - val_loss: 19.1560 - val_mae: 3.2417\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1594 - mae: 0.7287 - val_loss: 19.3175 - val_mae: 3.2031\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.1356 - mae: 0.7169 - val_loss: 19.2651 - val_mae: 3.2609\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 1.1500 - mae: 0.7381 - val_loss: 19.5263 - val_mae: 3.2132\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 1.0301 - mae: 0.6661 - val_loss: 19.3750 - val_mae: 3.2573\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.0375 - mae: 0.6811 - val_loss: 19.4163 - val_mae: 3.2134\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0520 - mae: 0.6859 - val_loss: 19.2366 - val_mae: 3.2241\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.0615 - mae: 0.6794 - val_loss: 19.4649 - val_mae: 3.2304\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.0197 - mae: 0.6495 - val_loss: 19.0609 - val_mae: 3.2265\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.9534 - mae: 0.6275 - val_loss: 19.0503 - val_mae: 3.2210\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.9900 - mae: 0.6611 - val_loss: 19.2916 - val_mae: 3.2490\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.0591 - mae: 0.6604 - val_loss: 19.1237 - val_mae: 3.2321\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.9630 - mae: 0.6319 - val_loss: 19.0185 - val_mae: 3.2155\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.9426 - mae: 0.6262 - val_loss: 19.1040 - val_mae: 3.2276\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 1.0033 - mae: 0.6603 - val_loss: 19.2881 - val_mae: 3.2549\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.9983 - mae: 0.6620 - val_loss: 18.8849 - val_mae: 3.2082\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.1003 - mae: 0.6932 - val_loss: 18.9800 - val_mae: 3.2278\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.1408 - mae: 0.7258 - val_loss: 19.3629 - val_mae: 3.2163\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.0283 - mae: 0.6741 - val_loss: 19.1642 - val_mae: 3.2470\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.0150 - mae: 0.7021 - val_loss: 19.1640 - val_mae: 3.2256\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.9920 - mae: 0.6496 - val_loss: 19.0046 - val_mae: 3.2090\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.9075 - mae: 0.6121 - val_loss: 19.0022 - val_mae: 3.2121\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.8792 - mae: 0.5875 - val_loss: 19.1040 - val_mae: 3.2205\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.8657 - mae: 0.5936 - val_loss: 19.1500 - val_mae: 3.2369\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.9107 - mae: 0.6034 - val_loss: 19.3061 - val_mae: 3.2474\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.9257 - mae: 0.6231 - val_loss: 19.3175 - val_mae: 3.2442\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.9078 - mae: 0.5935 - val_loss: 19.3246 - val_mae: 3.2256\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.8430 - mae: 0.5854 - val_loss: 19.1770 - val_mae: 3.2117\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.8758 - mae: 0.5993 - val_loss: 19.2284 - val_mae: 3.2575\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8347 - mae: 0.5882 - val_loss: 19.2953 - val_mae: 3.2566\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.8738 - mae: 0.5953 - val_loss: 19.2114 - val_mae: 3.2292\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.8852 - mae: 0.6163 - val_loss: 19.0077 - val_mae: 3.2547\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8957 - mae: 0.6225 - val_loss: 19.5638 - val_mae: 3.2451\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.8937 - mae: 0.6213 - val_loss: 19.2515 - val_mae: 3.2471\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.9132 - mae: 0.6268 - val_loss: 19.4984 - val_mae: 3.2624\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 20.8085 - mae: 3.3558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mae_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah-LHPBgiI2P",
        "outputId": "1057ecb1-f273-4379-ced9-61e5438379b9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.2167961597442627, 3.0090439319610596, 3.3557770252227783]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(mae_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL-FIxi5ihMI",
        "outputId": "d91381ad-fbdf-4b87-8426-8252031f372b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.1938723723093667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "riBg4QD2ii4u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}